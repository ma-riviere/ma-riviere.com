---
title: "Tidyverse <-> data.table"
subtitle: "Equivalence between `Tidyverse` and `data.table` expressions"

author:
  name: "Marc-Aurèle Rivière"
  orcid: 0000-0002-5108-3382

date: 2022-05-19

abstract: "This document is a collection of notes I took while learning to use `data.table`, summarizing the equivalences between most `dplyr`/`tidyr` verbs and `data.table`."

categories:
  - "Data Manipulation"
  - "Tidyverse"
  - "data.table"
  - "R"

format:
  html:
    code-tools:
      source: true
      toggle: false

execute: 
  output: asis

# filters:
#   - grouped-tabsets
---

<hr style="margin-bottom: 30px; margin-top: -12px">

:::{.callout-tip collapse="true"}

# Expand for Version History

- **V1:** 2022-05-19  
- **V2:** 2022-05-26   
  - Improved the section on **keys** (for ordering & filtering)  
  - Adding a [section](#tidyr-others) for translations of `Tidyr` (and other similar packages)      
  - Capping tables to display 15 rows max when unfolded  
  - Improving table display (stripping, hiding the contents of nested columns, ...)
- **V3:** 2022-07-20
  - Updating examples of dynamic programming based on the [latest recommendations](https://rdatatable.gitlab.io/data.table/articles/datatable-programming.html)  
  - Added new entries in [processing examples](#processing-examples)  
  - Added new entries to [Tidyr & Others](#tidyr-others): expand + complete, transpose/rotation, ...  
  - Added `pivot_wider` examples to match the `dcast` ones in the [Pivots](#pivots) section  
  - Added some new examples here and there across the [Basic Operations](#basic-operations) section  
  - Added an entry for operating inside nested data.frames/data.tables  
  - Added a processing example for run-length encoding (i.e. successive event tagging)
- **V4:** 2022-08-05
  - Improved `pivot` section: example of one-hot encoding (and reverse operation) + better examples of partial pivots with `.value`  
  - Added `tidyr::uncount()` (row duplication) example  
  - Improved both light & dark themes (code highlight, tables, ...)
:::

```{r}
#| echo: false
#| eval: false
#| output: false

# TODO:

## Grouped tabsets

# head(MT, 1)
first(MT$cyl)
MT[, first(cyl)]

# tail(MT, 1)
last(MT$cyl)
MT[, last(cyl)]

getElement(MT$cyl, 5)
nth(MT$cyl, 5)
MT[5, cyl]

## last_col()

## dplyr::consecutive_id() (v1.1) vs data.table::rleid() : move from example to own section ?
### See: https://github.com/tidyverse/dplyr/blob/main/NEWS.md

## Rework JOINS
### See: https://r4ds.had.co.nz/relational-data.html#filtering-joins
### - New dplyr::join_by() argument for joins -> non-equi, rolling, ...
### - Overlap join example (value -1+1)
### - Rework .EACHI example (and add to joins)
### - See: https://atrebas.github.io/post/2019-03-03-datatable-dplyr/

## dplyr:
### - group_map/modify/walk: DAT[, .(data = .(.SD)), by = group][, func(data[[1]]), by = group]
### - groups/group_data/group_sizes/group_indices/group_vars/n_groups
### - split() vs group_split()
### - nest_join()
### - with_order()

## tidyr:
### - Nesting with grouping variable inside: DAT[, .(data = list(data.table(group, .SD))), by = group]
### - tidyr::unnest_wider/longer ?

## groupingsets & rollup
```

<!------------------------------------------------------------------------------>
<!------------------------------------------------------------------------------>
# Setup {.unnumbered}
***

```{r}
#| echo: false
#| file: !expr here::here("src", "quarto", "renv_setup.R")
```

```{r}
#| echo: false
#| eval: false

renv::install(
  c(
    "here",
    "Rdatatable/data.table",
    "tidyverse/dplyr",
    "tidyr",
    "pipebind",
    "stringr",
    "purrr",
    "lubridate",
    "broom",
    "nplyr",
    "datawizard"
  )
)
```

```{r}
library(here)        # Project management

library(data.table)  # Data wrangling (>= 1.14.3)
library(dplyr)       # Data wrangling (>= 1.1.0)
library(tidyr)       # Data wrangling (extras) (>= 1.2.0)
library(pipebind)    # Piping goodies (>= 0.1.1)

library(stringr)     # Manipulating strings
library(purrr)       # Manipulating lists
library(lubridate)   # Manipulating dates

library(broom)

data.table::setDTthreads(parallel::detectCores(logical = TRUE))
```

:::{.callout-tip collapse="true"}

# Expand for Session Info

```{r}
#| echo: false
#| results: markup

si <- sessioninfo::session_info(pkgs = "attached")

si$platform$Quarto <- system("quarto --version", intern = TRUE)

si$platform$pandoc <- strsplit(si$platform$pandoc, "@")[[1]][1]

si
```

:::

```{r}
#| echo: false

## This section is for the html output (code-linking, ...)

library(knitr)
library(quarto)
library(downlit)
library(xml2)
library(withr)
```

```{css, echo=FALSE}
.panel-tabset > .tab-content {
  display: flex;
}

.panel-tabset > .tab-content > .tab-pane {
  display: block !important;
  visibility: hidden;
  margin-right: -100%;
  width: 100%;
}

.panel-tabset > .tab-content > .active {
  visibility: visible;
}
```

```{r}
#| echo: false
#| file: !expr c(here("src", "quarto", "quarto_theme.R"), here("src", "quarto", "style_gt_mono.R"))
```

<!-------------------------------------------------------->
<!-------------------------------------------------------->
# Basic Operations:
***

:::{.callout-tip}

## `data.table` general syntax:

DT[`row selector` (filter/sort), `col selector` (select/mutate/summarize/rename), `modifiers` (group)]
:::

**Data**

```{r}
MT <- as.data.table(mtcars)
IRIS <- as.data.table(iris)[, Species := as.character(Species)]
```


<!-------------------------------------------------------->
## Arrange / Order

### Basic ordering

::: {.panel-tabset group="framework"}

##### Tidyverse

```{r}
mtcars |> arrange(desc(cyl))
```

**Ordering on multiple columns**

```{r}
mtcars |> arrange(desc(cyl), gear)
```

##### data.table

```{r}
MT[order(-cyl)]

setorder(MT, -cyl)[]
```

**Ordering on multiple columns**

```{r}
MT[order(-cyl, gear)]
```

**Ordering on a character column**

```{r}
IRIS[chorder(Species)]
```

:::

### Ordering with keys

- Keys physically reorders the dataset within the RAM (by reference)  
  - No memory is used for sorting (other than marking which columns is the key)  
- The dataset is marked with an attribute _"sorted"_  
- The dataset is always sorted in _ascending order_, with _NAs_ first  
- Using `keyby` instead of `by` when grouping will set the grouping factors as keys

:::{.callout-tip}
See [this SO post](https://stackoverflow.com/questions/20039335/what-is-the-purpose-of-setting-a-key-in-data-table?rq=1) for more information on keys.
:::

```{r}
setkey(MT, cyl, gear)

setkeyv(MT, c("cyl", "gear"))

MT
```

To see over which keys (if any) the dataset is currently ordered:

```{r}
haskey(MT)

key(MT)
```

:::{.callout-warning}
Unless our task involves repeated subsetting on the same column, the speed gain from key-based subsetting could effectively be nullified by the time needed to reorder the data in RAM, especially for large datasets.
:::


### Ordering with (secondary) indices

- `setindex` creates an index for the provided columns, but doesn’t physically reorder the dataset in RAM.  
- It computes the ordering vector of the dataset's rows according to the provided columns in an additional attribute called _index_  


```{r}
#| echo: false

MT <- as.data.table(mtcars)
```


```{r}
setindex(MT, cyl, gear)

setindexv(MT, c("cyl", "gear"))

MT
```

We can see the additional _index_ attribute added to the `data.table`:

```{r}
#| results: markup

names(attributes(MT))
```

We can get the currently used indices with:

```{r}
indices(MT)
```

Adding a new index doesn't remove a previously existing one:

```{r}
setindex(MT, hp)

indices(MT)
```

We can thus use indices to pre-compute the ordering for the columns (or combinations of columns) that we will be using to group or subset by frequently !



<!-------------------------------------------------------->
## Subset / Filter

```{r}
#| echo: false

MT <- as.data.table(mtcars)
IRIS <- as.data.table(iris)[, Species := as.character(Species)]
```

### Basic filtering

::: {.panel-tabset group="framework"}

##### Tidyverse

```{r}
mtcars |> filter(cyl >= 6 & disp < 180)
```

##### data.table

```{r}
MT[cyl >= 6 & disp < 180]
```

**Filtering on characters:**

For non-regex, use `%chin%`, which is a character-optimized version of `%in%`.  

```{r}
IRIS[Species %chin% c("setosa")]
```

:::

### Filter based on a range

::: {.panel-tabset group="framework"}

##### Tidyverse

```{r}
mtcars |> filter(between(disp, 200, 300))
```

##### data.table

```{r}
MT[disp %between% c(200, 300)]
```

:::


### Filter with a pattern

::: {.panel-tabset group="framework"}

##### Tidyverse

```{r}
mtcars |> filter(str_detect(disp, "^\\d{3}\\."))
```

##### data.table

For regex patterns, use `%like%`

```{r}
MT[like(disp, "^\\d{3}\\.")]
```

Alternatively:

```{r}
MT[disp %like% "^\\d{3}\\."]
```

:::


### Filter on row number (slicing)

::: {.panel-tabset group="framework"}

##### Tidyverse

```{r}
mtcars |> slice(1)

mtcars |> slice_head(n = 1)
```

```{r}
mtcars |> slice(n())

mtcars |> slice_tail(n = 1)
```

**Slice a random sample of rows**

```{r}
mtcars |> slice_sample(n = 5)
```


##### data.table

```{r}
MT[1]
```

```{r}
MT[.N]
```

**Slice a random sample of rows**

```{r}
MT[sample(.N, 5)]
```


:::


### Filter distinct/unique rows

::: {.panel-tabset group="framework"}

##### Tidyverse

```{r}
mtcars |> distinct(mpg, hp, .keep_all = TRUE)
```

**Number of unique rows/values**

```{r}
n_distinct(mtcars$gear)
```


##### data.table

```{r}
unique(MT, by = c("mpg", "hp"))
```

**Number of unique rows/values**

```{r}
uniqueN(MT, by = "gear")
```

:::



### Filter by keys

When keys or indices are defined, we can filter based on them, which is often a lot faster.  

:::{.callout-tip}
We do not even need to specify the column name we are filtering on: the values will be attributed to the keys in order.
:::


```{r}
setkey(MT, cyl)

MT[.(6)] # Equivalent to MT[cyl == 6]
```

```{r}
setkey(MT, cyl, gear)

MT[.(6, 4)] # Equivalent to MT[cyl == 6 & gear == 4]
```


### Filter by indices

To filter by indices, we can use the `on` argument, which creates a **temporary secondary index** on the fly (if it doesn't already exist).

```{r}
IRIS["setosa", on = "Species"]
```

Since the time to compute the secondary indices is quite small, we don’t have to use `setindex`, unless the task involves repeated subsetting on the same columns.


:::{.callout-tip}
When using `on` with multiple values, the `nomatch = NULL` argument avoids 
creating combinations that do not exist in the original data (i.e. for `cyl == 5` here)
:::

```{r}
MT[.(4:6, 4), on = c("cyl", "gear"), nomatch = NULL]
```



### Filtering on multiple columns

**Filtering with one function taking multiple columns:**

```{r}
fcn <- \(x, y) x > y

fdat <- \(d) with(d, gear > cyl)
```

```{r}
cols <- c("gear", "cyl")
```

::: {.panel-tabset group="framework"}

##### Tidyverse

* Manually:

```{r}
mtcars |> filter(fcn(gear, cyl))
```

* Programatically:

_With the column names_

```{r}
mtcars |> filter(fcn(!!!syms(cols)))
```

_With the data_

```{r}
mtcars |> filter(fdat(cur_data()))
```


##### data.table

* Manually:

```{r}
MT[fcn(gear, cyl),]
```

* Programatically:

_With the column names:_

```{r}
MT[do.call(fcn, args), env = list(args = as.list(cols))]

MT[rlang::exec(fcn, !!!args), env = list(args = as.list(cols))]
```

_With the data:_

```{r}
MT[fdat(MT),] # Can't use .SD in i
```

:::{.callout-note}
We can't use `.SD` in the `i` clause of a `data.table`, but we can bypass that constraint by doing the operation in two steps:  
- Obtaining a vector stating if each row of the table matches or not the conditions  
- Filtering the original table based on the vector
:::

```{r}
MT[MT[, fdat(.SD)]]
```


:::


**Combining multiple filtering functions:**

This function filters rows that have 2 or more non-zero decimals, and we're going to call it on multiple columns:

```{r}
decp <- \(x) str_length(str_remove(as.character(abs(x)), ".*\\.")) >= 2
```

```{r}
cols <- c("drat", "wt", "qsec")
```

::: {.panel-tabset group="framework"}

##### Tidyverse

Manually:

```{r}
mtcars |> filter(decp(drat) & decp(wt) & decp(qsec))
```

Programatically:

```{r}
mtcars |> filter(if_all(cols, decp))
```

##### data.table

Manually:

```{r}
MT[decp(drat) & decp(wt) & decp(qsec), ]
```

Programatically:

```{r}
MT[Reduce(`&`, lapply(mget(cols), decp)), ]

MT[Reduce(`&`, lapply(MT[, ..cols], decp)), ]
```

_With the newer [`env`](https://rdatatable.gitlab.io/data.table/articles/datatable-programming.html) meta-programming interface:_

```{r}
MT[Reduce(`&`, lapply(v1, decp)), env = list(v1 = as.list(cols))]
```

_In two steps:_

```{r}
MT[MT[, Reduce(`&`, lapply(.SD, decp)), .SDcols = cols]]

MT[MT[, Reduce(`&`, lapply(.SD[, mget(cols)], decp))]]
```

:::



<!-------------------------------------------------------->
## Select:

```{r}
#| echo: false

MT <- as.data.table(mtcars)
IRIS <- as.data.table(iris)[, Species := as.character(Species)]
```

```{r}
MT |> select(matches("cyl|disp"))

MT[, .(mpg, disp)]

MT[ , .SD, .SDcols = c("mpg", "disp")]
MT[, .SD, .SDcols = patterns("mpg|disp")]
```

By dynamic name:

```{r}
cols <- c("cyl", "disp")

mtcars |> select(all_of(cols))

mtcars |> select(!!cols)
```

```{r}
copy(MT)[, ..cols]

copy(MT)[, mget(cols)]

copy(MT)[, cols, with = FALSE]

copy(MT)[, j, env = list(j = as.list(cols))]
```


**Remove a column**

```{r}
mtcars |> select(-cyl)

copy(MT)[, c("cyl") := NULL][]
copy(MT)[, !"cyl"] # MT[, -"cyl"]
```

By dynamic name:

```{r}
col <- "cyl"

copy(MT)[, (col) := NULL][]

copy(MT)[, j := NULL, env = list(j = col)][]
```

```{r}
cols <- c("cyl", "disp")

mtcars |> select(!matches(cols))
```

```{r}
copy(MT)[, !..cols]

copy(MT)[, !cols, with = FALSE]

copy(MT)[, -j, env = list(j = I(cols))][]
```


By pattern:

```{r}
mtcars |> select(-matches("^d"))

copy(MT)[, .SD, .SDcols = !patterns("^d")]

copy(MT)[, grep("^d", colnames(MT)) := NULL][]
```


By type:

```{r}
IRIS |> select(where(\(c) !is.numeric(c)))

IRIS[, .SD, .SDcols = !is.numeric]
```


**Select + pull**

```{r}
#| eval: false

mtcars |> pull(disp)
```

```{r}
#| eval: false

MT[, disp]
```


**Select + rename**

```{r}
mtcars |> select(dispp = disp)

MT[, .(dispp = disp)]
```


<!-------------------------------------------------------->
## Rename:

```{r}
#| echo: false

MT <- as.data.table(mtcars)
IRIS <- as.data.table(iris)[, Species := as.character(Species)]
```

**Manually:**

```{r}
mtcars |> rename(CYL = cyl, MPG = mpg)

setnames(copy(MT), c("cyl", "mpg"), c("CYL", "MPG"))[]
```


**Programmatically:**

```{r}
mtcars |> rename_with(\(c) toupper(c), .cols = matches("^d"))

setnames(copy(MT), grep("^d", names(MT)), \(c) toupper(c))[]
```


<!-------------------------------------------------------->
## Mutate:

```{r}
#| echo: false

MT <- as.data.table(mtcars)
IRIS <- as.data.table(iris)[, Species := as.character(Species)]
```

**`data.table` can mutate in 2 ways:**  
- Using `=` creates a new DT with the new columns only (like `dplyr::transmute`)   
- Using `:=` modifies the current dt *in place* (like `dplyr::mutate`)

The function modifying a column should be the same size as the original column (or group).  
If only one value is provided with `:=`, it will be recycled to the whole column/group.

If the number of values provided is smaller than the original column/group:  
- With `:=`, an error will be raised, asking to manually specify how to recycle the values.  
- With `=`, it will behave like `dplyr::summarize` (if a grouping has been specified).

### Transmute:

```{r}
MT[, .(cyl = cyl * 2)]
```


### In-Place:

#### Single column:

```{r}
mtcars |> mutate(cyl = 200)

copy(MT)[, cyl := 200][]
```

**Mutate a single column with a function:**

```{r}
mtcars |> mutate(mean_cyl = mean(cyl, na.rm = TRUE))

copy(MT)[, mean_cyl := mean(cyl, na.rm = TRUE)][]
copy(MT)[, `:=`(mean_cyl = mean(cyl, na.rm = TRUE))][]
```


**Dynamic mutate:**

Dynamic name on the LHS:

```{r}
RHS <- "MPG"

mtcars |> mutate({{RHS}} := mean(mpg))

mtcars |> mutate("{RHS}" := mean(mpg))
```

```{r}
copy(MT)[, (RHS) := mean(mpg)][] # (RHS) <=> c(RHS)

copy(MT)[, j := mean(mpg), env = list(j = RHS)][]
```


Dynamic name on both LHS & RHS:

`data.table` requires the use of `base::get()` on the LHS

```{r}
LHS <- "MPG"
RHS <- "mpg"
```

```{r}
mtcars |> mutate("{LHS}" := as.character(.data[[RHS]]))

mtcars |> mutate({{LHS}} := as.character(cur_data()[[RHS]]))
```

```{r}
copy(MT)[, c(LHS) := as.character(get(RHS))][]

copy(MT)[, x := y, env = list(x = LHS, y = RHS)][]
```


**Mutate based on multiple conditions:**

`if_else:`

```{r}
mtcars |> mutate(Size = if_else(cyl >= 6, "BIG", "small"))

copy(MT)[, Size := fifelse(cyl >= 6, "BIG", "small")][]
```

`case_when:`

```{r}
mtcars |> mutate(Size = case_when(
  cyl %between% c(2,4) ~ "small",
  cyl %between% c(4,8) ~ "BIG"
))

copy(MT)[, Size := fcase(
  cyl %between% c(2,4), "small", 
  cyl %between% c(4,8), "BIG"
)][]
```

**Mutate only if condition is met:**

It will keep all the rows and only mutate the ones meeting the provided condition (in `i`).

:::{.callout-note}
This can be extended to mutating multiple columns, of course.
:::

```{r}
mtcars |> mutate(BIG = case_when(am == 1 ~ cyl >= 6))

# mtcars |> mutate(BIG = cyl >= 6, .when = am == 1) # Not implemented yet as of dplyr 1.0.9
```


```{r}
copy(MT)[am == 1, BIG := cyl >= 6][]
```


**Lag / Lead**

```{r}
mtcars |> mutate(gear1 = lead(gear))

copy(MT)[, gear1 := shift(gear, 1, type = "lead")][]
```


#### Mutate multiple columns:

```{r}
mtcars |> mutate(cyl = 200, gear = 5)

copy(MT)[, `:=`(cyl = 200, gear = 5)][]
copy(MT)[, c("cyl", "gear") := list(200, 5)][]
```


**One function applied to multiple columns (across rows):**

```{r}
mtcars |> mutate(across(c("mpg", "disp"), \(c) min(c), .names = "min_{col}"))

copy(MT)[, c("min_mpg", "min_disp") := lapply(.SD, \(c) min(c)), .SDcols = c("mpg", "disp")][]
```

With dynamic naming:

```{r}
new <- c("min_mpg", "min_disp")
old <- c("mpg", "disp")

copy(MT)[, c(new) := lapply(mget(old), min)][]

copy(MT)[, c(new) := lapply(x, min), env = list(x = as.list(setNames(nm = old)))][]
```


**Multiple functions on one column (across rows):**

```{r}
copy(MT)[, c("min_mpg", "max_mpg") := list(min(c(mpg)), max(c(mpg)))][]

copy(MT)[, `:=`(min_mpg = min(c(mpg)), max_mpg = max(c(mpg)))][]
```

```{r}
copy(MT)[, c("min_mpg", "max_mpg") := lapply(.SD, \(x) list(min(x), max(x))) |> rbindlist(), .SDcols = "mpg"][]

copy(MT)[, c("min_mpg", "max_mpg") := lapply(.SD[, .(mpg)], \(x) list(min(x), max(x))) |> rbindlist()][]

copy(MT)[, c("min_mpg", "max_mpg") := lapply(.(mpg), \(x) list(min(x), max(x))) |> do.call(rbind, args = _)][]
```


**One function applied to multiple columns (across columns)**

```{r}
mtcars |> rowwise() |> mutate(RowSum = sum(c_across(where(is.numeric)))) |> ungroup()

copy(MT)[, RowSum := rowSums(.SD), .SDcols = is.numeric][]
```

More general option using row-wise `apply`:

```{r}
copy(MT)[, RowMean := apply(.SD, 1, \(x) mean(x)), .SDcols = is.numeric][]
```


**Multiple functions applied to multiple columns (row-wise)**

```{r}
copy(MT)[, c("row_mean", "row_sum") := apply(.SD, 1, \(x) list(mean(x), sum(x))) |> rbindlist(), .SDcols = is.numeric][]
```


**Apply an anonymous function inside the DT:**

```{r}
MT[, {
    print(summary(mpg))
    x <- cyl + gear
    .(RN = 1:.N, CG = x)
  }
]
```


<!-------------------------------------------------------->
## Group / Aggregate:

```{r}
#| echo: false

MT <- as.data.table(mtcars)
IRIS <- as.data.table(iris)[, Species := as.character(Species)]
```

The examples listed apply a grouping but do nothing (using `.SD` to simply keep all columns as is)

**One group:**

```{r}
mtcars |> group_by(cyl)

MT[, .SD, by = cyl]
```


**Multiple groups:**

```{r}
MT[, .SD, by = .(cyl, gear)]
```


**Dynamic grouping:**

```{r}
cols <- c("cyl", "disp")

mtcars |> group_by(across(any_of(cols)))

MT[, .SD, by = cols]
```

With potentially absent columns:

```{r}
cols <- c("cyl", "disp", "fake_col")

mtcars |> group_by(across(any_of(cols)))

MT[, .SD, by = intersect(cols, colnames(MT))]
```

**Getting the current group name:**

Use the `.BY` argument to get the current group name:

```{r}
#| layout-nrow: 1
#| layout-ncol: 3

mtcars |> group_by(cyl) |> 
  group_walk(
    \(d, g) with(d, plot(gear, mpg, main = paste("Cylinders:", g$cyl)))
  )
```

```{r}
#| layout-nrow: 1
#| layout-ncol: 3

MT[, with(.SD, plot(gear, mpg, main = paste("Cylinders:", .BY))), by = cyl] -> void
```


<!-------------------------------------------------------->
## Row numbers & indices:

```{r}
#| echo: false

MT <- as.data.table(mtcars)
IRIS <- as.data.table(iris)[, Species := as.character(Species)]
```

`.I`: Row indices  
`.N`: Number of rows  

`.GRP`: Group indices  
`.NGRP`: Number of groups  

**Getting rows indices:**

```{r}
#| results: markup

MT[, .I]
```


**Adding rows indices:**

```{r}
mtcars |> mutate(I = row_number())

copy(MT)[ , I := .I][]
```


**Getting row indices (after filtering):**

:::{.callout-important}
`.I` gives the vector of row numbers after any subsetting/filtering has been done
:::

Returns the row numbers in the original dataset:

```{r}
mtcars |> mutate(I = row_number()) |> filter(gear == 4) |> pull(I)

MT[, .I[gear == 4]]
```

Returns the row numbers in the new dataset (after filtering):

```{r}
mtcars |> filter(gear == 4) |> mutate(I = row_number()) |> pull(I)

MT[gear == 4, .I]
```


**Getting the row numbers of specific observations:**

Row number of the first and last observation of each group:

```{r}
mtcars |> group_by(cyl) |> summarize(I = cur_group_rows()[c(1, n())]) |> ungroup()
```

```{r}
MT[, .I[c(1, .N)], keyby = cyl]
```

_Keeping all other columns:_

```{r}
mtcars |> mutate(I = row_number()) |> group_by(cyl) |> slice(c(1, n())) |> ungroup()
```

```{r}
copy(MT)[, I := .I][, .SD[c(1, .N)], keyby = cyl]
```


**Filtering based on row numbers:**

```{r}
mtcars |> tail(10)

MT[(.N-10):.N] # Get the last 10 rows
```

```{r}
MT[MT[, .I[(.N-10):.N]]]
```

(Gets the indices of the last 10 rows and filters based on them)


**Adding group indices:**

```{r}
mtcars |> group_by(cyl) |> summarize(GRP = cur_group_id())

MT[, .GRP, by = cyl]
```

Mutate instead of summarize:

```{r}
mtcars |> arrange(cyl) |> group_by(cyl) |> mutate(GRP = cur_group_id())

copy(MT)[, GRP := .GRP, keyby = cyl][]
```


**Row numbers by group:**

```{r}
mtcars |> arrange(gear) |> group_by(gear) |> mutate(I_GRP = row_number())

copy(MT)[, I_GRP := 1:.N, keyby = gear][]
```


**Random sample by group:**

```{r}
mtcars |> group_by(cyl) |> slice_sample(n = 5)

MT[, .SD[sample(.N, 5)], keyby = cyl]
```


**Filter by group size:**

```{r}
mtcars |> group_by(cyl) |> filter(n() >= 8)

MT[, if(.N >= 8) .SD, by = cyl]
```



<!-------------------------------------------------------->
## Relocate:

```{r}
mtcars |> group_by(cyl) |> mutate(GRP = cur_group_id(), .before = 1)

(copy(MT)[ , GRP := .GRP, by = cyl] |> setcolorder(c("GRP", .SD)))[]
```

**Ordering by column names**

```{r}
mtcars |> select(sort(tidyselect::peek_vars()))

setcolorder(copy(MT), sort(names(MT)))[]
```

```{r}
mtcars |> select(carb, sort(tidyselect::peek_vars()))

setcolorder(copy(MT), c("carb", sort(setdiff(names(MT), "carb"))))[]
```


<!-------------------------------------------------------->
## Summarize:

```{r}
#| echo: false

MT <- as.data.table(mtcars)
IRIS <- as.data.table(iris)[, Species := as.character(Species)]
```

Summarizes uses the `=` operator.  
It's only difference with `mutate` is that it takes a function that returns a list of values smaller than the original column (or group) size.  
By default, it will only keep the modified columns (like `transmute`).

```{r}
mtcars |> summarize(mean_cyl = mean(cyl, na.rm = T))

MT[, .(mean_cyl = mean(cyl, na.rm = T))]
```

**Group > summarize**

```{r}
mtcars |> group_by(cyl) |> summarize(N = n())

MT[, .N, by = cyl]
```

`dplyr` automatically `arrange` the result by the grouping factor.  
To mimic this with `data.table`:

```{r}
MT[, .N, keyby = cyl]
MT[order(cyl), .N, by = cyl]
MT[, .N, by = cyl][order(cyl)]
```

Grouping on a condition:

```{r}
mtcars |> group_by(cyl > 6) |> summarize(N = n())

MT[, .N, by = .(cyl > 6)]
```


**Group > filter > summarize**

```{r}
mtcars |> filter(cyl >= 6 & disp >= 200) |> summarize(N = n())

MT[cyl >= 6 & disp >= 200, .(.N)]
```


```{r}
mtcars |> summarize(N = sum(cyl >= 6 & disp >= 200, na.rm = T))

MT[, .(N = sum(cyl >= 6 & disp >= 200, na.rm = T))]
```


**Obtaining one summary statistic on multiple columns**

```{r}
mtcars |> group_by(cyl) |> summarize(across(everything(), \(c) mean(c)))

MT[, lapply(.SD, \(c) mean(c)), keyby = cyl]
```

Apply summary function based on column type:

```{r}
mtcars |> group_by(cyl) |> summarize(across(where(is.double), \(col) mean(col)))

MT[, lapply(.SD, \(col) mean(col)), keyby = cyl, .SDcols = is.double][, cyl := NULL][]
```

Apply summary function to specific columns:

```{r}
mtcars |> group_by(cyl) |> summarize(across(c(mpg, disp), \(.x) mean(.x)))

MT[, lapply(.SD, \(.x) mean(.x)), keyby = cyl, .SDcols = c("mpg", "disp")]
MT[, lapply(.SD[, .(mpg, disp)], \(.x) mean(.x)), keyby = cyl]
```

Apply summary function to specific columns (by pattern):

```{r}
mtcars |> group_by(cyl) |> summarize(across(matches("^mpg|^disp"), \(.x) mean(.x)))

MT[, lapply(.SD, mean), keyby = cyl, .SDcols = patterns("^mpg|^disp")]
```


**Obtaining multiple summary statistics for one column:**

```{r}
mtcars |> group_by(cyl) |> summarize(mean_mpg = mean(mpg), sd_mpg = sd(mpg))

MT[, .(mean_mpg = mean(mpg), sd_mpg = sd(mpg)), keyby = cyl]
```

```{r}
MT[, lapply(.SD, \(x) list(mean_mpg = mean(x), sd_mpg = sd(x))) |> rbindlist(), keyby = cyl, .SDcols = "mpg"]

MT[, lapply(.(mpg), \(x) list(mean_mpg = mean(x), sd_mpg = sd(x))) |> rbindlist(), keyby = cyl]
```


**Obtaining multiple summary statistics on multiple columns (as rows):**

```{r}
MT[, lapply(.SD, \(v) c(mean(v), sd(v)))]
```

```{r}
list_of_funs <- list(mean = \(x) mean(x, na.rm = TRUE), sd = \(x) sd(x, na.rm = TRUE))
```

```{r}
MT[, lapply(list_of_funs, \(fun) lapply(.SD, fun)) |> rbindlist()]
```


**Obtaining multiple summary statistics on multiple columns (as columns):**

```{r}
cols <- c("mpg", "cyl")

funs_as_list <- \(x) list(mean = mean(x, na.rm = TRUE), sd = sd(x, na.rm = TRUE))
```

:::{.callout-warning}
`dplyr` & `data.table` don't use the same "format" when pre-defining a list of function to be applied:  
- `dplyr` needs a list of individual functions  
- `data.table` needs a function returning a list  
:::

```{r}
mtcars |> group_by(gear) |> summarize(across(cols, .fns = list_of_funs, .names = "{.col}.{.fn}"))

MT[, lapply(.SD, funs_as_list) |> unlist(recursive = FALSE), keyby = gear, .SDcols = cols]

MT[, lapply(.SD, funs_as_list) |> do.call(c, args = _), keyby = gear, .SDcols = cols]
```

Different column order & naming scheme:

:::{.callout-tip}
Here we can use the `list_of_funs` with `data.table` since we apply them individually.
:::

```{r}
MT[, lapply(list_of_funs, \(f) lapply(.SD, f)) |> do.call(c, args = _), keyby = gear, .SDcols = cols]
```

Using `dcast` (see next section):

```{r}
dcast(MT, gear ~ ., fun.aggregate = list(mean, sd), value.var = cols)
```



<!-------------------------------------------------------->
<!-------------------------------------------------------->
# Pivots:
***

<!-------------------------------------------------------->
## Melt / Longer:

**Data:**

```{r}
#| echo: false
#| output: false

fam1 <- "
family_id age_mother dob_child1 dob_child2 dob_child3
1         30 1998-11-26 2000-01-29         NA
2         27 1996-06-22         NA         NA
3         26 2002-07-11 2004-04-05 2007-09-02
4         32 2004-10-10 2009-08-27 2012-07-21
5         29 2000-12-05 2005-02-28         NA
"

FAM1 <- fread(fam1)
```

```{r}
FAM1
```

```{r}
#| echo: false
#| output: false

fam2 <- "
family_id age_mother dob_child1 dob_child2 dob_child3 gender_child1 gender_child2 gender_child3
1         30 1998-11-26 2000-01-29         NA             1             2            NA
2         27 1996-06-22         NA         NA             2            NA            NA
3         26 2002-07-11 2004-04-05 2007-09-02             2             2             1
4         32 2004-10-10 2009-08-27 2012-07-21             1             1             1
5         29 2000-12-05 2005-02-28         NA             2             1            NA
"

FAM2 <- fread(fam2)
```

```{r}
FAM2
```

**One group of columns --> single value column**

```{r}
FAM1 |> pivot_longer(cols = matches("dob_"), names_to = "variable")

FAM1 |> melt(measure.vars = c("dob_child1", "dob_child2", "dob_child3"))
FAM1 |> melt(measure.vars = patterns("^dob_"))
```


**One group of columns --> multiple value columns**

```{r}
FAM1 |> melt(measure.vars = patterns(child1 = "child1$", child2 = "child2$|child3$"))
```


### Merging multiple yes/no columns:

Melting multiple presence/absence columns into a single variable:

```{r}
#| echo: false
#| output: false

movies_wide <- tibble(
  ID = 1:3,
  action = c(1,1,1),
  adventure = c(0,1,1),
  animation = c(0,0,1)
)

MOVIES_WIDE <- as.data.table(movies_wide)
```

```{r}
movies_wide
```

```{r}
pivot_longer(
    movies_wide, -ID, names_to = "Genre", 
    values_transform = \(x) ifelse(x == 0, NA, x), values_drop_na = TRUE
  ) |> select(-value)
```

```{r}
melt(MOVIES_WIDE, id.vars = "ID", variable.name = "Genre")[value != 0][order(ID), -"value"]
```

### Partial pivot:

Multiple groups of columns --> Multiple value columns

**Manually:**

```{r}
colA <- str_subset(colnames(FAM2), "^dob")
colB <- str_subset(colnames(FAM2), "^gender")

FAM2 |> melt(measure.vars = list(colA, colB), value.name = c("dob", "gender"), variable.name = "child")
```

```{r}
FAM2 |> melt(measure.vars = list(a, b), value.name = c("dob", "gender"), variable.name = "child") |> 
  substitute2(env = list(a = I(str_subset(colnames(FAM2), "^dob")), b = I(str_subset(colnames(FAM2), "^gender")))) |> eval()
```


**Using `.value`:**

:::{.callout-tip}
Using the `.value` special identifier allows to do a "half" pivot: the values that would be listed as rows under `.value` are instead used as columns.
:::

```{r}
FAM2 |> pivot_longer(cols = matches("^dob|^gender"), names_to = c(".value", "child"), names_sep = "_child")

FAM2 |> melt(measure.vars = patterns("^dob", "^gender"), value.name = c("dob", "gender"), variable.name = "child")
```

**Using `measure` and `value.name`:**

:::{.callout-warning}
`data.table` only
:::

```{r}
FAM2 |> melt(measure.vars = measure(value.name, child = \(x) as.integer(x), sep = "_child"))

FAM2 |> melt(measure.vars = measurev(list(value.name = NULL, child = as.integer), pattern = "(.*)_child(\\d{1})"))
```


<!-------------------------------------------------------->
## Dcast / Wider:

**General idea:**  
- Pivot around the combination of `id.vars` (LHS of the formula)  
- The `measure.vars` (RHS of the formula) are the ones whose values become column names  
- The `value.var` are the ones the values are taken from to fill the new columns


**Data:**

```{r}
(FAM1L <- FAM1 |> melt(measure.vars = c("dob_child1", "dob_child2", "dob_child3")))
(FAM2L <- FAM2 |> melt(measure.vars = measure(value.name, child = \(.x) as.integer(.x), sep = "_child")))
```

**Basic pivot wider:**

```{r}
FAM1L |> pivot_wider(id_cols = c("family_id", "age_mother"), names_from = "variable")

FAM1L |> dcast(family_id + age_mother ~ variable)
```


**Using all the columns as IDs:**

:::{.callout-note}
By default, `id_cols = everything()`
:::

```{r}
FAM1L |> pivot_wider(names_from = variable)
```

:::{.callout-note}
`...` => "every unused column"
:::

```{r}
FAM1L |> dcast(... ~ variable)
```


**Multiple value columns --> Multiple groups of columns:**

```{r}
FAM2L |> pivot_wider(
  id_cols = c("family_id", "age_mother"), values_from = c("dob", "gender"), 
  names_from = "child", names_sep = "_child"
)
```

```{r}
FAM2L |> dcast(family_id + age_mother ~ child, value.var = c("dob", "gender"), sep = "_child")

FAM2L |> dcast(... ~ child, value.var = c("dob", "gender"), sep = "_child")
```


**Dynamic names in the formula:**

```{r}
var_name <- "variable"
```

```{r}
FAM1L |> pivot_wider(id_cols = c(family_id, age_mother), names_from = {{ var_name }})
```

```{r}
FAM1L |> dcast(family_id + age_mother ~ base::get(var_name))

FAM1L |> dcast(family_id + age_mother ~ v1) |> substitute2(env = list(v1 = var_name)) |> eval()
```


Multiple variables:

```{r}
id_vars <- c("family_id", "age_mother")
```

```{r}
FAM1L |> pivot_wider(id_cols = all_of(id_vars), names_from = variable)
```

```{r}
FAM1L |> dcast(str_c(str_c(id_vars, collapse = " + "), " ~ variable"))
```

```{r}
FAM1L |> dcast(v1 + v2 ~ variable) |> substitute2(env = list(v1 = id_vars[1], v2 = id_vars[2])) |> eval()
```


### Renaming (prefix/suffix) the columns:

```{r}
FAM1L |> pivot_wider(names_from = variable, values_from = value, names_prefix = "Attr: ")

FAM1L |> pivot_wider(names_from = variable, values_from = value, names_glue = "Attr: {variable}")
```

```{r}
FAM1L |> dcast(family_id + age_mother ~ paste0("Attr: ", variable))
```


### Unused combinations:

:::{.callout-warning}
The logic is inverted between `dplyr` (keep) and `data.table` (drop)
:::

```{r}
FAM1L |> pivot_wider(names_from = variable, values_from = value, id_expand = TRUE, names_expand = FALSE) # (keep_id, keep_names)

FAM1L |> dcast(family_id + age_mother ~ variable, drop = c(F, T)) # (drop_LHS, drop_RHS)
```


### Subsetting:

:::{.callout-note}
AFAIK, `pivot_wider` can't do this on it's own.
:::

```{r}
FAM1L |> filter(value >= lubridate::ymd(20030101)) |> 
  pivot_wider(id_cols = c("family_id", "age_mother"), names_from = "variable")
```

```{r}
FAM1L |> dcast(family_id + age_mother ~ variable, subset = .(value >= lubridate::ymd(20030101)))
```


### Aggregating:

Not specifying the column holding the measure vars (the names) will result in an empty column counting the number of columns that should have been created for all the measures.

```{r}
FAM1L |> dcast(family_id + age_mother ~ .)
```

We can customize that default behavior using the `fun.aggregate` argument:

*Here, we count the number of child for each each combination of (family_id + age_mother) -> sum all non-NA `value`*

```{r}
FAM1L |> pivot_wider(id_cols = c(family_id, age_mother), names_from = variable, values_fn = \(.x) sum(!is.na(.x))) |>
  rowwise() |> mutate(child_count = sum(c_across(matches("_child")))) |> ungroup()

FAM1L |> pivot_wider(id_cols = c(family_id, age_mother), names_from = variable, values_fn = \(.x) sum(!is.na(.x))) |>
  mutate(child_count = apply(select(cur_data(), matches("_child")), 1, \(r) sum(r)))
```

```{r}
(FAM1L |> dcast(family_id + age_mother ~ ., fun.agg = \(.x) sum(!is.na(.x))) |> setnames(".", "child_count"))
```


**Applying multiple `fun.agg`:**

Data:

```{r}
(DTL <- data.table(
  id1 = sample(5, 20, TRUE), 
  id2 = sample(2, 20, TRUE), 
  group = sample(letters[1:2], 20, TRUE), 
  v1 = runif(20), 
  v2 = 1L)
)
```

Multiple `fun.agg` applied to one variable:

```{r}
DTL |> dcast(id1 + id2 ~ group, fun.aggregate = list(sum, mean), value.var = "v1")
```

Multiple `fun.agg` to multiple `value.var` (all combinations):

```{r}
DTL |> dcast(id1 + id2 ~ group, fun.aggregate = list(sum, mean), value.var = c("v1", "v2"))
```

Multiple `fun.agg` and multiple `value.var` (one-to-one):

*Here, we apply `sum` to `v1` (for both `group` a & b), and `mean` to `v2` (for both `group` a & b)*

```{r}
DTL |> dcast(id1 + id2 ~ group, fun.aggregate = list(sum, mean), value.var = list("v1", "v2"))
```


### One-hot encoding:

Making each level of a variable into a presence/absence column:

```{r}
#| echo: false
#| output: false

movies_long <- data.frame(
  ID = c(1L, 2L, 2L, 3L, 3L, 3L), 
  Genre = c("action", "action", "adventure", "action", "adventure", "animation")
)

MOVIES_LONG <- as.data.table(movies_long)
```

```{r}
movies_long
```

```{r}
pivot_wider(
  movies_long, names_from = "Genre", values_from = "Genre", 
  values_fn = \(x) ifelse(is.na(x), 0, 1), values_fill = 0
)
```

```{r}
dcast(
  MOVIES_LONG, ID ~ Genre, value.var = "Genre", 
  fun.agg = \(x) ifelse(is.na(x), 0, 1), fill = 0
)
```


<!-------------------------------------------------------->
<!-------------------------------------------------------->
# Joins:
***

:::{.callout-tip}
In `data.table`, a JOIN is just another type of SUBSET: we subset the rows of one `data.table` with the rows of a second one, based on some conditions that define the type of JOIN.
:::

Matching two tables based on their rows can be done:  
- Either on equivalences (**equi-joins**)  
- Or functions comparing one row to another (**non-equi joins**)


**Data:**

```{r}
(DT1 <- data.table( 
  ID = LETTERS[1:10],
  A = sample(1:5, 10, replace = TRUE),
  B = sample(10:20, 10)
))

(DT2 <- data.table(
  ID = LETTERS[5:14],
  C = sample(1:5, 10, replace = TRUE),
  D = sample(10:20, 10) 
))
```


**Basic (right) join example:**

```{r}
right_join(
  DT1 |> select(ID, A),
  DT2 |> select(ID, C), 
  by = "ID"
) |> as_tibble()

DT1[DT2, .(ID, A, C), on = .(ID)]
```


<!-------------------------------------------------------->
## Outer (right, left):

Appends data of one at the end of the other.

:::{.callout-note}
`data.table` doesn't do left joins natively
:::


**Subsetting DT1 by DT2:**

:::{.callout-note}
DT2 (everything) + DT1 (all columns, but only the rows that match those in DT1).  
  > Looking up DT1's rows using DT2 (or DT2's key, if it has one) as an index.
:::

As a **right join**:

```{r}
right_join(DT1, DT2, by = "ID") # DT1 into DT2

DT1[DT2, on = .(ID)]
```

As a **left join:**

:::{.callout-note}
Not exactly equivalent to the right join: same columns, but DT2 is first instead of DT1
:::

```{r}
left_join(DT2, DT1, by = "ID") # DT1 into DT2

copy(DT2)[DT1, c("A", "B") := list(i.A, i.B), on = .(ID)][]
```


**Subsetting DT2 by DT1:**

:::{.callout-note}
DT1 (everything) + DT2 (all columns, but only the rows that match those in DT1).  
  > Looking up DT2's rows using DT1 (or DT1's key, if it has one) as an index.
:::

As a **right join**:

```{r}
right_join(DT2, DT1, by = "ID") # DT2 into DT1

DT2[DT1, on = .(ID)]
```

As a **left join:**

:::{.callout-note}
Not exactly equivalent to the right join: same columns, but DT1 is first instead of DT2
:::

```{r}
left_join(DT1, DT2, by = "ID") # DT2 into DT1

copy(DT1)[DT2, c("C", "D") := list(i.C, i.D), on = .(ID)][]
```


<!-------------------------------------------------------->
## Full (outer):

```{r}
full_join(DT1, DT2, by = "ID")

data.table::merge.data.table(DT1, DT2, by = "ID", all = TRUE)
```

Alternatively:

```{r}
setkey(DT1, ID)
setkey(DT2, ID)

# Getting the union of the unique keys of both DT
unique_keys <- union(DT1[, ID], DT2[, ID])

DT1[DT2[unique_keys, on = "ID"]]
```


<!-------------------------------------------------------->
## Inner:

**Only returns the ROWS matching both tables:**  
- **Inner**: rows matching both DT1 and DT2, columns of both (add DT2's columns to the right)  
- **Semi**: rows matching both DT1 and DT2, columns of first one  


**Inner:**

```{r}
inner_join(DT1, DT2, by = "ID") 

DT1[DT2, on = .(ID), nomatch = NULL]
```

**Semi:**

```{r}
semi_join(DT1, DT2, by = "ID")

DT1[na.omit(DT1[DT2, on = .(ID), which = TRUE])]
```

:::{.callout-note}
`which = TRUE` returns the row numbers instead of the rows themselves.
:::

<!-------------------------------------------------------->
## Anti:

ROWS of DT1 that are NOT in DT2, and only the columns of DT1.

```{r}
anti_join(DT1, DT2, by = "ID")

DT1[!DT2, on = .(ID)]
```

ROWS of DT2 that are NOT in DT1, and only the columns of DT2.

```{r}
anti_join(DT2, DT1, by = "ID")

DT2[!DT1, on = .(ID)]
```


<!-------------------------------------------------------->
## Non-equi joins:

<!--
See:  
- https://scitilab.com/post_data/non_equi_joins/2020_11_17_non_equi_merge/  
- https://medium.com/analytics-vidhya/r-data-table-joins-48f00b46ce29  
- https://gist.github.com/nacnudus/ef3b22b79164bbf9c0ebafbf558f22a0  
-->

```{r}
DT1[DT2, on = .(ID, A <= C)]
```


<!-------------------------------------------------------->
## Rolling joins:

```{r}
DT1[DT2, on = "ID", roll = TRUE]
```

Inverse the rolling direction:

```{r}
DT1[DT2, on = "ID", roll = -Inf]
```

```{r}
DT1[DT2, on = "ID", rollends = TRUE]
```



<!-------------------------------------------------------->
<!-------------------------------------------------------->
# Tidyr & Others:
***

```{r}
#| echo: false

MT <- as.data.table(mtcars)
IRIS <- as.data.table(iris)[, Species := as.character(Species)]
```

## Remove NA:

```{r}
tidyr::drop_na(IRIS, matches("Sepal"))
```

```{r}
na.omit(IRIS, cols = str_subset(colnames(IRIS), "Sepal"))
```


## Unite:

Combine multiple columns into a single one:

```{r}
mtcars |> tidyr::unite("x", gear, carb, sep = "_")

copy(MT)[, x := paste(gear, carb, sep = "_")][]
```


## Extract / Separate:

Separate a row into multiple columns based on a pattern (`extract`) or a separator (`separate`):

```{r}
MT.ext <- MT[, .(x = str_c(gear, carb, sep = "_"))]
```

```{r}
MT.ext |> tidyr::extract(col = x, into = c("a", "b"), regex = "(.*)_(.*)", remove = F)

MT.ext[, c("a", "b") := tstrsplit(x, "_", fixed = TRUE)][] 
```


## Separate rows:

Separate a row into multiple rows based on a separator:

**Data**

```{r}
(SP <- data.table(
  val = c(1,"2,3",4), 
  date = as.Date(c("2020-01-01", "2020-01-02", "2020-01-03"), origin = "1970-01-01")
  )
)
```

```{r}
SP |> tidyr::separate_rows(val, sep = ",", convert = TRUE)
```

**Solution 1:**

```{r}
copy(SP)[, c(V1 = strsplit(val, ",", fixed = TRUE), .SD), by = val][, `:=`(val = V1, V1 = NULL)][]
```

**Solution 2:**

```{r}
SP[, strsplit(val, ",", fixed = TRUE), by = val][SP, on = "val"][, `:=`(val = V1, V1 = NULL)][]
```

**Solution 3:**

_(With type conversion)_

```{r}
SP[, unlist(tstrsplit(val, ",", type.convert = TRUE)), by = val][SP, on = "val"][, `:=`(val = V1, V1 = NULL)][]
```

**Solution 4:**

```{r}
copy(SP)[rep(1:.N, lengths(strsplit(val, ",")))][, val := strsplit(val, ","), by = val][]
```

```{r}
#| eval: false
#| echo: false

# copy(SP)[rep(1:.N, lengths(strsplit(val, ",")))][, val := unlist(strsplit(SP$val, ","))][]
```

_(With type conversion)_

```{r}
#| eval: false
#| echo: false

# copy(SP)[rep(1:.N, lengths(strsplit(val, ",")))
#   ][, val := utils::type.convert(unlist(strsplit(SP$val, ",")), as.is = T, na.strings = "")][]
```

```{r}
copy(SP)[rep(1:.N, lengths(strsplit(val, ",")))
       ][, val := strsplit(val, ","), by = val
       ][, val := utils::type.convert(val, as.is = T)][]
```



<!-------------------------------------------------------->
## Duplicates:

### Duplicated rows:

**Finding duplicated rows:**

```{r}
mtcars |> group_by(mpg, hp) |> filter(n() > 1)

MT[, if(.N > 1) .SD, by = .(mpg, hp)]
```

**Only keeping non-duplicated rows:**


:::{.callout-note}
This is different from distinct/unique, which will keep one of the duplicated rows of each group.

This removes all groups which have duplicated rows.
:::

Solution 1:

```{r}
mtcars |> group_by(mpg, hp) |> filter(n() == 1)

MT[, if(.N == 1) .SD, by = .(mpg, hp)]
```

Solution 2:

_More convoluted_

```{r}
mtcars |> group_by(mpg, hp) |> filter(n() > 1) |> anti_join(mtcars, y = _)

MT[!MT[, if(.N > 1) .SD, by = .(mpg, hp)], on = names(MT)]

fsetdiff(MT, setcolorder(MT[, if(.N > 1) .SD, by = .(mpg, hp)], names(MT)))
```


### Duplicated values (per row):

```{r}
(DUPED <- data.table(
    A = c("A1", "A2", "B3", "A4"), 
    B = c("B1", "B2", "B3", "B4"), 
    C = c("A1", "C2", "D3", "C4"), 
    D = c("A1", "D2", "D3", "D4")
  )
)
```

```{r}
DUPED |> mutate(Repeats = apply(cur_data(), 1, \(r) r[which(duplicated(r))] |> unique() |> str_c(collapse = ", ")))
```

```{r}
DUPED[, Repeats := apply(.SD, 1, \(r) r[which(duplicated(r))] |> unique() |> str_c(collapse = ", "))][]
```

**With duplication counter:**

```{r}
dup_counts <- function(v) {
  rles <- as.data.table(unclass(rle(v[which(duplicated(v))])))[, lengths := lengths + 1]
  paste(apply(rles, 1, \(r) paste0(r[2], " (", r[1], ")")), collapse = ", ")
}
```

```{r}
DUPED |> mutate(Repeats = apply(cur_data(), 1, \(r) dup_counts(r)))
```

```{r}
DUPED[, Repeats := apply(.SD, 1, \(r) dup_counts(r))][]
```


<!-------------------------------------------------------->
## Expand & Complete:

Here, we are missing an entry for person B on year 2010, that we want to fill:

```{r}
(CAR <- data.table(
    year = c(2010,2011,2012,2013,2014,2015,2011,2012,2013,2014,2015), 
    person = c("A","A","A","A","A","A", "B","B","B","B","B"),
    car = c("BMW", "BMW", "AUDI", "AUDI", "AUDI", "Mercedes", "Citroen","Citroen", "Citroen", "Toyota", "Toyota")
  )
)
```

### Expand:

```{r}
tidyr::expand(CAR, person, year)
```

```{r}
CJ(CAR$person, CAR$year, unique = TRUE)
```


### Complete:

Joins the original dataset with the expanded one:

```{r}
CAR |> tidyr::complete(person, year)
```

```{r}
CAR[CJ(person, year, unique = TRUE), on = .(person, year)]
```


<!-------------------------------------------------------->
## Uncount:

Duplicating aggregated rows to get the un-aggregated version back

**Data**

```{r}
#| echo: false
#| output: false

dat_agg <- fread("
Site Domain Mild Moderate Severe
23     A1    4        0      0
27     A1    0        1      1
28     A1    0        1      0
29     A1    0        0      1
31     A1    0        1      0
33     A1    0        1      1
41     A1    3        0      1
48     A1    0        2      4
64     A1    1        0      0
66     A1    1        0      0
") |> as.data.frame() |> mutate(ID = row_number(), .before = 1)

DAT_AGG <- as.data.table(dat_agg)
```

```{r}
cols <- c("Mild", "Moderate", "Severe")

dat_agg
```

```{r}
dat_agg |> 
  tidyr::pivot_longer(cols = cols, names_to = "Severity", values_to = "Count") |> 
  tidyr::uncount(Count) |> 
  mutate(ID_new = row_number(), .after = "ID") |>
  tidyr::pivot_wider(
    names_from = "Severity", values_from = "Severity", 
    values_fn = \(x) ifelse(is.na(x), 0, 1), values_fill = 0
  )
```

_Solution 1:_

```{r}
(melt(DAT_AGG, measure.vars = cols, variable.name = "Severity", value.name = "Count")
  [rep(1:.N, Count)][, ID_new := .I] |> 
  dcast(... ~ Severity, value.var = "Severity", fun.agg = \(x) ifelse(is.na(x), 0, 1), fill = 0)
)[, -"Count"]
```

_Solution 2:_

```{r}
DAT_AGG[Reduce(`c`, sapply(mget(cols), \(x) rep(1:.N, x)))
      ][, (cols) := lapply(.SD, \(x) ifelse(x > 1, 1, x)), .SDcols = cols
      ][order(ID)]
```


<!-------------------------------------------------------->
## List / Unlist:

When a column contains a simple vector/list of values (of the same type, without structure)

### One listed column:

**Single ID (grouping) column:**

```{r}
(mtcars_list <- mtcars |> group_by(cyl) |> summarize(mpg = list(mpg)) |> ungroup())

(MT_LIST <- MT[, .(mpg = .(mpg)), keyby = cyl])
```

_Solution 1:_

```{r}
mtcars_list |> unnest(mpg)

MT_LIST[, .(mpg = unlist(mpg)), keyby = cyl]
```

_Solution 2:_

Bypasses the need of grouping when unlisting by growing the `data.table` back to its original number of rows before unlisting.

```{r}
MT_LIST[rep(MT_LIST[, .I], lengths(mpg))][, mpg := unlist(MT_LIST$mpg)][]
```


**Multiple ID (grouping) columns:**

```{r}
(mtcars_list2 <- mtcars |> group_by(cyl, gear) |> summarize(mpg = list(mpg)) |> ungroup())

(MT_LIST2 <- MT[, .(mpg = .(mpg)), keyby = .(cyl, gear)])
```

_Solution 1:_

```{r}
mtcars_list2 |> unnest(mpg) # group_by(cyl, gear) is optional

MT_LIST2[, .(mpg = unlist(mpg)), by = setdiff(names(MT_LIST2), 'mpg')]
```

_Solution 2:_

_Same as with one grouping column_

```{r}
MT_LIST2[rep(MT_LIST2[, .I], lengths(mpg))][, mpg := unlist(MT_LIST2$mpg)][]
```


### Multiple listed column:

Creating the data:

```{r}
(mtcars_list_mult <- mtcars |> group_by(cyl, gear) |> summarize(across(c(mpg, disp), \(c) list(c))) |> ungroup())

(MT_LIST_MULT <- MT[, lapply(.SD, \(c) .(c)), keyby = .(cyl, gear), .SDcols = c("mpg", "disp")])
```

_Solution 1:_

```{r}
mtcars_list_mult |> unnest(c(mpg, disp)) # group_by(cyl, gear) is optional

MT_LIST_MULT[, lapply(.SD, \(c) unlist(c)), by = setdiff(names(MT_LIST_MULT), c("mpg", "disp"))]
```


<!-------------------------------------------------------->
## Nest / Unnest:

When a column contains a data.table/data.frame (with multiple columns, structured)

### One nested column:

**Nesting**

```{r}
(mtcars_nest <- mtcars |> tidyr::nest(data = -cyl)) # Data is inside a tibble
```

```{r}
#| eval: false

mtcars_nest <- mtcars |> nest_by(cyl) |> ungroup() # Data is inside a vctrs_list_of
```

```{r}
(MT_NEST <- MT[, .(data = .(.SD)), keyby = cyl])
```


**Unnesting**

```{r}
mtcars_nest |> unnest(data) |> ungroup()

MT_NEST[, rbindlist(data), keyby = cyl]
# MT_NEST[, do.call(c, data), keyby = cyl]
```


### Multiple nested column:

**Nesting:**

```{r}
(mtcars_nest_mult <- mtcars |> group_by(cyl, gear) |> nest(data1 = c(mpg, hp), data2 = !c(cyl, gear, mpg, hp)) |> ungroup())

(MT_NEST_MULT <- MT[, .(data1 = .(.SD[, .(mpg, hp)]), data2 = .(.SD[, !c("mpg", "hp")])), keyby = .(cyl, gear)])
```

**Unnesting:**

```{r}
mtcars_nest_mult |> unnest(c(data1, data2)) |> ungroup()

MT_NEST_MULT[, c(rbindlist(data1), rbindlist(data2)), keyby = .(cyl, gear)]

MT_NEST_MULT[, do.call(c, unname(lapply(.SD, \(c) rbindlist(c)))), .SDcols = patterns('data'), keyby = .(cyl, gear)]
```


### Operate on nested/list columns:

```{r}
(mtcars_nest <- mtcars |> nest(-cyl) |> ungroup())

(MT_NEST <- MT[, .(data = .(.SD)), keyby = cyl])
```

**Creating a new column using the nested data:**

Keeping the nested column:

```{r}
mtcars_nest |> group_by(cyl) |> mutate(sum = sum(unlist(data))) |> ungroup()

copy(MT_NEST)[, sum := sapply(data, \(r) sum(r)), keyby = cyl][]
```

Dropping the nested column:

```{r}
mtcars_nest |> group_by(cyl) |> summarize(sum = sum(unlist(data))) |> ungroup()

MT_NEST[, .(sum = sapply(data, \(r) sum(r))), keyby = cyl]
```

**Creating multiple new columns using the nested data:**

```{r}
linreg <- \(data) lm(mpg ~ hp, data = data) |> broom::tidy()
```

```{r}
mtcars_nest |> group_by(cyl) |> group_modify(\(d, g) linreg(unnest(d, everything()))) |> ungroup()

MT_NEST[, rbindlist(lapply(data, \(ndt) linreg(ndt))), keyby = cyl][]
```


**Operating inside the nested data:**

```{r}
mtcars_nest |> 
  mutate(data = map(data, \(tibl) mutate(tibl, sum = purrr::pmap_dbl(cur_data(), sum)))) |> 
  unnest(data)
```

```{r}
mtcars_nest |> 
  mutate(across(data, \(tibls) map(tibls, \(tibl) mutate(tibl, sum = apply(cur_data(), 1, sum))))) |> 
  unnest(data)
```

Using the [`nplyr`](https://markjrieke.github.io/nplyr/index.html) package:

```{r}
library(nplyr)

mtcars_nest |> 
  nplyr::nest_mutate(data, sum = apply(cur_data(), 1, sum)) |> 
  unnest(data)
```

```{r}
copy(MT_NEST)[, data := lapply(data, \(dt) dt[, sum := apply(.SD, 1, sum)])
            ][, rbindlist(data), keyby = cyl]
```


<!-------------------------------------------------------->
## Rotate / Transpose:

```{r}
(MT_SUMMARY <- MT[, tidy(summary(mpg)), by = cyl])
```

**Solution 1:**

Using pivots to fully rotate the data.table:

```{r}
MT_SUMMARY |> 
  pivot_longer(!cyl, names_to = "Statistic") |> 
  pivot_wider(id_cols = "Statistic", names_from = "cyl", names_prefix = "Cyl ")
```

```{r}
MT_SUMMARY |> 
  melt(id.vars = "cyl", variable.name = "Statistic") |> 
  dcast(Statistic ~ paste0("Cyl ", cyl))
```

**Solution 2:**

Using a dedicated function:

:::{.callout-note}
AFAIK there is no native Tidyverse function to do this.
:::

```{r}
library(datawizard)

datawizard::data_rotate(MT_SUMMARY, colnames = TRUE, rownames = "Statistic")
```

```{r}
data.table::transpose(MT_SUMMARY, keep.names = "Statistic", make.names = 1)
```



<!-------------------------------------------------------->
<!-------------------------------------------------------->
# Processing examples:
***

Examples of interesting tasks that I've collected over time.

<!-------------------------------------------------------->
## Find minimum in each group:

```{r}
MT |> group_by(cyl) |> arrange(mpg) |> slice(1) |> ungroup()
```

```{r}
MT[, .SD[which.min(mpg)], keyby = cyl]
```


<!-------------------------------------------------------->
## GROUP > FILTER > MUTATE

**Data:**

```{r}
(DAT <- structure(list(
  id = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), 
  name = c("Jane", "Jane", "Jane", "Jane", "Jane", "Jane", "Jane", "Jane", "Bob", "Bob", "Bob", "Bob", "Bob", "Bob", "Bob", "Bob"), 
  year = c(1980L, 1981L, 1982L, 1983L, 1984L, 1985L, 1986L, 1987L, 1985L, 1986L, 1987L, 1988L, 1989L, 1990L, 1991L, 1992L), 
  job = c("Manager", "Manager", "Manager", "Manager", "Manager", "Manager", "Boss", "Boss", "Manager", "Manager", "Manager", "Boss", "Boss", "Boss", "Boss", "Boss"), 
  job2 = c(1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L)
  ), 
  .Names = c("id", "name", "year", "job", "job2"), 
  class = "data.frame", 
  row.names = c(NA, -16L)
) |> setDT())
```

**`Tidyverse`:**

```{r}
DAT |> group_by(name, job) |> 
  filter(job != "Boss" | year == min(year)) |> 
  mutate(cumu_job2 = cumsum(job2)) |> 
  ungroup()
```

:::{.callout-note}
Here, the grouping is done BEFORE the filter -> there will be empty groups, meaning they will sum to 0
:::

**`data.table`:**

Solution 1:

```{r}
DAT[ , .SD[job != "Boss" | year == min(year), .(cumu_job2 = cumsum(job2))], by = .(name, job)]
```

Solution 2:

```{r}
DAT[ , .(cum_job2 = cumsum(job2[job != "Boss" | year == min(year)])), by = .(name, job)]
```

Solution 3:

```{r}
DAT[
    DAT[, .I[job != "Boss" | year == min(year)], by = .(name, job)]$V1 # Row indices
  ][
    , cumu_job2 := cumsum(job2), by = .(name, job)
  ][]
```

**If we filtered after the grouping:**

```{r}
DAT[job != "Boss" | year == min(year), list(cumu_job2 = cumsum(job2)), by = .(name, job)]
```


<!-------------------------------------------------------->
## GROUP > SUMMARIZE > JOIN > MUTATE

**Data:**

```{r}
(GSJM1 <- data.table(x = c(1,1,1,1,2,2,2,2), y = c("a", "a", "b", "b"), z = 1:8, key = c("x", "y")))
(GSJM2 <- data.table(x = 1:2, y = c("a", "b"), mul = 4:3, key = c("x", "y")))
```

**`Tidyverse`:**

```{r}
as.data.frame(GSJM1) |> 
  group_by(x, y) |>
  summarise(z = sum(z)) |>
  ungroup() |> 
  right_join(GSJM2) |>
  mutate(z = z * mul) |> 
  select(-mul)
```

**`data.table`:**

Basic:

```{r}
GSJM1[, .(z = sum(z)), by = .(x, y)][GSJM2][, `:=`(z = z * mul, mul = NULL)][]
```

Advanced (using `.EACHI`):

<!-- See: https://stackoverflow.com/questions/27004002/eachi-in-data-table/27004566#27004566 -->

```{r}
GSJM1[GSJM2, .(z = sum(z) * mul), by = .EACHI]
```


<!-------------------------------------------------------->
## Separating rows & cleaning text:

**Data**

```{r}
(DT_COMA <- data.table(
  first = c(1,"2,3",3,4,5,6.5,7,8,9,0), 
  second = c(1,"2,,5",3,4,5,"6,5,9",7,8,9,0), 
  third = c("one", "two", "thr,ee", "four", "five", "six", "sev,en", "eight", "nine", "zero"), 
  fourth = as.Date(c(1/1/2020, 2/1/2020, 3/1/2020, 4/1/2020, 5/1/2020, 6/1/2020, 7/1/2020, 8/1/2020, 9/1/2020, 10/1/2020), origin = "1970-01-01")
  )
)
```

### Step1: Cleaning

Removing unwanted commas within words

**`Tidyverse`:**

```{r}
DT_COMA |> mutate(across(where(\(v) is.character(v) & all(is.na(as.numeric(v)))), \(v) stringr::str_remove_all(v, ",")))
```

**`data.table`:**

```{r}
cols_to_clean <- DT_COMA[, .SD, .SDcols = \(v) is.character(v) & all(is.na(as.numeric(v)))] |> colnames()

copy(DT_COMA)[, c(cols_to_clean) := purrr::map(.SD[, cols_to_clean, with = F], \(v) stringr::str_remove_all(v, ","))][]
```


### Step 2: Separating rows

Each numeric row that has multiple comma-separated values has to be split into multiple rows (one value per row)

**`Tidyverse`:**

```{r}
cols_to_separate <- DT_COMA |> select(where(\(v) is.character(v) & any(!is.na(as.numeric(v))))) |> colnames()

purrr::reduce(
  cols_to_separate, 
  \(acc, col) acc |> tidyr::separate_rows(col, sep = ",", convert = T), 
  .init = DT_COMA
)
```

**`data.table`:**

```{r}
cols_to_separate <- DT_COMA[, .SD, .SDcols = \(v) is.character(v) & any(!is.na(as.numeric(v)))] |> colnames()

(purrr::reduce(
  cols_to_separate,
  \(acc, col) acc[rep(1:.N, lengths(strsplit(get(col), ",")))][, (col) := type.convert(unlist(strsplit(acc[[col]], ",", fixed = T)), as.is = T, na.strings = "")],
  .init = DT_COMA
))[]
```


### Combining both steps:

**`Tidyverse`:**

```{r}
DT_COMA <- DT_COMA |> mutate(across(where(\(v) is.character(v) & all(is.na(as.numeric(v)))), \(v) stringr::str_remove_all(v, ",")))

purrr::reduce(
  select(DT_COMA, where(\(v) is.character(v) & any(!is.na(as.numeric(v))))) |> colnames(), 
  \(acc, col) acc |> tidyr::separate_rows(col, sep = ",", convert = T), 
  .init = DT_COMA
)
```

**`data.table`:**

```{r}
cols_to_clean <- DT_COMA[, .SD, .SDcols = \(v) is.character(v) & all(is.na(as.numeric(v)))] |> colnames()
cols_to_separate <- DT_COMA[, .SD, .SDcols = \(v) is.character(v) & any(!is.na(as.numeric(v)))] |> colnames()

DT_COMA[, c(cols_to_clean) := purrr::map(.SD[, cols_to_clean, with = F], \(v) stringr::str_remove_all(v, ","))]

(purrr::reduce(
  cols_to_separate,
  \(acc, col) acc[rep(1:.N, lengths(strsplit(get(col), ",")))][, (col) := type.convert(unlist(strsplit(acc[[col]], ",", fixed = T)), as.is = T, na.strings = "")],
  .init = DT_COMA
))[]
```


<!-------------------------------------------------------->
## Multiple choice questions:

**Data:**

```{r}
#| echo: false
#| output: false

surv <- data.frame(
  ID = c(1:5),
  response = c(
    "I read the assigned readings.|I reread my notes.|I worked with one or more classmates.",
    "I read the assigned readings.|I reviewed this week's slides.",
    "I worked on practice problems.|I read the assigned readings.|I reread my notes.",
    "I worked on practice problems.|I read the assigned readings.|I reread my notes.",
    "I worked on practice problems.|I read the assigned readings.|I reread my notes.|I reviewed this week's slides.|I worked with one or more classmates."
  )
)

SURV <- as.data.table(surv)
```

```{r}
surv
```

Here we will spread the answers into their own columns using a pivot because not all rows have all the possible answers:

**`Tidyverse`:**

```{r}
surv |> 
  mutate(response = str_split(response, fixed("|"))) |> 
  unnest(response) |> 
  pivot_wider(id_cols = ID, names_from = response, values_from = response, values_fn = \(.x) sum(!is.na(.x)), values_fill = 0)
```

**`data.table`:**

```{r}
SURV[, c(.SD, tstrsplit(response, "|", fixed = T))][, -"response"] |> 
  melt(measure.vars = patterns("^V")) |> 
  dcast(ID ~ value, fun.agg = \(.x) sum(!is.na(.x)), subset = .(!is.na(value)))
```


<!-------------------------------------------------------->
## Filling with lagging conditions:

**Task:** See [this SO question](https://stackoverflow.com/questions/71952593/filling-rows-of-multiple-columns-based-on-multiple-conditions).

**Data:**

```{r}
ZIP <- structure(
  list(
    zipcode = c(1001, 1002, 1003, 1004, 1101, 1102, 1103, 1104, 1201, 1202, 1203, 1302), 
    areacode = c(4, 4, NA, 4, 4, 4, NA, 1, 4, 4, NA, 4), 
    type = structure(c(1L, 1L, NA, 1L, 2L, 2L, NA, 1L, 1L, 1L, NA, 1L), .Label = c("clay", "sand"), class = "factor"), 
    region = c(3, 3, NA, 3, 3, 3, NA, 3, 3, 3, NA, 3), 
    do_not_fill = c(1, NA, NA, 1, 1, NA, NA, 1, NA, NA, NA, 1)
    ), 
  class = c("data.table", "data.frame"), row.names = c(NA, -4L)
)
```

**`Tidyverse`:**

```{r}
as_tibble(ZIP) |>
  mutate(type = as.character(type)) |>
  mutate(
    across(1:4, ~ ifelse(
        is.na(.) & lag(areacode) == lead(areacode) & 
          lag(as.numeric(substr(zipcode, 1, 2))) == lead(as.numeric(substr(zipcode, 1, 2))),
        lag(.), .
      )
    )
  )
```

**`data.table`:**

```{r}
ZIP[, c(lapply(.SD, \(v) {fifelse(
  is.na(areacode) & lag(areacode) == lead(areacode) &
    lag(as.numeric(substr(zipcode, 1, 2))) == lead(as.numeric(substr(zipcode, 1, 2))), lag(v), v)}), 
  .SD[, .(do_not_fill)]), .SDcols = !patterns("do_not_fill")]
```


<!-------------------------------------------------------->
## Join + Coalesce:

**Task:** Replace the missing dates from one dataset with the earliest date from another dataset, matching by ID:

**Data:**

```{r}
(dt1 <- data.table::fread(
"
      id  x       y   z         
     1    A       1    NA        
     2    C       3    NA        
     3    C       3    NA        
     4    C       2    NA        
     5    B       2    2019-08-04
     6    C       1    2019-09-18
     7    B       3    2019-12-17
     8    A       2    2019-11-02
     9    A       3    2020-03-16
    10    A       1    2020-01-31
"
))

(dt2 <- data.table::fread(
"      id      date
      1      2012-09-25
      1      2012-03-26
      1      2012-11-12
      2      2013-01-24
      2      2012-05-04
      2      2012-02-24
      3      2012-05-30
      3      2012-02-15
      4      2012-03-13
      4      2012-05-18
"))
```

**`Tidyverse`:**

Using `coalesce`:

```{r}
left_join(
  dt1, 
  dt2 |> group_by(id) |> summarize(date = min(date)), 
  by = "id"
) |> mutate(date = coalesce(z, date), z = NULL)
```

Using the [`rows_*` functions](https://dplyr.tidyverse.org/reference/rows.html):

```{r}
dplyr::rows_patch(
  dt1 |> rename(date = z), 
  dt2 |> group_by(id) |> summarize(date = min(date)), 
  by = "id"
)
```

**`data.table`:**

As a right join:

```{r}
copy(dt2)[, .(date = min(date)), by = id
  ][dt1, on = "id"][, `:=`(date = fcoalesce(date, z), z = NULL)][]
```

As a left join:

```{r}
copy(dt1)[dt2[, .(date = min(date)), by = id], c("id", "date") := .(i.id, i.date), on = "id"
  ][, `:=`(date = fcoalesce(date, z), z = NULL)][]
```


<!-------------------------------------------------------->
## Join on multiple columns (partial matching):

**Task:** Join both tables based on matching IDs, but the IDs are split between multiple columns in one table (`id1` & `id2`).

```{r}
(dt1 <- data.table(id = c("ABC", "AAA", "CBC"), x = 1:3))

(dt2 <- data.table(
  id1 = c("ABC", "AA", "CB"), 
  id2 = c("AB", "AAA", "CBC"), 
  y = c(0.307, 0.144, 0.786))
)
```

**Solution 1:**

Combine the two ID columns into one with `pivot_longer`, then join:

```{r}
dt2 |> pivot_longer(matches("^id"), names_to = NULL, values_to = "id") |> right_join(dt1)
```

```{r}
melt(dt2, measure.vars = patterns("^id"), value.name = "id")[, variable := NULL][dt1, on = "id"]
```


**Solution 2:**

Combine the two ID columns into one with `unite` + `separate_rows`, then join:

_(From [@TimTeaFan](https://twitter.com/TimTeaFan/status/1534492468787421187)_

```{r}
dt2 |> unite("id", id1, id2, sep = "_") |> separate_rows("id") |> right_join(dt1)
```

```{r}
copy(dt2)[, id := paste(id1, id2, sep = "_")
        ][, c(V1 = strsplit(id, "_", fixed = TRUE), .SD), by = id
        ][, `:=`(id = V1, V1 = NULL, id1 = NULL, id2 = NULL)
        ][dt1, on = "id"]
```


**Solution 3:**

Join on one of the two columns (`id2` here), and then fill in (patch) the missing values:

```{r}
left_join(dt2, dt1, by = c("id2" = "id")) |> 
  rows_patch(rename(dt1, id1 = id), unmatched = "ignore")
```


## Merging rows across multiple columns (every X rows):

**Data:**

```{r}
(BANK <- data.table(
    date = c("30 feb", "NA", "NA", "NA", "31 feb", "NA", "NA", "NA"), 
    description = c("Mary", "had a", "little", "lamb", "Twinkle", "twinkle", "little", "star"), 
    withdrawal = c("100", "NA", "NA", "NA", "NA", "NA", "NA", "NA"), 
    deposit = c("NA", "NA", "NA", "NA", "100", "NA", "NA", "NA")
  )[, lapply(.SD, \(c) utils::type.convert(c, as.is = T))]
)
```

```{r}
merge_and_convert <- function(v) {
  utils::type.convert(v, as.is = T) |> na.omit() |> 
    paste(collapse = " ") |> utils::type.convert(as.is = T) |> 
    bind(x, ifelse(is.logical(x), as.integer(x), x))
}
```

**`Tidyverse`:**

Solution 1:

```{r}
mutate(BANK, ID = ceiling(seq_along(row_number())/4)) |> 
  group_by(ID) |> 
  summarize(across(everything(), \(m) merge_and_convert(m)))
```

Solution 2:

```{r}
summarize(BANK, across(
  everything(), 
  \(c) sapply(split(c, ceiling(seq_along(c)/4)), \(m) merge_and_convert(m))
))
```

**`data.table`:**

```{r}
BANK[, lapply(.SD, \(c) sapply(split(c, ceiling(seq_along(c)/4)), \(m) merge_and_convert(m)))]
```


```{r}
copy(BANK)[, ID := ceiling(seq_along(.I)/4)][, lapply(.SD, \(m) merge_and_convert(m)), by = ID][]
```


<!-------------------------------------------------------->
## Tagging successive events:

Tagging repeated blocks of events (aka _run length encoding_):

```{r}
(DAT <- data.table(event = c(
  rep("A", 3),
  rep("B", 5),
  rep("C", 2),
  rep("B", 2),
  rep("A", 3)
)))
```

```{r}
DAT |> mutate(ID = with(rle(event), rep(seq_along(lengths), lengths)))

DAT |> mutate(ID = c(0, cumsum(diff(as.integer(factor(event))) != 0)) + 1)
```

Using data.table's `rleid()` function:

```{r}
DAT |> mutate(ID = data.table::rleid(event))
```

```{r}
copy(DAT)[, ID := rleid(event)][]
```


<!-------------------------------------------------------->
<!-------------------------------------------------------->
# Miscellaneous:
***

<!-------------------------------------------------------->
## Keywords:

.SD  
.I, .N  
.GRP, .NGRP  
.BY  
.EACHI  

<!-------------------------------------------------------->
## Useful functions:

`fsetdiff`, `fintersect`, `funion` and `fsetequal` (apply to data.tables instead of vectors)

`nafill`, `fcoalesce`

`as.IDate`

***

![](http://vignette2.wikia.nocookie.net/creepypasta/images/1/11/Thats_all_folks.svg.png)