---
title: "Tidyverse <-> data.table"
subtitle: "Equivalence between `Tidyverse` and `data.table` expressions"

author:
  name: "Marc-Aurèle Rivière"
  orcid: 0000-0002-5108-3382

date: 2022-05-19

abstract: "This document is a collection of notes I took while learning to use `data.table`, summarizing the equivalences between most `dplyr`/`tidyr` verbs and `data.table`."

website:
  open-graph:
    description: "A collection of notes illustrating the equivalences between most Tidyverse & data.table verbs"
  twitter-card:
    description: "A collection of notes illustrating the equivalences between most Tidyverse & data.table verbs"

categories:
  - "Data Manipulation"
  - "Tidyverse"
  - "data.table"
  - "R"

format:
  html:
    code-summary: "Alternatives"
    code-tools:
      source: true
      toggle: false

execute: 
  output: asis
---

<hr style="margin-bottom: 30px; margin-top: -12px">

:::{.callout-tip collapse="true"}

# Expand for Version History

- **V1:** 2022-05-19  
- **V2:** 2022-05-26   
  - Improved the section on **keys** (for ordering & filtering)  
  - Adding a [section](#tidyr-others) for translations of `Tidyr` (and other similar packages)      
  - Capping tables to display 15 rows max when unfolded  
  - Improving table display (stripping, hiding the contents of nested columns, ...)
- **V3:** 2022-07-20
  - Updating `data.table`'s examples of dynamic programming using [`env`](https://rdatatable.gitlab.io/data.table/articles/datatable-programming.html)  
  - Added new entries in [processing examples](#processing-examples)  
  - Added new entries to [Tidyr & Others](#tidyr-others): expand + complete, transpose/rotation, ...  
  - Added `pivot_wider` examples to match the `dcast` ones in the [Pivots](#pivots) section  
  - Added some new examples here and there across the [Basic Operations](#basic-operations) section  
  - Added an entry for operating inside nested data.frames/data.tables  
  - Added a processing example for run-length encoding (i.e. successive event tagging)
- **V4:** 2022-08-05
  - Improved `pivot` section: example of one-hot encoding (and reverse operation) + better examples of partial pivots with `.value`  
  - Added `tidyr::uncount()` (row duplication) example  
  - Improved both light & dark themes (code highlight, tables, ...)
- **V5:** 2022-10-15
  - Grouped the tabsets by framework  
  - Revamped the whole [Basic Operations](#basic-operations) section (better structure, reworked examples, ...)  
    - Updated `Tidyverse` examples to `dplyr` 1.1.0 & added examples of new functions & arguments (e.g. `consecutive_id`, ...)  
    - Updated `data.table` examples to version 1.14.5 & added examples of new functions & arguments (e.g. `let`, `DT()`, ...)
:::

```{r}
#| echo: false
#| eval: false
#| output: false

# TODO:

## See: https://atrebas.github.io/post/2019-03-03-datatable-dplyr/

# ----------------------------------------------------------

## New purrr:
### - list_rbind / list_cbind / list_c <--> rbindlist / do.call(c, ...)
### - map_dfr -> map() |> list_rbind() ????
### - pmap_vec instead of pmap + as.vector ???

### setcolorder(before = NULL, after = NULL) 

### tstrsplit: https://github.com/Rdatatable/data.table/issues/5094

### shift(x, 1, type = "cyclic") -> pushes last value as first one

## Time methods (eq to lubridate): https://rdatatable.gitlab.io/data.table/reference/IDateTime.html

## nafill(x, type = c("const", "locf", "nocb"))
### - locf: last observation carried forward
### - nocb: Next observation carried backward

# ----------------------------------------------------------

## Pivots:
### - melt(): New "variable_table" type in measure.vars = measure()
#### See: https://github.com/Rdatatable/data.table/issues/3396#issuecomment-704675464

## Rework JOINS
### See: https://r4ds.had.co.nz/relational-data.html#filtering-joins
### Create example dataset (see https://duckdb.org/2022/05/27/iejoin.html)
### - New dplyr::join_by() argument for joins -> non-equi, rolling, ...
### - Overlap join example (value -1+1)
### - Cross-joins: CJ & full_join(x, x, by = character()) or full_join(x, x, by = join_by())
### - Rework .EACHI example (and add to joins) --> by = .EACHI == by = .I for both tables ?!!?
### - frollmean() frollsum() frollapply()

## dplyr:
### - group_map/modify/walk: DAT[, .(data = .(.SD)), by = group][, func(data[[1]]), by = group]
### - groups/group_data/group_sizes/group_indices/group_vars/n_groups
### - split() vs group_split()
### - nest_join()
### - with_order()

## tidyr:
### - Nesting with grouping variable inside: DAT[, .(data = list(data.table(group, .SD))), by = group]
### - tidyr::unnest_wider/longer ?

## groupingsets & rollup
```

<!------------------------------------------------------------------------------>
<!------------------------------------------------------------------------------>
# Setup {.unnumbered}
***

```{r}
#| echo: false
#| output: false

source(here::here("src", "init_min.R"), echo = FALSE)

config <- config::get(file = here("_config.yml"))
```

```{r}
#| echo: false
#| eval: false

renv::install(
  c(
    "here",
    "Rdatatable/data.table",
    "Tidyverse/dplyr",
    "tidyr",
    "pipebind",
    "stringr",
    "Tidyverse/purrr",
    "lubridate",
    "broom",
    "nplyr",
    "datawizard"
  )
)
```

```{r}
library(here)        # Project management

library(data.table)  # Data wrangling (>= 1.14.5)
library(dplyr)       # Data wrangling (>= 1.1.0)
library(tidyr)       # Data wrangling (extras) (>= 1.2.1)
library(pipebind)    # Piping goodies (>= 0.1.1)

library(stringr)     # Manipulating strings
library(purrr)       # Manipulating lists
library(lubridate)   # Manipulating dates

library(broom)

data.table::setDTthreads(parallel::detectCores(logical = TRUE))
```

:::{.callout-tip collapse="true"}

# Expand for Session Info

```{r}
#| echo: false
#| results: markup

si <- sessioninfo::session_info(pkgs = "attached")

si$platform$Quarto <- system("quarto --version", intern = TRUE)

si$platform$pandoc <- strsplit(si$platform$pandoc, "@")[[1]][1]

si
```

:::

```{r}
#| echo: false

## This section is for the html output (code-linking, ...)

library(knitr)
library(quarto)
library(downlit)
library(xml2)
library(withr)
```

```{css, echo=FALSE}
.panel-tabset > .tab-content {
  display: flex;
}

.panel-tabset > .tab-content > .tab-pane {
  display: block !important;
  visibility: hidden;
  margin-right: -100%;
  width: 100%;
}

.panel-tabset > .tab-content > .active {
  visibility: visible;
}
```

```{r}
#| echo: false
#| output: false
#| file: !expr here("src", "common", "knitr", "knit_print_gt_mono.R")
```

<!-------------------------------------------------------->
<!-------------------------------------------------------->
# Basic Operations
***

:::{.callout-tip}

## `data.table` general syntax

DT[`row selector` (filter/sort), `col selector` (select/mutate/summarize/rename), `modifiers` (group)]
:::

**Data**

```{r}
MT <- as.data.table(mtcars)
IRIS <- as.data.table(iris)[, Species := as.character(Species)]
```


<!-------------------------------------------------------->
## Arrange / Order

### Basic ordering

::: {.panel-tabset group="framework"}

##### Tidyverse

```{r}
mtcars |> arrange(desc(cyl))
```

```{r}
mtcars |> arrange(desc(cyl), gear)
```

##### data.table

```{r}
MT[order(-cyl)]
```

```{r}
MT[order(-cyl, gear)]
```

```{r}
#| eval: false
#| code-fold: true

MT[fsort(cyl, decreasing = TRUE)]

setorder(MT, -cyl, gear)[]

setorderv(MT, c("cyl", "gear"), c(-1 ,1))[]
```

**Ordering on a character column**

```{r}
IRIS[chorder(Species)]
```

:::

### Ordering with keys

- Keys physically reorders the dataset within the RAM (by reference)  
  - No memory is used for sorting (other than marking which columns is the key)  
- The dataset is marked with an attribute _"sorted"_  
- The dataset is always sorted in _ascending order_, with _NA_ first  
- Using `keyby` instead of `by` when grouping will set the grouping factors as keys

:::{.callout-tip}
See [this SO post](https://stackoverflow.com/questions/20039335/what-is-the-purpose-of-setting-a-key-in-data-table?rq=1) for more information on keys.
:::

```{r}
setkey(MT, cyl, gear)

setkeyv(MT, c("cyl", "gear"))

MT
```

To see over which keys (if any) the dataset is currently ordered:

```{r}
haskey(MT)

key(MT)
```

:::{.callout-warning}
Unless our task involves repeated subsetting on the same column, the speed gain from key-based subsetting could effectively be nullified by the time needed to reorder the data in RAM, especially for large datasets.
:::


### Ordering with (secondary) indices

- `setindex` creates an index for the provided columns, but doesn’t physically reorder the dataset in RAM.  
- It computes the ordering vector of the dataset's rows according to the provided columns in an additional attribute called _index_  


```{r}
#| echo: false

MT <- as.data.table(mtcars)
```


```{r}
setindex(MT, cyl, gear)

setindexv(MT, c("cyl", "gear"))

MT
```

We can see the additional _index_ attribute added to the `data.table`:

```{r}
#| results: markup

names(attributes(MT))
```

We can get the currently used indices with:

```{r}
indices(MT)
```

Adding a new index doesn't remove a previously existing one:

```{r}
setindex(MT, hp)

indices(MT)
```

We can thus use indices to pre-compute the ordering for the columns (or combinations of columns) that we will be using to group or subset by frequently !



<!-------------------------------------------------------->
## Subset / Filter

```{r}
#| echo: false

MT <- as.data.table(mtcars)
IRIS <- as.data.table(iris)[, Species := as.character(Species)]
```

### Basic filtering

::: {.panel-tabset group="framework"}

##### Tidyverse

```{r}
mtcars |> filter(cyl >= 6 & disp < 180)
```

```{r}
iris |> filter(Species %in% c("setosa"))
```


##### data.table

```{r}
MT[cyl >= 6 & disp < 180]
```

```{r}
IRIS[Species %chin% c("setosa")]
```

For non-regex character filtering, use `%chin%` (which is a character-optimized version of `%in%`)

:::


### Filter based on a range

```{r}
mtcars |> filter(between(disp, 200, 300))
```

```{r}
MT[disp %between% c(200, 300)]
```


### Filter with a pattern

```{r}
mtcars |> filter(str_detect(disp, "^\\d{3}\\."))
```

```{r}
MT[disp %like% "^\\d{3}\\."]
```

```{r}
#| eval: false
#| code-fold: true
#| code-summary: Variants

IRIS[Species %flike% "set"] # Fixed (not regex)

IRIS[Species %ilike% "Set"] # Ignore case

IRIS[Species %plike% "(?=set)"] # Perl-like regex
```


### Filter on row number (slicing)

::: {.panel-tabset group="framework"}

##### Tidyverse

```{r}
mtcars |> slice(1) # slice_head(n = 1)
```

```{r}
mtcars |> slice(n()) # slice_tail(n = 1)
```

Slice a random sample of rows:

```{r}
mtcars |> slice_sample(n = 5)
```


##### data.table

```{r}
MT[1]
```

```{r}
MT[.N]
```

Slice a random sample of rows:

```{r}
MT[sample(.N, 5)]
```


:::


### Filter distinct/unique rows

::: {.panel-tabset group="framework"}

##### Tidyverse

```{r}
mtcars |> distinct(mpg, hp, .keep_all = TRUE)
```

**Number of unique rows/values**

```{r}
n_distinct(mtcars$gear)
```


##### data.table

```{r}
unique(MT, by = c("mpg", "hp")) # cols = other_cols_to_keep
```

**Number of unique rows/values**

```{r}
uniqueN(MT, by = "gear")
```

:::



### Filter by keys

When keys or indices are defined, we can filter based on them, which is often a lot faster.  

:::{.callout-tip}
We do not even need to specify the column name we are filtering on: the values will be attributed to the keys in order.
:::


```{r}
setkey(MT, cyl)

MT[.(6)] # Equivalent to MT[cyl == 6]
```

```{r}
setkey(MT, cyl, gear)

MT[.(6, 4)] # Equivalent to MT[cyl == 6 & gear == 4]
```


### Filter by indices

To filter by indices, we can use the `on` argument, which creates a **temporary secondary index** on the fly (if it doesn't already exist).

```{r}
IRIS["setosa", on = "Species"]
```

Since the time to compute the secondary indices is quite small, we don’t have to use `setindex`, unless the task involves repeated subsetting on the same columns.


:::{.callout-tip}
When using `on` with multiple values, the `nomatch = NULL` argument avoids 
creating combinations that do not exist in the original data (i.e. for `cyl == 5` here)
:::

```{r}
MT[.(4:6, 4), on = c("cyl", "gear"), nomatch = NULL]
```



### Filtering on multiple columns

**Filtering with one function taking multiple columns:**

```{r}
f_dat <- \(d) with(d, gear > cyl) # Function taking the data and comparing fix columns

f_dyn <- \(x, y) x > y # Function taking dynamic columns and comparing them
```

```{r}
cols <- c("gear", "cyl")
```

::: {.panel-tabset group="framework"}

##### Tidyverse

**Manually:**

```{r}
mtcars |> filter(f_dyn(gear, cyl))
```

**Dynamically:**

Taking column names:

```{r}
mtcars |> filter(f_dyn(!!!syms(cols)))
```

Taking the data:

```{r}
mtcars |> filter(f_dat(cur_data()))
```


##### data.table

**Manually:**

```{r}
MT[f_dyn(gear, cyl),]
```

**Dynamically:**

Taking column names:

```{r}
MT[do.call(f_dyn, args), env = list(args = as.list(cols))] # exec(f_dyn, !!!args)
```

Taking the data:

```{r}
MT[f_dat(MT),] # Can't use .SD in i
```

_In two steps:_

:::{.callout-note}
We can't use `.SD` in the `i` clause of a `data.table`, but we can bypass that constraint by doing the operation in two steps:  
- Obtaining a vector stating if each row of the table matches or not the conditions  
- Filtering the original table based on the vector
:::

```{r}
MT[MT[, f_dat(.SD)]]
```


:::


**Combining multiple filtering functions:**

This function filters rows that have 2 or more non-zero decimals, and we're going to call it on multiple columns:

```{r}
decp <- \(x) str_length(str_remove(as.character(abs(x)), ".*\\.")) >= 2
```

```{r}
cols <- c("drat", "wt", "qsec")
```

::: {.panel-tabset group="framework"}

##### Tidyverse

**Manually:**

```{r}
mtcars |> filter(decp(drat) & decp(wt) & decp(qsec))
```

**Dynamically:**

```{r}
mtcars |> filter(if_all(cols, decp))
```

##### data.table

**Manually:**

```{r}
MT[decp(drat) & decp(wt) & decp(qsec), ]
```

**Dynamically:**

```{r}
MT[Reduce(`&`, lapply(mget(cols), decp)), ]
```

```{r}
#| eval: false
#| code-fold: true

MT[Reduce(`&`, lapply(MT[, ..cols], decp)), ]

MT[Reduce(`&`, lapply(v1, decp)), env = list(v1 = as.list(cols))]
```

_In two steps:_

```{r}
MT[MT[, Reduce(`&`, lapply(.SD, decp)), .SDcols = cols]]
```

:::


<!-------------------------------------------------------->
## Rename

```{r}
#| echo: false

MT <- as.data.table(mtcars)
IRIS <- as.data.table(iris)[, Species := as.character(Species)]
```

:::{.callout-note}
`setnames` changes column names **in-place**
:::

::: {.panel-tabset group="framework"}

##### Tidyverse

Manually:

```{r}
mtcars |> rename(CYL = cyl, MPG = mpg)
```

Dynamically:

```{r}
mtcars |> rename_with(\(c) toupper(c), .cols = matches("^d"))
```


##### data.table

Manually:

```{r}
setnames(copy(MT), c("cyl", "mpg"), c("CYL", "MPG"))[]
```

Dynamically:

```{r}
setnames(copy(MT), grep("^d", colnames(MT)), toupper)[]
```

:::


<!-------------------------------------------------------->
## Select

```{r}
#| echo: false

MT <- as.data.table(mtcars)
IRIS <- as.data.table(iris)[, Species := as.character(Species)]
```

### Basic selection

::: {.panel-tabset group="framework"}

##### Tidyverse

```{r}
MT |> select(matches("cyl|disp"))
```

<br>

**Remove a column:**

```{r}
mtcars |> select(!cyl) # select(-cyl)
```

##### data.table

```{r}
MT[, .(mpg, disp)]
```

```{r}
#| eval: false
#| code-fold: true

MT[ , .SD, .SDcols = c("mpg", "disp")]

MT[, .SD, .SDcols = patterns("mpg|disp")]
```

**Remove a column:**

```{r}
MT[, !"cyl"] # MT[, -"cyl"]
```

In-place:

```{r}
copy(MT)[, cyl := NULL][]
```

:::


::: {.panel-tabset group="framework"}

##### Tidyverse

**Select & Extract:**

```{r}
#| results: markup

mtcars |> pull(disp)
```

**Select & Rename:**

```{r}
mtcars |> select(dispp = disp)
```

##### data.table

**Select & Extrac:**

```{r}
#| results: markup

MT[, disp]
```

**Select & Rename:**

```{r}
MT[, .(dispp = disp)]
```

:::



### Dynamic selection

**By name:**

```{r}
cols <- c("cyl", "disp")
```

::: {.panel-tabset group="framework"}

##### Tidyverse

```{r}
mtcars |> select(all_of(cols)) # select(!!cols)
```

<br>

Removing a column:

```{r}
mtcars |> select(!{{cols}}) # select(-matches(cols))
```


##### data.table

```{r}
MT[, ..cols]
```

```{r}
#| eval: false
#| code-fold: true

MT[, mget(cols)] # Retired

MT[, cols, with = FALSE] # Retired

MT[, .SD, .SDcols = cols]

MT[, j, env = list(j = as.list(cols))]
```

Removing a column:

```{r}
MT[, !..cols]
```

```{r}
#| eval: false
#| code-fold: true

MT[, .SD, .SDcols = !cols]

MT[, -j, env = list(j = I(cols))]
```

_In-place:_

```{r}
copy(MT)[, (cols) := NULL][]
```


:::


**By pattern:**

::: {.panel-tabset group="framework"}

##### Tidyverse

```{r}
mtcars |> select(-matches("^d"))
```

```{r}
mtcars |> select(where(\(x) all(x != 0))) # Only keep columns where no value == 0
```


##### data.table

```{r}
MT[, .SD, .SDcols = !patterns("^d")]
```

```{r}
MT[, .SD, .SDcols = \(x) all(x != 0)] # Only keep columns where no value == 0
```

```{r}
#| eval: false
#| code-fold: show

copy(MT)[, grep("^d", colnames(MT)) := NULL][] # In place (column deletion)

MT[, MT[, sapply(.SD, \(x) all(x != 0))], with = FALSE]
```

:::


**By column type:**

```{r}
iris |> select(where(\(x) !is.numeric(x)))
```

```{r}
IRIS[, .SD, .SDcols = !is.numeric]
```



<!-------------------------------------------------------->
## Mutate / Transmute

```{r}
#| echo: false

MT <- as.data.table(mtcars)
IRIS <- as.data.table(iris)[, Species := as.character(Species)]
```

**`data.table` can mutate in 2 ways:**  
- Using `=` creates a new DT with the new columns only (like `dplyr::transmute`)   
- Using `:=` (or `let`) modifies the current dt *in place* (like `dplyr::mutate`)

The function modifying a column should be the same size as the original column (or group).  
If only one value is provided with `:=`, it will be recycled to the whole column/group.

If the number of values provided is smaller than the original column/group:  
- With `:=` or `let`, an error will be raised, asking to manually specify how to recycle the values.  
- With `=`, it will behave like `dplyr::summarize` (if a grouping has been specified).

### Basic transmute

Only keeping the transformed columns.

::: {.panel-tabset group="framework"}

##### Tidyverse

```{r}
mtcars |> transmute(cyl = cyl * 2)
```

##### data.table

```{r}
MT[, .(cyl = cyl * 2)]
```

Transmute & Extract:

```{r}
#| results: markup

MT[, (cyl = cyl * 2)]
```


:::


### Basic mutate

Modifies the transformed column **in-place** and keeps every other column as-is.

::: {.panel-tabset group="framework"}

##### Tidyverse

```{r}
mtcars |> mutate(cyl = 200)

mtcars |> mutate(cyl = 200, gear = 5)
```

<br>

```{r}
mtcars |> mutate(mean_cyl = mean(cyl, na.rm = TRUE))
```

```{r}
mtcars |> mutate(gear_plus = lead(gear))
```


##### data.table

```{r}
copy(MT)[, cyl := 200][]

copy(MT)[, let(cyl = 200, gear = 5)][]
```

```{r}
#| eval: false
#| code-fold: true

copy(MT)[, `:=`(cyl = 200, gear = 5)][]

copy(MT)[, c("cyl", "gear") := .(200, 5)][]
```

```{r}
copy(MT)[, mean_cyl := mean(cyl, na.rm = TRUE)][]
```

```{r}
copy(MT)[, gearplus := shift(gear, 1, type = "lead")][] # lead, lag, cyclic
```

:::


### Dynamic trans/mutate

```{r}
LHS <- "mean_mpg"
RHS <- "mpg"
```


::: {.panel-tabset group="framework"}

##### Tidyverse

```{r}
mtcars |> mutate({{LHS}} := mean(mpg))
```

```{r}
mtcars |> mutate("{LHS}" := mean(.data[[RHS]]))

mtcars |> mutate({{LHS}} := mean(cur_data()[[RHS]]))
```


##### data.table

```{r}
copy(MT)[, (LHS) := mean(mpg)][] # (LHS) <=> c(LHS)

copy(MT)[, j := mean(mpg), env = list(j = LHS)][]
```

```{r}
copy(MT)[, c(LHS) := mean(get(RHS))][]

copy(MT)[, x := mean(y), env = list(x = LHS, y = RHS)][]
```

:::


### Conditional trans/mutate

::: {.panel-tabset group="framework"}

##### Tidyverse

**Mutate everything based on multiple conditions:**

One condition:

```{r}
mtcars |> mutate(Size = if_else(cyl >= 6, "BIG", "small", missing = "Unk"))
```

Nested conditions:

```{r}
mtcars |> mutate(Size = case_when(
  cyl %between% c(2,4) ~ "small",
  cyl %between% c(4,8) ~ "BIG",
  .default = "Unk"
))
```

**Mutate only rows meeting conditions:**

```{r}
mtcars |> mutate(BIG = case_when(am == 1 ~ cyl >= 6))
```


##### data.table

**Mutate everything based on multiple conditions:**

One condition:

```{r}
copy(MT)[, Size := fifelse(cyl >= 6, "BIG", "small", na = "Unk")][]
```

Nested conditions:

```{r}
copy(MT)[, Size := fcase(
  cyl %between% c(2,4), "small", 
  cyl %between% c(4,8), "BIG",
  default = "Unk"
)][]
```

**Mutate only rows meeting conditions:**

```{r}
copy(MT)[am == 1, BIG := cyl >= 6][]
```

:::


### Complex trans/mutate

#### Column-wise operations

```{r}
new <- c("min_mpg", "min_disp")
old <- c("mpg", "disp")
```

**Apply one function to multiple columns:**

::: {.panel-tabset group="framework"}

##### Tidyverse

```{r}
mtcars |> mutate(across(c("mpg", "disp"), min, .names = "min_{col}"))
```

<br><br>

**As a `transmute`:**

```{r}
mtcars |> transmute(across(c("mpg", "disp"), min, .names = "min_{col}"))
```

<br>

**Dynamically:**

```{r}
mtcars |> mutate(across(all_of(old), min, .names = "min_{col}"))
```


##### data.table

```{r}
copy(MT)[
    , c("min_mpg", "min_disp") := lapply(.SD, min), .SDcols = c("mpg", "disp")
  ][]
```

```{r}
#| eval: false

copy(MT)[, c("min_mpg", "min_disp") := lapply(.(mpg, disp), min)][]
```

**As a `transmute`:**

A second step is needed to add `min_` before the names:

```{r}
(MT[, lapply(.SD[, .(mpg, disp)], min)] |> 
   bind(d, setnames(d, names(d), \(x) paste0("min_", x)))
)[]
```

**Dynamically:**

```{r}
copy(MT)[, c(new) := lapply(mget(old), min)][]
```

```{r}
#| eval: false

copy(MT)[, c(new) := lapply(x, min), env = list(x = as.list(old))][]
```


:::

**Apply multiple functions to one or multiple column:**

```{r}
col <- "mpg"
cols <- c("mpg", "disp")
```


::: {.panel-tabset group="framework"}

##### Tidyverse

```{r}
mtcars |> mutate(min_mpg = min(mpg), max_mpg = max(mpg))

mtcars |> mutate(across(mpg, list(min = min, max = max), .names = "{fn}_{col}"))
```

<br>

**Multiple columns:**

```{r}
mtcars |> mutate(
    across(matches("mpg|disp"), list(min = min, max = max), .names = "{fn}_{col}")
  )
```

```{r}
mtcars |> mutate(
    across(cols, list(min = \(x) min(x), max = \(x) max(x)), .names = "{fn}_{col}")
  )
```


##### data.table

```{r}
copy(MT)[, let(min_mpg = min(mpg), max_mpg = max(mpg))][]

copy(MT)[, c("min_mpg", "max_mpg") := .(min(mpg), max(mpg))][]
```

```{r}
#| eval: false
#| code-fold: true

copy(MT)[, c("min_mpg", "max_mpg") := 
           lapply(.(mpg), \(x) list(min(x), max(x))) |> do.call(rbind, args = _)
        ][]

copy(MT)[, c("min_mpg", "max_mpg") := 
           lapply(.(get(col)), \(x) list(min(x), max(x))) |> unlist(recursive = F)
        ][]
```

**Multiple columns:**

```{r}
copy(MT)[, c("min_mpg", "min_disp", "max_mpg", "max_disp") := 
           lapply(.SD, \(x) list(min(x), max(x))) |> do.call(rbind, args = _), 
         .SDcols = cols][]
```

```{r}
copy(MT)[, outer(c("min", "max"), cols, str_c, sep = "_") |> t() |> as.vector() := 
           lapply(.SD, \(x) list(min(x), max(x))) |> do.call(rbind, args = _), 
         .SDcols = cols][]
```

:::


#### Row-wise operations

**Apply one function to multiple columns (row-wise):**

::: {.panel-tabset group="framework"}

##### Tidyverse

```{r}
mtcars |> rowwise() |> mutate(rsum = sum(c_across(where(is.numeric)))) |> ungroup()

mtcars |> mutate(rsum = pmap_dbl(across(where(is.numeric)), \(...) sum(c(...))))
```

Hybrid base R-Tidyverse:

```{r}
mtcars |> mutate(rsum = apply(across(where(is.numeric)), 1, sum))

mtcars |> mutate(rsum = rowSums(across(where(is.numeric))))
```


##### data.table

```{r}
copy(MT)[, rsum := rowSums(.SD), .SDcols = is.numeric][]

copy(MT)[, rsum := apply(.SD, 1, sum), .SDcols = is.numeric][]
```

:::


**Apply multiple functions to multiple columns (row-wise)**

::: {.panel-tabset group="framework"}

##### Tidyverse

```{r}
mtcars |> mutate(
  pmap_dfr(
    across(where(is.numeric)), 
    \(...) c(...) |> bind(x, list(mean = mean(x), sum = sum(x)))
  )
)
```

Hybrid base R-Tidyverse:

```{r}
mtcars |> mutate(
  apply(across(where(is.numeric)), 1, \(x) list(mean = mean(x), sum = sum(x))) |> 
    bind_rows()
)
```

##### data.table

```{r}
copy(MT)[, c("rmean", "rsum") := 
           apply(.SD, 1, \(x) list(mean(x), sum(x))) |> rbindlist(), 
         .SDcols = is.numeric][]
```

:::


**Apply an anonymous function inside the DT:**

```{r}
MT[, {
    print(summary(mpg))
    x <- cyl + gear
    .(RN = 1:.N, CG = x)
  }
]
```


<!-------------------------------------------------------->
## Group / Aggregate

```{r}
#| echo: false

MT <- as.data.table(mtcars)
IRIS <- as.data.table(iris)[, Species := as.character(Species)]
```

:::{.callout-note}
The examples listed apply a grouping but do nothing (using `.SD` to simply keep all columns as is)
:::

```{r}
cols <- c("cyl", "disp")
cols_missing <- c("cyl", "disp", "missing_col")
```

### Basic grouping

::: {.panel-tabset group="framework"}

##### Tidyverse

```{r}
mtcars |> group_by(cyl, gear)
```

**Dynamic grouping:**

```{r}
mtcars |> group_by(across(all_of(cols)))
```

Use `any_of` if you expect some columns to be missing in the data.

```{r}
mtcars |> group_by(across(any_of(cols_missing)))
```


##### data.table

```{r}
MT[, .SD, by = .(cyl, gear)]
```

**Dynamic grouping:**

```{r}
MT[, .SD, by = cols]
```

To handle potentially missing columns:

```{r}
MT[, .SD, by = intersect(cols_missing, colnames(MT))]
```


:::


### Current group info

::: {.panel-tabset group="framework"}

##### Tidyverse

```{r}
#| layout-nrow: 1
#| layout-ncol: 3

mtcars |> 
  group_by(cyl) |> 
  summarize(plot(gear, mpg, main = paste("Cyl:", cur_group()))) -> void
```

```{r}
#| layout-nrow: 1
#| layout-ncol: 3

mtcars |> 
  group_by(cyl) |> 
  group_walk(\(d, g) with(d, plot(gear, mpg, main = paste("Cyl:", g$cyl))))
```


##### data.table

Use the `.BY` argument to get the current group name:

```{r}
#| layout-nrow: 1
#| layout-ncol: 3

MT[, with(.SD, plot(gear, mpg, main = paste("Cyl:", .BY))), by = cyl] -> void
```

:::



<!-------------------------------------------------------->
## Row numbers & indices

```{r}
#| echo: false

MT <- as.data.table(mtcars)
IRIS <- as.data.table(iris)[, Species := as.character(Species)]
```

### Adding row or group indices

`.I`: Row indices  
`.N`: Number of rows  

`.GRP`: Group indices  
`.NGRP`: Number of groups  

**Adding rows indices:**

```{r}
mtcars |> mutate(I = row_number())

copy(MT)[ , I := .I][]
```

**Adding group indices:**

::: {.panel-tabset group="framework"}

##### Tidyverse

**Adding group indices (same index for each group):**

```{r}
mtcars |> group_by(cyl) |> summarize(GRP = cur_group_id())
```

Mutate instead of summarize:

```{r}
mtcars |> arrange(cyl) |> group_by(cyl) |> mutate(GRP = cur_group_id())
```

**Adding row numbers within each group:**

```{r}
mtcars |> group_by(gear) |> mutate(I_GRP = row_number())
```

##### data.table

**Adding group indices (same index for each group):**

```{r}
MT[, .GRP, by = cyl]
```

Mutate instead of summarize:

```{r}
copy(MT)[, GRP := .GRP, keyby = cyl][]
```

**Adding row numbers within each group:**

```{r}
copy(MT)[, I_GRP := 1:.N, by = gear][]

copy(MT)[, I_GRP := rowid(gear)][]
```

:::


### Filtering based on row numbers (slicing)

**Extracting a specific row:**

::: {.panel-tabset group="framework"}

##### Tidyverse

```{r}
mtcars |> dplyr::first()

mtcars |> dplyr::last()

mtcars |> dplyr::nth(5)
```

##### data.table

```{r}
MT[1,] # data.table::first(MT)

MT[.N,] # data.table::last(MT)

MT[5,]
```

:::


**Slicing rows:**

::: {.panel-tabset group="framework"}

##### Tidyverse

```{r}
tail(mtcars, 10)

mtcars |> slice((n()-9):n())

mtcars |> slice_tail(n = 10)
```

##### data.table

```{r}
tail(MT, 10)

MT[(.N-9):.N]

MT[MT[, .I[(.N-9):.N]]] # Gets the last 10 rows' indices and filters based on them
```

:::


**Slicing groups:**

::: {.panel-tabset group="framework"}

##### Tidyverse

**Random sample by group:**

```{r}
mtcars |> group_by(cyl) |> slice_sample(n = 5)
```

**Filter groups by condition:**

```{r}
mtcars |> group_by(cyl) |> filter(n() >= 8)

mtcars |> group_by(cyl) |> group_modify(\(d,g) if (nrow(d) >= 8) d else data.frame())
```

##### data.table

**Random sample by group:**

```{r}
MT[, .SD[sample(.N, 5)], keyby = cyl]
```

**Filter groups by condition:**

```{r}
MT[, if(.N >= 8) .SD, by = cyl]

MT[, .SD[.N >= 8], by = cyl]
```

:::



### Extracting row indices

**Getting the row numbers of specific observations:**

::: {.panel-tabset group="framework"}

##### Tidyverse

Row number of the first and last observation of each group:

```{r}
mtcars |> group_by(cyl) |> summarize(I = cur_group_rows()[c(1, n())]) |> ungroup()
```

... while keeping all other columns:

```{r}
mtcars |> mutate(I = row_number()) |> group_by(cyl) |> slice(c(1, n())) |> ungroup()
```

##### data.table

Row number of the first and last observation of each group:

```{r}
MT[, .I[c(1, .N)], keyby = cyl]
```

... while keeping all other columns:

```{r}
copy(MT)[, I := .I][, .SD[c(1, .N)], keyby = cyl]
```

:::


**Extracting row indices after filtering:**

:::{.callout-important}
`.I` gives the vector of row numbers *after* any subsetting/filtering has been done
:::

::: {.panel-tabset group="framework"}

##### Tidyverse

Extracting row numbers in the original dataset:

```{r}
mtcars |> mutate(I = row_number()) |> filter(gear == 4) |> pull(I)
```

Extracting row numbers in the new dataset (after filtering):

```{r}
mtcars |> filter(gear == 4) |> mutate(I = row_number()) |> pull(I)
```

##### data.table

Extracting row numbers in the original dataset:

```{r}
MT[, .I[gear == 4]]
```

Extracting row numbers in the new dataset (after filtering):

```{r}
MT[gear == 4, .I]
```

:::



<!-------------------------------------------------------->
## Relocate

### Basic reordering

::: {.panel-tabset group="framework"}

##### Tidyverse

```{r}
mtcars |> group_by(cyl) |> mutate(GRP = cur_group_id(), .before = 1)
```

```{r}
mtcars |> relocate(cyl, .after = last_col())
```


##### data.table

```{r}
setcolorder(copy(MT)[ , GRP := .GRP, by = cyl], c("GRP"))[]
```

```{r}
setcolorder(copy(MT), c(setdiff(colnames(MT), "cyl"), "cyl"))[]
```

:::


### Reordering by column names

::: {.panel-tabset group="framework"}

##### Tidyverse

```{r}
mtcars |> select(sort(tidyselect::peek_vars()))
```

```{r}
mtcars |> select(carb, sort(tidyselect::peek_vars()))
```


##### data.table

```{r}
setcolorder(copy(MT), sort(colnames(MT)))[]
```

```{r}
setcolorder(copy(MT), c("carb", sort(setdiff(colnames(MT), "carb"))))[]
```

:::

<!-------------------------------------------------------->
## Summarize:

```{r}
#| echo: false

MT <- as.data.table(mtcars)
IRIS <- as.data.table(iris)[, Species := as.character(Species)]
```

With `data.table`, one needs to use the `=` operator to summarize. It takes a **function that returns a list of values smaller than the original column** (or group) size. By default, it will **only keep the modified columns** (like a `transmute`).

### Basic summary

```{r}
mtcars |> summarize(mean_cyl = mean(cyl))
```

```{r}
MT[, .(mean_cyl = mean(cyl))]
```


### Grouped summary

::: {.panel-tabset group="framework"}

##### Tidyverse

By default, `dplyr::summarize` will `arrange` the result by the grouping factor:

```{r}
mtcars |> group_by(cyl) |> summarize(N = n())
```

##### data.table

By default, `data.table` keeps the order the groups originally appear in:

```{r}
MT[, .N, by = cyl]
```

To order by the grouping factor, use `keyby` instead of `by`:

```{r}
MT[, .N, keyby = cyl]
```

:::

**Grouped on a temporary variable:**

```{r}
mtcars |> group_by(cyl > 6) |> summarize(N = n())
```

```{r}
MT[, .N, by = .(cyl > 6)]
```


### Column-wise summary

**Apply one function to multiple columns:**

::: {.panel-tabset group="framework"}

##### Tidyverse

```{r}
mtcars |> group_by(cyl) |> summarize(across(everything(), mean))
```

By column type:

```{r}
mtcars |> group_by(cyl) |> summarize(across(where(is.double), mean))
```

By matching column names:

```{r}
mtcars |> group_by(cyl) |> summarize(across(matches("^d"), mean))
```


##### data.table

```{r}
MT[, lapply(.SD, mean), keyby = cyl]
```

By column type:

```{r}
MT[, lapply(.SD[, -"cyl"], mean), keyby = cyl, .SDcols = is.double]
```

By matching column names:

```{r}
MT[, lapply(.SD, mean), keyby = cyl, .SDcols = patterns("^d")]
```

:::


**Applying multiple functions to one column:**

::: {.panel-tabset group="framework"}

##### Tidyverse

```{r}
mtcars |> group_by(cyl) |> summarize(mean(mpg), sd(mpg))
```

```{r}
mtcars |> group_by(cyl) |> summarize(mean_mpg = mean(mpg), sd_mpg = sd(mpg))
```

```{r}
mtcars |> 
  group_by(cyl) |> 
  summarize(across(mpg, list(mean = mean, sd = sd), .names = "{fn}"))
```


##### data.table

```{r}
MT[, .(mean(mpg), sd(mpg)), keyby = cyl]
```

```{r}
MT[, .(mean_mpg = mean(mpg), sd_mpg = sd(mpg)), keyby = cyl]
```

```{r}
MT[, lapply(.(mpg), \(x) list(mean(x), sd(x))) |> rbindlist(), keyby = cyl]
```

With column names:

```{r}
MT[, 
  lapply(.SD, \(x) list(mean_mpg = mean(x), sd_mpg = sd(x))) |> rbindlist(), 
  keyby = cyl, .SDcols = "mpg"
]
```

```{r}
MT[, 
  lapply(.SD, \(x) list(mean = mean(x), sd = sd(x))) |> rbindlist(idcol = "Var"), 
  keyby = cyl, .SDcols = "mpg"
]
```


:::


**Apply multiple functions to multiple columns:**

:::{.callout-note}
Depending on the output we want (i.e. having the function's output as columns or rows), we can either provide a list of functions to apply (`list_of_fns`), or a function returning a list (`fn_returning_list`).
:::

```{r}
cols <- c("mpg", "hp")

list_of_fns <- list(mean = \(x) mean(x), sd = \(x) sd(x))

fn_returning_list <- \(x) list(mean = mean(x), sd = sd(x))
```

::: {.panel-tabset group="framework"}

##### Tidyverse

**One column per function, one row per variable:**

```{r}
mtcars |> 
  group_by(cyl) |> 
  summarize(map_dfr(across(all_of(cols)), fn_returning_list, .id = "Var")) |> 
  ungroup()
```

**One column per variable, one row per function:**

```{r}
mtcars |> 
  group_by(cyl) |> 
  summarize(map_dfr(list_of_fns, \(f) map(across(all_of(cols)), f), .id = "Fn")) |> 
  ungroup()
```

**One column per function/variable combination:**

```{r}
mtcars |> 
  group_by(cyl) |> 
  summarize(across(all_of(cols), list_of_fns, .names = "{col}.{fn}")) |> 
  ungroup()
```


##### data.table

**One column per function, one row per variable:**

```{r}
MT[, 
  lapply(.SD, fn_returning_list) |> rbindlist(idcol = "Var"), 
  keyby = cyl, .SDcols = cols
]
```

**One column per variable, one row per function:**

```{r}
MT[, 
  lapply(list_of_fns, \(f) lapply(.SD, f)) |> rbindlist(idcol = "Fn"), 
  keyby = cyl, .SDcols = cols
]
```

**One column per function/variable combination:**

```{r}
MT[, 
  lapply(.SD, fn_returning_list) |> 
    unlist(recursive = FALSE), # do.call(c, args = _)
  keyby = cyl, .SDcols = cols
]
```

Different column order & naming scheme:

```{r}
MT[, 
  lapply(list_of_fns, \(f) lapply(.SD, f)) |> 
    unlist(recursive = FALSE), # do.call(c, args = _)
  keyby = cyl, .SDcols = cols
]
```

Using `dcast` (see next section):

```{r}
dcast(MT, cyl ~ ., fun.agg = list_of_fns, value.var = cols) # list(mean, sd)
```

:::




<!-------------------------------------------------------->
<!-------------------------------------------------------->
# Pivots
***

<!-------------------------------------------------------->
## Melt / Longer

**Data:**

```{r}
#| echo: false
#| output: false

fam1 <- "
family_id age_mother dob_child1 dob_child2 dob_child3
1         30 1998-11-26 2000-01-29         NA
2         27 1996-06-22         NA         NA
3         26 2002-07-11 2004-04-05 2007-09-02
4         32 2004-10-10 2009-08-27 2012-07-21
5         29 2000-12-05 2005-02-28         NA
"

FAM1 <- fread(fam1)
```

```{r}
FAM1
```

```{r}
#| echo: false
#| output: false

fam2 <- "
family_id age_mother dob_child1 dob_child2 dob_child3 gender_child1 gender_child2 gender_child3
1         30 1998-11-26 2000-01-29         NA             1             2            NA
2         27 1996-06-22         NA         NA             2            NA            NA
3         26 2002-07-11 2004-04-05 2007-09-02             2             2             1
4         32 2004-10-10 2009-08-27 2012-07-21             1             1             1
5         29 2000-12-05 2005-02-28         NA             2             1            NA
"

FAM2 <- fread(fam2)
```

```{r}
FAM2
```

**One group of columns --> single value column**

```{r}
FAM1 |> pivot_longer(cols = matches("dob_"), names_to = "variable")

FAM1 |> melt(measure.vars = c("dob_child1", "dob_child2", "dob_child3"))
FAM1 |> melt(measure.vars = patterns("^dob_"))
```


**One group of columns --> multiple value columns**

```{r}
FAM1 |> melt(measure.vars = patterns(child1 = "child1$", child2 = "child2$|child3$"))
```


### Merging multiple yes/no columns:

Melting multiple presence/absence columns into a single variable:

```{r}
#| echo: false
#| output: false

movies_wide <- tibble(
  ID = 1:3,
  action = c(1,1,1),
  adventure = c(0,1,1),
  animation = c(0,0,1)
)

MOVIES_WIDE <- as.data.table(movies_wide)
```

```{r}
movies_wide
```

```{r}
pivot_longer(
    movies_wide, -ID, names_to = "Genre", 
    values_transform = \(x) ifelse(x == 0, NA, x), values_drop_na = TRUE
  ) |> select(-value)
```

```{r}
melt(MOVIES_WIDE, id.vars = "ID", variable.name = "Genre")[value != 0][order(ID), -"value"]
```

### Partial pivot:

Multiple groups of columns --> Multiple value columns

**Manually:**

```{r}
colA <- str_subset(colnames(FAM2), "^dob")
colB <- str_subset(colnames(FAM2), "^gender")

FAM2 |> melt(measure.vars = list(colA, colB), value.name = c("dob", "gender"), variable.name = "child")
```

```{r}
FAM2 |> melt(measure.vars = list(a, b), value.name = c("dob", "gender"), variable.name = "child") |> 
  substitute2(env = list(a = I(str_subset(colnames(FAM2), "^dob")), b = I(str_subset(colnames(FAM2), "^gender")))) |> eval()
```


**Using `.value`:**

:::{.callout-tip}
Using the `.value` special identifier allows to do a "half" pivot: the values that would be listed as rows under `.value` are instead used as columns.
:::

```{r}
FAM2 |> pivot_longer(cols = matches("^dob|^gender"), names_to = c(".value", "child"), names_sep = "_child")

FAM2 |> melt(measure.vars = patterns("^dob", "^gender"), value.name = c("dob", "gender"), variable.name = "child")
```

**Using `measure` and `value.name`:**

:::{.callout-warning}
`data.table` only
:::

```{r}
FAM2 |> melt(measure.vars = measure(value.name, child = \(x) as.integer(x), sep = "_child"))

FAM2 |> melt(measure.vars = measurev(list(value.name = NULL, child = as.integer), pattern = "(.*)_child(\\d{1})"))
```


<!-------------------------------------------------------->
## Dcast / Wider:

**General idea:**  
- Pivot around the combination of `id.vars` (LHS of the formula)  
- The `measure.vars` (RHS of the formula) are the ones whose values become column names  
- The `value.var` are the ones the values are taken from to fill the new columns


**Data:**

```{r}
(FAM1L <- FAM1 |> melt(measure.vars = c("dob_child1", "dob_child2", "dob_child3")))

(FAM2L <- FAM2 |> melt(measure.vars = measure(value.name, child = \(.x) as.integer(.x), sep = "_child")))
```

**Basic pivot wider:**

```{r}
FAM1L |> pivot_wider(id_cols = c("family_id", "age_mother"), names_from = "variable")

FAM1L |> dcast(family_id + age_mother ~ variable)
```


**Using all the columns as IDs:**

:::{.callout-note}
By default, `id_cols = everything()`
:::

```{r}
FAM1L |> pivot_wider(names_from = variable)
```

:::{.callout-note}
`...` => "every unused column"
:::

```{r}
FAM1L |> dcast(... ~ variable)
```


**Multiple value columns --> Multiple groups of columns:**

```{r}
FAM2L |> pivot_wider(
  id_cols = c("family_id", "age_mother"), values_from = c("dob", "gender"), 
  names_from = "child", names_sep = "_child"
)
```

```{r}
FAM2L |> dcast(family_id + age_mother ~ child, value.var = c("dob", "gender"), sep = "_child")

FAM2L |> dcast(... ~ child, value.var = c("dob", "gender"), sep = "_child")
```


**Dynamic names in the formula:**

```{r}
var_name <- "variable"
```

```{r}
FAM1L |> pivot_wider(id_cols = c(family_id, age_mother), names_from = {{ var_name }})
```

```{r}
FAM1L |> dcast(family_id + age_mother ~ base::get(var_name))

FAM1L |> dcast(family_id + age_mother ~ v1) |> substitute2(env = list(v1 = var_name)) |> eval()
```


Multiple variables:

```{r}
id_vars <- c("family_id", "age_mother")
```

```{r}
FAM1L |> pivot_wider(id_cols = all_of(id_vars), names_from = variable)
```

```{r}
FAM1L |> dcast(str_c(str_c(id_vars, collapse = " + "), " ~ variable"))
```

```{r}
FAM1L |> dcast(v1 + v2 ~ variable) |> substitute2(env = list(v1 = id_vars[1], v2 = id_vars[2])) |> eval()
```


### Renaming (prefix/suffix) the columns:

```{r}
FAM1L |> pivot_wider(names_from = variable, values_from = value, names_prefix = "Attr: ")

FAM1L |> pivot_wider(names_from = variable, values_from = value, names_glue = "Attr: {variable}")
```

```{r}
FAM1L |> dcast(family_id + age_mother ~ paste0("Attr: ", variable))
```


### Unused combinations:

:::{.callout-warning}
The logic is inverted between `dplyr` (keep) and `data.table` (drop)
:::

```{r}
FAM1L |> pivot_wider(names_from = variable, values_from = value, id_expand = TRUE, names_expand = FALSE) # (keep_id, keep_names)

FAM1L |> dcast(family_id + age_mother ~ variable, drop = c(F, T)) # (drop_LHS, drop_RHS)
```


### Subsetting:

:::{.callout-note}
AFAIK, `pivot_wider` can't do this on it's own.
:::

```{r}
FAM1L |> filter(value >= lubridate::ymd(20030101)) |> 
  pivot_wider(id_cols = c("family_id", "age_mother"), names_from = "variable")
```

```{r}
FAM1L |> dcast(family_id + age_mother ~ variable, subset = .(value >= lubridate::ymd(20030101)))
```


### Aggregating:

Not specifying the column holding the measure vars (the names) will result in an empty column counting the number of columns that should have been created for all the measures.

```{r}
FAM1L |> dcast(family_id + age_mother ~ .)
```

We can customize that default behavior using the `fun.aggregate` argument:

*Here, we count the number of child for each each combination of (family_id + age_mother) -> sum all non-NA `value`*

```{r}
FAM1L |> pivot_wider(id_cols = c(family_id, age_mother), names_from = variable, values_fn = \(.x) sum(!is.na(.x))) |>
  rowwise() |> mutate(child_count = sum(c_across(matches("_child")))) |> ungroup()

FAM1L |> pivot_wider(id_cols = c(family_id, age_mother), names_from = variable, values_fn = \(.x) sum(!is.na(.x))) |>
  mutate(child_count = apply(select(cur_data(), matches("_child")), 1, \(r) sum(r)))
```

```{r}
(FAM1L |> dcast(family_id + age_mother ~ ., fun.agg = \(.x) sum(!is.na(.x))) |> setnames(".", "child_count"))
```


**Applying multiple `fun.agg`:**

Data:

```{r}
(DTL <- data.table(
  id1 = sample(5, 20, TRUE), 
  id2 = sample(2, 20, TRUE), 
  group = sample(letters[1:2], 20, TRUE), 
  v1 = runif(20), 
  v2 = 1L)
)
```

Multiple `fun.agg` applied to one variable:

```{r}
DTL |> dcast(id1 + id2 ~ group, fun.aggregate = list(sum, mean), value.var = "v1")
```

Multiple `fun.agg` to multiple `value.var` (all combinations):

```{r}
DTL |> dcast(id1 + id2 ~ group, fun.aggregate = list(sum, mean), value.var = c("v1", "v2"))
```

Multiple `fun.agg` and multiple `value.var` (one-to-one):

*Here, we apply `sum` to `v1` (for both `group` a & b), and `mean` to `v2` (for both `group` a & b)*

```{r}
DTL |> dcast(id1 + id2 ~ group, fun.aggregate = list(sum, mean), value.var = list("v1", "v2"))
```


### One-hot encoding:

Making each level of a variable into a presence/absence column:

```{r}
#| echo: false
#| output: false

movies_long <- data.frame(
  ID = c(1L, 2L, 2L, 3L, 3L, 3L), 
  Genre = c("action", "action", "adventure", "action", "adventure", "animation"),
  OtherCol = runif(6)
)

MOVIES_LONG <- as.data.table(movies_long)
```

```{r}
movies_long
```

```{r}
pivot_wider(
  movies_long, names_from = "Genre", values_from = "Genre", 
  values_fn = \(x) !is.na(x), values_fill = FALSE
)
```

```{r}
dcast(
  MOVIES_LONG, ... ~ Genre, value.var = "Genre", 
  fun.agg = \(x) !is.na(x), fill = FALSE
)
```


<!-------------------------------------------------------->
<!-------------------------------------------------------->
# Joins:
***

:::{.callout-tip}
In `data.table`, a JOIN is just another type of SUBSET: we subset the rows of one `data.table` with the rows of a second one, based on some conditions that define the type of JOIN.
:::

Matching two tables based on their rows can be done:  
- Either on equivalences (**equi-joins**)  
- Or functions comparing one row to another (**non-equi joins**)


**Data:**

```{r}
(DT1 <- data.table( 
  ID = LETTERS[1:10],
  A = sample(1:5, 10, replace = TRUE),
  B = sample(10:20, 10)
))

(DT2 <- data.table(
  ID = LETTERS[5:14],
  C = sample(1:5, 10, replace = TRUE),
  D = sample(10:20, 10) 
))
```


**Basic (right) join example:**

```{r}
right_join(
  DT1 |> select(ID, A),
  DT2 |> select(ID, C), 
  by = "ID"
) |> as_tibble()

DT1[DT2, .(ID, A, C), on = .(ID)]
```


<!-------------------------------------------------------->
## Outer (right, left):

Appends data of one at the end of the other.

:::{.callout-note}
`data.table` doesn't do left joins natively
:::


**Subsetting DT1 by DT2:**

:::{.callout-note}
DT2 (everything) + DT1 (all columns, but only the rows that match those in DT1).  
  > Looking up DT1's rows using DT2 (or DT2's key, if it has one) as an index.
:::

As a **right join**:

```{r}
right_join(DT1, DT2, by = "ID") # DT1 into DT2

DT1[DT2, on = .(ID)]
```

As a **left join:**

:::{.callout-note}
Not exactly equivalent to the right join: same columns, but DT2 is first instead of DT1
:::

```{r}
left_join(DT2, DT1, by = "ID") # DT1 into DT2

copy(DT2)[DT1, c("A", "B") := list(i.A, i.B), on = .(ID)][]
```


**Subsetting DT2 by DT1:**

:::{.callout-note}
DT1 (everything) + DT2 (all columns, but only the rows that match those in DT1).  
  > Looking up DT2's rows using DT1 (or DT1's key, if it has one) as an index.
:::

As a **right join**:

```{r}
right_join(DT2, DT1, by = "ID") # DT2 into DT1

DT2[DT1, on = .(ID)]
```

As a **left join:**

:::{.callout-note}
Not exactly equivalent to the right join: same columns, but DT1 is first instead of DT2
:::

```{r}
left_join(DT1, DT2, by = "ID") # DT2 into DT1

copy(DT1)[DT2, c("C", "D") := list(i.C, i.D), on = .(ID)][]
```


<!-------------------------------------------------------->
## Full (outer):

```{r}
full_join(DT1, DT2, by = "ID")

data.table::merge.data.table(DT1, DT2, by = "ID", all = TRUE)
```

Alternatively:

```{r}
setkey(DT1, ID)
setkey(DT2, ID)

# Getting the union of the unique keys of both DT
unique_keys <- union(DT1[, ID], DT2[, ID])

DT1[DT2[unique_keys, on = "ID"]]
```


<!-------------------------------------------------------->
## Inner:

**Only returns the ROWS matching both tables:**  
- **Inner**: rows matching both DT1 and DT2, columns of both (add DT2's columns to the right)  
- **Semi**: rows matching both DT1 and DT2, columns of first one  


**Inner:**

```{r}
inner_join(DT1, DT2, by = "ID") 

DT1[DT2, on = .(ID), nomatch = NULL]
```

**Semi:**

```{r}
semi_join(DT1, DT2, by = "ID")

DT1[na.omit(DT1[DT2, on = .(ID), which = TRUE])]
```

:::{.callout-note}
`which = TRUE` returns the row numbers instead of the rows themselves.
:::

<!-------------------------------------------------------->
## Anti:

ROWS of DT1 that are NOT in DT2, and only the columns of DT1.

```{r}
anti_join(DT1, DT2, by = "ID")

DT1[!DT2, on = .(ID)]
```

ROWS of DT2 that are NOT in DT1, and only the columns of DT2.

```{r}
anti_join(DT2, DT1, by = "ID")

DT2[!DT1, on = .(ID)]
```


<!-------------------------------------------------------->
## Non-equi joins:

<!--
See:  
- https://scitilab.com/post_data/non_equi_joins/2020_11_17_non_equi_merge/  
- https://medium.com/analytics-vidhya/r-data-table-joins-48f00b46ce29  
- https://gist.github.com/nacnudus/ef3b22b79164bbf9c0ebafbf558f22a0  
-->

```{r}
DT1[DT2, on = .(ID, A <= C)]
```


<!-------------------------------------------------------->
## Rolling joins:

```{r}
DT1[DT2, on = "ID", roll = TRUE]
```

Inverse the rolling direction:

```{r}
DT1[DT2, on = "ID", roll = -Inf]
```

```{r}
DT1[DT2, on = "ID", rollends = TRUE]
```



<!-------------------------------------------------------->
<!-------------------------------------------------------->
# Tidyr & Others:
***

```{r}
#| echo: false

MT <- as.data.table(mtcars)
IRIS <- as.data.table(iris)[, Species := as.character(Species)]
```

## Remove NA:

```{r}
tidyr::drop_na(IRIS, matches("Sepal"))
```

```{r}
na.omit(IRIS, cols = str_subset(colnames(IRIS), "Sepal"))
```


## Unite:

Combine multiple columns into a single one:

```{r}
mtcars |> tidyr::unite("x", gear, carb, sep = "_")

copy(MT)[, x := paste(gear, carb, sep = "_")][]
```


## Extract / Separate:

Separate a row into multiple columns based on a pattern (`extract`) or a separator (`separate`):

```{r}
MT.ext <- MT[, .(x = str_c(gear, carb, sep = "_"))]
```

```{r}
MT.ext |> tidyr::extract(col = x, into = c("a", "b"), regex = "(.*)_(.*)", remove = F)

MT.ext[, c("a", "b") := tstrsplit(x, "_", fixed = TRUE)][] 
```


## Separate rows:

Separate a row into multiple rows based on a separator:

**Data**

```{r}
(SP <- data.table(
  val = c(1,"2,3",4), 
  date = as.Date(c("2020-01-01", "2020-01-02", "2020-01-03"), origin = "1970-01-01")
  )
)
```

```{r}
SP |> tidyr::separate_rows(val, sep = ",", convert = TRUE)
```

**Solution 1:**

```{r}
copy(SP)[, c(V1 = strsplit(val, ",", fixed = TRUE), .SD), by = val][, let(val = V1, V1 = NULL)][]
```

**Solution 2:**

```{r}
SP[, strsplit(val, ",", fixed = TRUE), by = val][SP, on = "val"][, let(val = V1, V1 = NULL)][]
```

**Solution 3:**

_(With type conversion)_

```{r}
SP[, unlist(tstrsplit(val, ",", type.convert = TRUE)), by = val][SP, on = "val"][, let(val = V1, V1 = NULL)][]
```

**Solution 4:**

```{r}
copy(SP)[rep(1:.N, lengths(strsplit(val, ",")))][, val := strsplit(val, ","), by = val][]
```

```{r}
#| eval: false
#| echo: false

# copy(SP)[rep(1:.N, lengths(strsplit(val, ",")))][, val := unlist(strsplit(SP$val, ","))][]
```

_(With type conversion)_

```{r}
#| eval: false
#| echo: false

# copy(SP)[rep(1:.N, lengths(strsplit(val, ",")))
#   ][, val := utils::type.convert(unlist(strsplit(SP$val, ",")), as.is = T, na.strings = "")][]
```

```{r}
copy(SP)[rep(1:.N, lengths(strsplit(val, ",")))
       ][, val := strsplit(val, ","), by = val
       ][, val := utils::type.convert(val, as.is = T)][]
```



<!-------------------------------------------------------->
## Duplicates:

### Duplicated rows:

**Finding duplicated rows:**

```{r}
mtcars |> group_by(mpg, hp) |> filter(n() > 1)

MT[, if(.N > 1) .SD, by = .(mpg, hp)]
```

**Only keeping non-duplicated rows:**


:::{.callout-note}
This is different from distinct/unique, which will keep one of the duplicated rows of each group.

This removes all groups which have duplicated rows.
:::

Solution 1:

```{r}
mtcars |> group_by(mpg, hp) |> filter(n() == 1)

MT[, if(.N == 1) .SD, by = .(mpg, hp)]
```

Solution 2:

_More convoluted_

```{r}
mtcars |> group_by(mpg, hp) |> filter(n() > 1) |> anti_join(mtcars, y = _)

MT[!MT[, if(.N > 1) .SD, by = .(mpg, hp)], on = colnames(MT)]

fsetdiff(MT, setcolorder(MT[, if(.N > 1) .SD, by = .(mpg, hp)], colnames(MT)))
```


### Duplicated values (per row):

```{r}
(DUPED <- data.table(
    A = c("A1", "A2", "B3", "A4"), 
    B = c("B1", "B2", "B3", "B4"), 
    C = c("A1", "C2", "D3", "C4"), 
    D = c("A1", "D2", "D3", "D4")
  )
)
```

```{r}
DUPED |> mutate(Repeats = apply(cur_data(), 1, \(r) r[which(duplicated(r))] |> unique() |> str_c(collapse = ", ")))
```

```{r}
DUPED[, Repeats := apply(.SD, 1, \(r) r[which(duplicated(r))] |> unique() |> str_c(collapse = ", "))][]
```

**With duplication counter:**

```{r}
dup_counts <- function(v) {
  rles <- as.data.table(unclass(rle(v[which(duplicated(v))])))[, lengths := lengths + 1]
  paste(apply(rles, 1, \(r) paste0(r[2], " (", r[1], ")")), collapse = ", ")
}
```

```{r}
DUPED |> mutate(Repeats = apply(cur_data(), 1, \(r) dup_counts(r)))
```

```{r}
DUPED[, Repeats := apply(.SD, 1, \(r) dup_counts(r))][]
```


<!-------------------------------------------------------->
## Expand & Complete:

Here, we are missing an entry for person B on year 2010, that we want to fill:

```{r}
(CAR <- data.table(
    year = c(2010,2011,2012,2013,2014,2015,2011,2012,2013,2014,2015), 
    person = c("A","A","A","A","A","A", "B","B","B","B","B"),
    car = c("BMW", "BMW", "AUDI", "AUDI", "AUDI", "Mercedes", "Citroen","Citroen", "Citroen", "Toyota", "Toyota")
  )
)
```

### Expand:

```{r}
tidyr::expand(CAR, person, year)
```

```{r}
CJ(CAR$person, CAR$year, unique = TRUE)
```


### Complete:

Joins the original dataset with the expanded one:

```{r}
CAR |> tidyr::complete(person, year)
```

```{r}
CAR[CJ(person, year, unique = TRUE), on = .(person, year)]
```


<!-------------------------------------------------------->
## Uncount:

Duplicating aggregated rows to get the un-aggregated version back

**Data**

```{r}
#| echo: false
#| output: false

dat_agg <- fread("
Site Domain Mild Moderate Severe
23     A1    4        0      0
27     A1    0        1      1
28     A1    0        1      0
29     A1    0        0      1
31     A1    0        1      0
33     A1    0        1      1
41     A1    3        0      1
48     A1    0        2      4
64     A1    1        0      0
66     A1    1        0      0
") |> as.data.frame() |> mutate(ID = row_number(), .before = 1)

DAT_AGG <- as.data.table(dat_agg)
```

```{r}
cols <- c("Mild", "Moderate", "Severe")

dat_agg
```

```{r}
dat_agg |> 
  tidyr::pivot_longer(cols = cols, names_to = "Severity", values_to = "Count") |> 
  tidyr::uncount(Count) |> 
  mutate(ID_new = row_number(), .after = "ID") |>
  tidyr::pivot_wider(
    names_from = "Severity", values_from = "Severity", 
    values_fn = \(x) ifelse(is.na(x), 0, 1), values_fill = 0
  )
```

_Solution 1:_

```{r}
(melt(DAT_AGG, measure.vars = cols, variable.name = "Severity", value.name = "Count")
  [rep(1:.N, Count)][, ID_new := .I] 
  |> dcast(... ~ Severity, value.var = "Severity", fun.agg = \(x) ifelse(is.na(x), 0, 1), fill = 0)
  |> DT(, -"Count")
)
```

_Solution 2:_

```{r}
DAT_AGG[Reduce(`c`, sapply(mget(cols), \(x) rep(1:.N, x)))
      ][, (cols) := lapply(.SD, \(x) ifelse(x > 1, 1, x)), .SDcols = cols
      ][order(ID)]
```


<!-------------------------------------------------------->
## List / Unlist:

When a column contains a simple vector/list of values (of the same type, without structure)

### One listed column:

**Single ID (grouping) column:**

```{r}
(mtcars_list <- mtcars |> group_by(cyl) |> summarize(mpg = list(mpg)) |> ungroup())

(MT_LIST <- MT[, .(mpg = .(mpg)), keyby = cyl])
```

_Solution 1:_

```{r}
mtcars_list |> unnest(mpg)

MT_LIST[, .(mpg = unlist(mpg)), keyby = cyl]
```

_Solution 2:_

Bypasses the need of grouping when unlisting by growing the `data.table` back to its original number of rows before unlisting.

```{r}
MT_LIST[rep(MT_LIST[, .I], lengths(mpg))][, mpg := unlist(MT_LIST$mpg)][]
```


**Multiple ID (grouping) columns:**

```{r}
(mtcars_list2 <- mtcars |> group_by(cyl, gear) |> summarize(mpg = list(mpg)) |> ungroup())

(MT_LIST2 <- MT[, .(mpg = .(mpg)), keyby = .(cyl, gear)])
```

_Solution 1:_

```{r}
mtcars_list2 |> unnest(mpg) # group_by(cyl, gear) is optional

MT_LIST2[, .(mpg = unlist(mpg)), by = setdiff(colnames(MT_LIST2), 'mpg')]
```

_Solution 2:_

_Same as with one grouping column_

```{r}
MT_LIST2[rep(MT_LIST2[, .I], lengths(mpg))][, mpg := unlist(MT_LIST2$mpg)][]
```


### Multiple listed column:

Creating the data:

```{r}
(mtcars_list_mult <- mtcars |> group_by(cyl, gear) |> summarize(across(c(mpg, disp), \(c) list(c))) |> ungroup())

(MT_LIST_MULT <- MT[, lapply(.SD, \(c) .(c)), keyby = .(cyl, gear), .SDcols = c("mpg", "disp")])
```

_Solution 1:_

```{r}
mtcars_list_mult |> unnest(c(mpg, disp)) # group_by(cyl, gear) is optional

MT_LIST_MULT[, lapply(.SD, \(c) unlist(c)), by = setdiff(colnames(MT_LIST_MULT), c("mpg", "disp"))]
```


<!-------------------------------------------------------->
## Nest / Unnest:

When a column contains a data.table/data.frame (with multiple columns, structured)

### One nested column:

**Nesting**

```{r}
(mtcars_nest <- mtcars |> tidyr::nest(data = -cyl)) # Data is inside a tibble
```

```{r}
#| eval: false

mtcars_nest <- mtcars |> nest_by(cyl) |> ungroup() # Data is inside a vctrs_list_of
```

```{r}
(MT_NEST <- MT[, .(data = .(.SD)), keyby = cyl])
```


**Unnesting**

```{r}
mtcars_nest |> unnest(data) |> ungroup()

MT_NEST[, rbindlist(data), keyby = cyl] # MT_NEST[, do.call(c, data), keyby = cyl]
```


### Multiple nested column:

**Nesting:**

```{r}
(mtcars_nest_mult <- mtcars |> group_by(cyl, gear) |> nest(data1 = c(mpg, hp), data2 = !c(cyl, gear, mpg, hp)) |> ungroup())

(MT_NEST_MULT <- MT[, .(data1 = .(.SD[, .(mpg, hp)]), data2 = .(.SD[, !c("mpg", "hp")])), keyby = .(cyl, gear)])
```

**Unnesting:**

```{r}
mtcars_nest_mult |> unnest(c(data1, data2)) |> ungroup()

MT_NEST_MULT[, c(rbindlist(data1), rbindlist(data2)), keyby = .(cyl, gear)]

MT_NEST_MULT[, do.call(c, unname(lapply(.SD, \(c) rbindlist(c)))), .SDcols = patterns('data'), keyby = .(cyl, gear)]
```


### Operate on nested/list columns:

```{r}
(mtcars_nest <- mtcars |> nest(-cyl) |> ungroup())

(MT_NEST <- MT[, .(data = .(.SD)), keyby = cyl])
```

**Creating a new column using the nested data:**

Keeping the nested column:

```{r}
mtcars_nest |> group_by(cyl) |> mutate(sum = sum(unlist(data))) |> ungroup()

copy(MT_NEST)[, sum := sapply(data, \(r) sum(r)), keyby = cyl][]
```

Dropping the nested column:

```{r}
mtcars_nest |> group_by(cyl) |> summarize(sum = sum(unlist(data))) |> ungroup()

MT_NEST[, .(sum = sapply(data, \(r) sum(r))), keyby = cyl]
```

**Creating multiple new columns using the nested data:**

```{r}
linreg <- \(data) lm(mpg ~ hp, data = data) |> broom::tidy()
```

```{r}
mtcars_nest |> group_by(cyl) |> group_modify(\(d, g) linreg(unnest(d, everything()))) |> ungroup()

MT_NEST[, rbindlist(lapply(data, \(ndt) linreg(ndt))), keyby = cyl][]
```


**Operating inside the nested data:**

```{r}
mtcars_nest |> 
  mutate(data = map(data, \(tibl) mutate(tibl, sum = pmap_dbl(cur_data(), sum)))) |> 
  unnest(data)
```

```{r}
mtcars_nest |> 
  mutate(across(data, \(tibls) map(tibls, \(tibl) mutate(tibl, sum = apply(cur_data(), 1, sum))))) |> 
  unnest(data)
```

Using the [`nplyr`](https://markjrieke.github.io/nplyr/index.html) package:

```{r}
library(nplyr)

mtcars_nest |> 
  nplyr::nest_mutate(data, sum = apply(cur_data(), 1, sum)) |> 
  unnest(data)
```

```{r}
copy(MT_NEST)[, data := lapply(data, \(dt) dt[, sum := apply(.SD, 1, sum)])
            ][, rbindlist(data), keyby = cyl]
```


<!-------------------------------------------------------->
## Rotate / Transpose:

```{r}
(MT_SUMMARY <- MT[, tidy(summary(mpg)), by = cyl])
```

**Solution 1:**

Using pivots to fully rotate the data.table:

```{r}
MT_SUMMARY |> 
  pivot_longer(!cyl, names_to = "Statistic") |> 
  pivot_wider(id_cols = "Statistic", names_from = "cyl", names_prefix = "Cyl ")
```

```{r}
MT_SUMMARY |> 
  melt(id.vars = "cyl", variable.name = "Statistic") |> 
  dcast(Statistic ~ paste0("Cyl ", cyl))
```

**Solution 2:**

```{r}
library(datawizard)

datawizard::data_rotate(MT_SUMMARY, colnames = TRUE, rownames = "Statistic")
```

```{r}
data.table::transpose(MT_SUMMARY, keep.names = "Statistic", make.names = 1)
```



<!-------------------------------------------------------->
<!-------------------------------------------------------->
# Processing examples:
***

Examples of interesting tasks that I've collected over time.

<!-------------------------------------------------------->
## Find minimum in each group:

```{r}
MT |> group_by(cyl) |> arrange(mpg) |> slice(1) |> ungroup()
```

```{r}
MT[, .SD[which.min(mpg)], keyby = cyl]
```


<!-------------------------------------------------------->
## GROUP > FILTER > MUTATE

**Data:**

```{r}
(DAT <- structure(list(
  id = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), 
  name = c("Jane", "Jane", "Jane", "Jane", "Jane", "Jane", "Jane", "Jane", "Bob", "Bob", "Bob", "Bob", "Bob", "Bob", "Bob", "Bob"), 
  year = c(1980L, 1981L, 1982L, 1983L, 1984L, 1985L, 1986L, 1987L, 1985L, 1986L, 1987L, 1988L, 1989L, 1990L, 1991L, 1992L), 
  job = c("Manager", "Manager", "Manager", "Manager", "Manager", "Manager", "Boss", "Boss", "Manager", "Manager", "Manager", "Boss", "Boss", "Boss", "Boss", "Boss"), 
  job2 = c(1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L)
  ), 
  .Names = c("id", "name", "year", "job", "job2"), 
  class = "data.frame", 
  row.names = c(NA, -16L)
) |> setDT())
```

**`Tidyverse`:**

```{r}
DAT |> group_by(name, job) |> 
  filter(job != "Boss" | year == min(year)) |> 
  mutate(cumu_job2 = cumsum(job2)) |> 
  ungroup()
```

:::{.callout-note}
Here, the grouping is done BEFORE the filter -> there will be empty groups, meaning they will sum to 0
:::

**`data.table`:**

Solution 1:

```{r}
DAT[ , .SD[job != "Boss" | year == min(year), .(cumu_job2 = cumsum(job2))], by = .(name, job)]
```

Solution 2:

```{r}
DAT[ , .(cum_job2 = cumsum(job2[job != "Boss" | year == min(year)])), by = .(name, job)]
```

Solution 3:

```{r}
DAT[DAT[, .I[job != "Boss" | year == min(year)], by = .(name, job)]$V1
  ][, cumu_job2 := cumsum(job2), by = .(name, job)][]
```

**If we filtered after the grouping:**

```{r}
DAT[job != "Boss" | year == min(year), list(cumu_job2 = cumsum(job2)), by = .(name, job)]
```


<!-------------------------------------------------------->
## GROUP > SUMMARIZE > JOIN > MUTATE

**Data:**

```{r}
(GSJM1 <- data.table(x = c(1,1,1,1,2,2,2,2), y = c("a", "a", "b", "b"), z = 1:8, key = c("x", "y")))
(GSJM2 <- data.table(x = 1:2, y = c("a", "b"), mul = 4:3, key = c("x", "y")))
```

**`Tidyverse`:**

```{r}
as.data.frame(GSJM1) |> 
  group_by(x, y) |>
  summarise(z = sum(z)) |>
  ungroup() |> 
  right_join(GSJM2) |>
  mutate(z = z * mul) |> 
  select(-mul)
```

**`data.table`:**

Basic:

```{r}
GSJM1[, .(z = sum(z)), by = .(x, y)][GSJM2][, let(z = z * mul, mul = NULL)][]
```

Advanced (using `.EACHI`):

<!-- See: https://stackoverflow.com/questions/27004002/eachi-in-data-table/27004566#27004566 -->

```{r}
GSJM1[GSJM2, .(z = sum(z) * mul), by = .EACHI]
```


<!-------------------------------------------------------->
## Separating rows & cleaning text:

**Data**

```{r}
(DT_COMA <- data.table(
  first = c(1,"2,3",3,4,5,6.5,7,8,9,0), 
  second = c(1,"2,,5",3,4,5,"6,5,9",7,8,9,0), 
  third = c("one", "two", "thr,ee", "four", "five", "six", "sev,en", "eight", "nine", "zero"), 
  fourth = as.Date(c(1/1/2020, 2/1/2020, 3/1/2020, 4/1/2020, 5/1/2020, 6/1/2020, 7/1/2020, 8/1/2020, 9/1/2020, 10/1/2020), origin = "1970-01-01")
  )
)
```

### Step1: Cleaning

Removing unwanted commas within words

**`Tidyverse`:**

```{r}
DT_COMA |> mutate(across(where(\(v) is.character(v) & all(is.na(as.numeric(v)))), \(v) str_remove_all(v, ",")))
```

**`data.table`:**

```{r}
cols_to_clean <- DT_COMA[, .SD, .SDcols = \(v) is.character(v) & all(is.na(as.numeric(v)))] |> colnames()

copy(DT_COMA)[, c(cols_to_clean) := map(.SD[, cols_to_clean, with = F], \(v) str_remove_all(v, ","))][]
```


### Step 2: Separating rows

Each numeric row that has multiple comma-separated values has to be split into multiple rows (one value per row)

**`Tidyverse`:**

```{r}
cols_to_separate <- DT_COMA |> select(where(\(v) is.character(v) & any(!is.na(as.numeric(v))))) |> colnames()

reduce(
  cols_to_separate, 
  \(acc, col) acc |> tidyr::separate_rows(col, sep = ",", convert = T), 
  .init = DT_COMA
)
```

**`data.table`:**

```{r}
cols_to_separate <- DT_COMA[, .SD, .SDcols = \(v) is.character(v) & any(!is.na(as.numeric(v)))] |> colnames()

(reduce(
  cols_to_separate,
  \(acc, col) acc[rep(1:.N, lengths(strsplit(get(col), ",")))][, (col) := type.convert(unlist(strsplit(acc[[col]], ",", fixed = T)), as.is = T, na.strings = "")],
  .init = DT_COMA
))[]
```


### Combining both steps:

**`Tidyverse`:**

```{r}
DT_COMA <- DT_COMA |> mutate(across(where(\(v) is.character(v) & all(is.na(as.numeric(v)))), \(v) str_remove_all(v, ",")))

reduce(
  select(DT_COMA, where(\(v) is.character(v) & any(!is.na(as.numeric(v))))) |> colnames(), 
  \(acc, col) acc |> tidyr::separate_rows(col, sep = ",", convert = T), 
  .init = DT_COMA
)
```

**`data.table`:**

```{r}
cols_to_clean <- DT_COMA[, .SD, .SDcols = \(v) is.character(v) & all(is.na(as.numeric(v)))] |> colnames()
cols_to_separate <- DT_COMA[, .SD, .SDcols = \(v) is.character(v) & any(!is.na(as.numeric(v)))] |> colnames()

DT_COMA[, c(cols_to_clean) := map(.SD[, cols_to_clean, with = F], \(v) str_remove_all(v, ","))]

(reduce(
  cols_to_separate,
  \(acc, col) acc[rep(1:.N, lengths(strsplit(get(col), ",")))][, (col) := type.convert(unlist(strsplit(acc[[col]], ",", fixed = T)), as.is = T, na.strings = "")],
  .init = DT_COMA
))[]
```


<!-------------------------------------------------------->
## Multiple choice questions:

**Data:**

```{r}
#| echo: false
#| output: false

surv <- data.frame(
  ID = c(1:5),
  response = c(
    "I read the assigned readings.|I reread my notes.|I worked with one or more classmates.",
    "I read the assigned readings.|I reviewed this week's slides.",
    "I worked on practice problems.|I read the assigned readings.|I reread my notes.",
    "I worked on practice problems.|I read the assigned readings.|I reread my notes.",
    "I worked on practice problems.|I read the assigned readings.|I reread my notes.|I reviewed this week's slides.|I worked with one or more classmates."
  )
)

SURV <- as.data.table(surv)
```

```{r}
surv
```

Here we will spread the answers into their own columns using a pivot because not all rows have all the possible answers:

**`Tidyverse`:**

```{r}
surv |> 
  mutate(response = str_split(response, fixed("|"))) |> 
  unnest(response) |> 
  pivot_wider(id_cols = ID, names_from = response, values_from = response, values_fn = \(.x) sum(!is.na(.x)), values_fill = 0)
```

**`data.table`:**

```{r}
SURV[, c(.SD, tstrsplit(response, "|", fixed = T))][, -"response"] |> 
  melt(measure.vars = patterns("^V")) |> 
  dcast(ID ~ value, fun.agg = \(.x) sum(!is.na(.x)), subset = .(!is.na(value)))
```


<!-------------------------------------------------------->
## Filling with lagging conditions:

**Task:** See [this SO question](https://stackoverflow.com/questions/71952593/filling-rows-of-multiple-columns-based-on-multiple-conditions).

**Data:**

```{r}
ZIP <- structure(
  list(
    zipcode = c(1001, 1002, 1003, 1004, 1101, 1102, 1103, 1104, 1201, 1202, 1203, 1302), 
    areacode = c(4, 4, NA, 4, 4, 4, NA, 1, 4, 4, NA, 4), 
    type = structure(c(1L, 1L, NA, 1L, 2L, 2L, NA, 1L, 1L, 1L, NA, 1L), .Label = c("clay", "sand"), class = "factor"), 
    region = c(3, 3, NA, 3, 3, 3, NA, 3, 3, 3, NA, 3), 
    do_not_fill = c(1, NA, NA, 1, 1, NA, NA, 1, NA, NA, NA, 1)
    ), 
  class = c("data.table", "data.frame"), row.names = c(NA, -4L)
)
```

**`Tidyverse`:**

```{r}
as_tibble(ZIP) |>
  mutate(type = as.character(type)) |>
  mutate(
    across(1:4, ~ ifelse(
        is.na(.) & lag(areacode) == lead(areacode) & 
          lag(as.numeric(substr(zipcode, 1, 2))) == lead(as.numeric(substr(zipcode, 1, 2))),
        lag(.), .
      )
    )
  )
```

**`data.table`:**

```{r}
ZIP[, c(lapply(.SD, \(v) {fifelse(
  is.na(areacode) & lag(areacode) == lead(areacode) &
    lag(as.numeric(substr(zipcode, 1, 2))) == lead(as.numeric(substr(zipcode, 1, 2))), lag(v), v)}), 
  .SD[, .(do_not_fill)]), .SDcols = !patterns("do_not_fill")]
```


<!-------------------------------------------------------->
## Join + Coalesce:

**Task:** Replace the missing dates from one dataset with the earliest date from another dataset, matching by ID:

**Data:**

```{r}
(dt1 <- data.table::fread(
"
      id  x       y   z         
     1    A       1    NA        
     2    C       3    NA        
     3    C       3    NA        
     4    C       2    NA        
     5    B       2    2019-08-04
     6    C       1    2019-09-18
     7    B       3    2019-12-17
     8    A       2    2019-11-02
     9    A       3    2020-03-16
    10    A       1    2020-01-31
"
))

(dt2 <- data.table::fread(
"      id      date
      1      2012-09-25
      1      2012-03-26
      1      2012-11-12
      2      2013-01-24
      2      2012-05-04
      2      2012-02-24
      3      2012-05-30
      3      2012-02-15
      4      2012-03-13
      4      2012-05-18
"))
```

**`Tidyverse`:**

Using `coalesce`:

```{r}
left_join(
  dt1, 
  dt2 |> group_by(id) |> summarize(date = min(date)), 
  by = "id"
) |> mutate(date = coalesce(z, date), z = NULL)
```

Using the [`rows_*` functions](https://dplyr.tidyverse.org/reference/rows.html):

```{r}
rows_patch(
  dt1 |> rename(date = z), 
  dt2 |> group_by(id) |> summarize(date = min(date)), 
  by = "id"
)
```

**`data.table`:**

As a right join:

```{r}
copy(dt2)[, .(date = min(date)), by = id
  ][dt1, on = "id"][, let(date = fcoalesce(date, z), z = NULL)][]
```

As a left join:

```{r}
copy(dt1)[dt2[, .(date = min(date)), by = id], c("id", "date") := .(i.id, i.date), on = "id"
  ][, let(date = fcoalesce(date, z), z = NULL)][]
```


<!-------------------------------------------------------->
## Join on multiple columns (partial matching):

**Task:** Join both tables based on matching IDs, but the IDs are split between multiple columns in one table (`id1` & `id2`).

```{r}
(dt1 <- data.table(id = c("ABC", "AAA", "CBC"), x = 1:3))

(dt2 <- data.table(
  id1 = c("ABC", "AA", "CB"), 
  id2 = c("AB", "AAA", "CBC"), 
  y = c(0.307, 0.144, 0.786))
)
```

**Solution 1:**

Combine the two ID columns into one with `pivot_longer`, then join:

```{r}
dt2 |> pivot_longer(matches("^id"), names_to = NULL, values_to = "id") |> right_join(dt1)
```

```{r}
melt(dt2, measure.vars = patterns("^id"), value.name = "id")[, variable := NULL][dt1, on = "id"]
```


**Solution 2:**

Combine the two ID columns into one with `unite` + `separate_rows`, then join:

_(From [@TimTeaFan](https://twitter.com/TimTeaFan/status/1534492468787421187)_

```{r}
dt2 |> unite("id", id1, id2, sep = "_") |> separate_rows("id") |> right_join(dt1)
```

```{r}
copy(dt2)[, id := paste(id1, id2, sep = "_")
        ][, c(V1 = strsplit(id, "_", fixed = TRUE), .SD), by = id
        ][, let(id = V1, V1 = NULL, id1 = NULL, id2 = NULL)
        ][dt1, on = "id"]
```


**Solution 3:**

Join on one of the two columns (`id2` here), and then fill in (patch) the missing values:

```{r}
left_join(dt2, dt1, by = c("id2" = "id")) |> 
  rows_patch(rename(dt1, id1 = id), unmatched = "ignore")
```


## Merging rows across multiple columns (every X rows):

**Data:**

```{r}
(BANK <- data.table(
    date = c("30 feb", "NA", "NA", "NA", "31 feb", "NA", "NA", "NA"), 
    description = c("Mary", "had a", "little", "lamb", "Twinkle", "twinkle", "little", "star"), 
    withdrawal = c("100", "NA", "NA", "NA", "NA", "NA", "NA", "NA"), 
    deposit = c("NA", "NA", "NA", "NA", "100", "NA", "NA", "NA")
  )[, lapply(.SD, \(c) type.convert(c, as.is = T))]
)
```

```{r}
merge_and_convert <- function(v) {
  type.convert(v, as.is = T) |> na.omit() |> 
    paste(collapse = " ") |> type.convert(as.is = T) |> 
    bind(x, ifelse(is.logical(x), as.integer(x), x))
}
```

**`Tidyverse`:**

Solution 1:

```{r}
mutate(BANK, ID = ceiling(seq_along(row_number())/4)) |> 
  group_by(ID) |> 
  summarize(across(everything(), \(m) merge_and_convert(m)))
```

Solution 2:

```{r}
summarize(BANK, across(
  everything(), 
  \(c) sapply(split(c, ceiling(seq_along(c)/4)), \(m) merge_and_convert(m))
))
```

**`data.table`:**

```{r}
BANK[, lapply(.SD, \(c) sapply(split(c, ceiling(seq_along(c)/4)), \(m) merge_and_convert(m)))]
```


```{r}
copy(BANK)[, ID := ceiling(seq_along(.I)/4)][, lapply(.SD, \(m) merge_and_convert(m)), by = ID][]
```


<!-------------------------------------------------------->
## Tagging successive events:

Tagging repeated blocks of events (aka _run length encoding_):

```{r}
(dat <- data.frame(event = c(
  rep("A", 3),
  rep("B", 5),
  rep("C", 2),
  rep("B", 2),
  rep("A", 3)
)))

DAT <- as.data.table(dat)
```

**Manually:**

```{r}
dat |> mutate(ID = with(rle(event), rep(seq_along(lengths), lengths)))

dat |> mutate(ID = c(0, cumsum(diff(as.integer(factor(event))) != 0)) + 1)
```

**`Tidyverse`:**

```{r}
dat |> mutate(ID = consecutive_id(event))
```

**`data.table`:**

```{r}
DAT[, ID := rleid(event)][]
```


<!-------------------------------------------------------->
<!-------------------------------------------------------->
# Miscellaneous:
***

<!-------------------------------------------------------->
## Keywords:

.SD  
.I, .N  
.GRP, .NGRP  
.BY  
.EACHI  

<!-------------------------------------------------------->
## Useful functions:

`fsetdiff`, `fintersect`, `funion` and `fsetequal` (apply to data.tables instead of vectors)

`nafill`, `fcoalesce`

`as.IDate`

***

![](http://vignette2.wikia.nocookie.net/creepypasta/images/1/11/Thats_all_folks.svg.png)