---
title: "NAV-VIR"
subtitle: "Virtual Map exploration for Visually Impaired People"
date: 2018-09
doi: "PHC Polonium (French-Polish EU grant)" # TODO: make specific param

author:
  - "[LITIS (Rouen, France)](https://www.litislab.fr/en/)"
  - "[Institute of Electronics (Lodz, Poland)](http://www.eletel.p.lodz.pl/eng/)"

image: F2T-v2-render.png
image-alt: "3D rendering of the F2T, the main device used during the NAV-VIR project"

description: "Developing a multi-modal interface for Visually Impaired People to virtually explore a map in order to prepare for a journey."

abstract: |
  The goal of the NAV-VIR project was to develop a multimodal interface to allow Visually Impaired People in virtually discovering and exploring unknown areas from the safety of their home. It relies on an interactive Force-Feedback Tablet, the F2T, and an immersive HRTF-based 3D audio simulation relying on binaural recordings of real environments.

categories:
  - "Assistive Devices"
  - "Accessibility"
  - "Visual Impairment"
  - "Virtual Reality"
  - "Sensory Substitution"
  - "Haptic Interface"
  - "Auditory Interface"

# Dirty trick to get some links/buttons
about:
  links:
    - text: "Article"
      icon: file-pdf
      url: content/pubs/NER19/
      aria-label: "See an article about the project"
    - text: "Poster"
      icon: file-image
      url: content/projects/NAV-VIR/poster.pdf
      aria-label: "See a poster about the project"
---

<hr style="margin-bottom: 30px; margin-top: -12px">

# Project summary
***

<!--# TODO: summary -->

*To Be Filled*

## Our interface: F2T (v2)

During this project, we improved upon the first iteration of the **Force Feedback Tablet (F2T)** from the [TETMOST project](/content/projects/TETMOST/) to design the finalized prototype of this interface:

:::{layout='[46,54]'}

![](F2T-v2.jpg){fig-alt="Photo of the F2T interface"}

![](F2T-explanation.png){fig-alt="Schema explaining the F2T interface"}

:::

## Our tools

**1)** We developed a Java application to create or convert images into simplified tactile representations, which can then be explored using the F2T:

![](F2T-interface.png){fig-alt="Screenshot of the F2T control interface"}

**2)** We investigated and developed tools to automatically generate a navigation graph from a floor plan, which can then be converted into a tactile image and explored with the F2T:

![](map-graph.png){fig-alt="Illustrations of the navigation graph generation"}

# My role in this project
***

**1)** Participate in the development of a [Java app](https://github.com/ma-riviere/F2T-interface) to control the F2T and display tactile "images".

**2)** Help design the first round of experimental evaluations, where participants where tasked with recognizing simple geometrical shapes, as well as the layout of a simple mock apartment.

:::{layout='[40,60]' layout-valign="center"}

![](exp-setup.png){fig-alt="A drawing illustrating the experimental setup of NAV-VIR"}

![](rooms.png){fig-alt="A drawing illustrating the experimental setup of NAV-VIR"}

:::

**3)** Write a first-author [conference article](/content/pubs/NER19/) and a [poster](poster.pdf).