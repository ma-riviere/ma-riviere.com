---
title: "NAV-VIR"
subtitle: "Virtual Map exploration for Visually Impaired People"
date: 2018-09

author:
  - name: "LITIS"
    url: "https://www.litislab.fr/"
  - name: "Institute of Electronics"
    url: "http://www.eletel.p.lodz.pl/eng/"

image: feature.png
image-alt: "3D rendering of the F2T, the main device used during the NAV-VIR project"

description: "Developing a multi-modal interface for Visually Impaired People to virtually explore a map in order to prepare for a journey."

abstract: |
  The goal of the NAV-VIR project was to develop a multimodal interface to allow Visually Impaired People in virtually discovering and exploring unknown areas from the safety of their home. It relies on an interactive Force-Feedback Tablet, the F2T, and an immersive HRTF-based 3D audio simulation relying on binaural recordings of real environments.

website:
  open-graph:
    image: feature.png
    description: "An audio-tactile interface for virtually exploring maps and preparing journeys"
  twitter-card:
    image: feature.png
    description: "An audio-tactile interface for virtually exploring maps and preparing journeys"

categories:
  - Research
  - Software Engineering
  - Java
  - Human-Computer Interaction
  - Virtual Reality

# Dirty trick to get some links/buttons
about:
  template: solana
  links:
    - text: "Article"
      icon: file-pdf
      file: /content/pubs/NER19/
      aria-label: "See an article about the project"
    - text: "Poster"
      icon: file-image
      url: /content/projects/NAV-VIR/poster.pdf
      aria-label: "See a poster about the project"
---

{{< include /content/_hr.qmd >}}

![](feature.png){fig-alt="Image illustrating the project"}

# Introduction
***

<!--# TODO: summary -->

*To Be Filled*

## Our interface: F2T (v2)

During this project, we improved upon the first iteration of the **Force Feedback Tablet (F2T)** from the [TETMOST project](/content/projects/TETMOST/) to design the finalized prototype of this interface:

:::{layout='[46,54]'}

![](F2T-v2.jpg){fig-alt="Photo of the F2T interface"}

![](F2T-explanation.png){fig-alt="Schema explaining the F2T interface"}

:::


# Outcomes
***

**1)** We developed a Java application to create or convert images into simplified tactile representations, which can then be explored using the F2T:

![](F2T-interface.png){fig-alt="Screenshot of the F2T control interface"}

**2)** We investigated and developed tools to automatically generate a navigation graph from a floor plan, which can then be converted into a tactile image and explored with the F2T:

![](map-graph.png){fig-alt="Illustrations of the navigation graph generation"}


# My role in this project
***

**1)** Participated in the development of a [Java app](https://github.com/ma-riviere/F2T-interface) to control the F2T and display tactile "images".

**2)** Helped design the first round of experimental evaluations, where participants where tasked with recognizing and re-drawing simple geometrical shapes, as well as the layout of a simple mock apartment.

:::{layout='[40,60]' layout-valign="center"}

![](exp-setup.png){fig-alt="A drawing illustrating the experimental setup of NAV-VIR"}

![](rooms.png){fig-alt="A drawing illustrating the experimental setup of NAV-VIR"}

:::

**3)** Wrote a first-author [conference article](/content/pubs/NER19/) and a [poster](poster.pdf).