---
title: "NAV-VIR"
subtitle: "Virtual Map exploration for Visually Impaired People"
date: 2017-09
doi: "PHC Polonium (French-Polish EU grant)" # TODO: make specific param

author:
  - "[LITIS (Rouen, France)](https://www.litislab.fr/en/)"
  - "[Institute of Electronics (Lodz, Poland)](http://www.eletel.p.lodz.pl/eng/)"

image: F2T.jpg
image-alt: "Photography of the F2T, the main device used during the NAV-VIR project"

description: "Developing a multi-modal interface for Visually Impaired People to virtually explore a map in order to prepare for a journey"

abstract: |
  The goal of the NAV-VIR project was to develop a multimodal interface to allow Visually Impaired People in virtually discovering and exploring unknown areas from the safety of their home. It relies on an interactive Force-Feedback Tablet, the F2T, and an immersive HRTF-based 3D audio simulation relying on binaural recordings of real environments.

categories:
  - "Assistive Devices"
  - "Accessibility"
  - "Visual Impairment"
  - "Virtual Reality"
  - "Sensory Substitution"
  - "Haptic Interface"
  - "Auditory Interface"

# Dirty trick to get some links/buttons
about:
  links:
    - text: "Article"
      icon: file-pdf
      url: content/pubs/NER19/index.qmd
      aria-label: "See an article illustrating the project"
---

{{< include ../../additional-links.qmd >}}

## Project's summary

<!-- TODO: photo & descriptif F2T -->

## My role in this project

**My role in this project was many-fold:**

1) Participated in the development of a [Java application](https://github.com/ma-riviere/F2T-interface) to control the F2T, and to display various tactile "images".

2) Participate in the first round of experimental evaluations where participants where tasked with recognizing simple geometrical shapes, as well as the layout of mock appartment.