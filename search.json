[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Marc-Aurèle Rivière",
    "section": "",
    "text": "Cognitive Neuroscientist with a keen interest in Perception, Spatial Cognition, Memory, and Human-Machine Interfaces.\nI’m a recovering academic who worked on several projects at the intersection between Cognitive Neurosciences and Biomedical Engineering. Those projects aimed to develop and evaluate wearable assistive devices for Visually Impaired People (VIP), providing them with a non-visual experience of their surroundings through a clever use of :Computer Vision and Augmented Reality, within the :Sensory Substitution framework.\nI have since retrained as a Data Scientist with a fondness for Bayesian methods and an unhealthy obsession with the R ecosystem and its community. I also dabble in more generic programming language such as Java, C# (Unity), and JavaScript.\n\n\n\n\n\n\n\n\n\n\nI use this website to gather information on the various projects I have worked on, my publications and scientific communications, as well as some blog posts (which mainly pertain to R and statistics). I also maintain an up-to-date resumé."
  },
  {
    "objectID": "content/about.html",
    "href": "content/about.html",
    "title": "About Me",
    "section": "",
    "text": "PhD in Cognitive Neurosciences (2017-2020)Unfinished - COVIDUniversity of Rouen-Normandy\nMSc in Cognitive Neurosciences (2015-2016)Grenoble INP - Phelma\nMSc in Organisational Psychology (2013-2015)University of Strasbourg"
  },
  {
    "objectID": "content/about.html#fa-address-book-contact-me",
    "href": "content/about.html#fa-address-book-contact-me",
    "title": "About Me",
    "section": "\n Contact Me",
    "text": "Contact Me\nYou can send me an email or directly message me on twitter at @mariviere1"
  },
  {
    "objectID": "content/about.html#fa-location-dot-location",
    "href": "content/about.html#fa-location-dot-location",
    "title": "About Me",
    "section": "\n Location",
    "text": "Location\nOffice U2.1.51, LITIS Lab, Saint-Etienne-du-Rouvray, France."
  },
  {
    "objectID": "content/about.html#fa-gears-about-this-site",
    "href": "content/about.html#fa-gears-about-this-site",
    "title": "About Me",
    "section": "\n About this site",
    "text": "About this site\nThis website was made with Quarto and R.\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.1 (2022-06-23)\n os       Ubuntu 20.04.4 LTS\n system   x86_64, linux-gnu\n ui       X11\n language (EN)\n collate  C.UTF-8\n ctype    C.UTF-8\n tz       Europe/Paris\n date     2022-09-20\n pandoc   2.19.2\n Quarto   1.1.251\n\n─ Packages ───────────────────────────────────────────────────────────────────\n ! package     * version    date (UTC) lib source\n P bayesplot   * 1.9.0      2022-03-10 [?] CRAN (R 4.2.0)\n P cmdstanr    * 0.5.2      2022-09-16 [?] Github (ma-riviere/cmdstanr@8c77d4a)\n P crayon      * 1.5.1      2022-03-26 [?] CRAN (R 4.2.0)\n P data.table  * 1.14.3     2022-07-27 [?] Github (Rdatatable/data.table@c4a2085)\n P DBI         * 1.1.3      2022-06-18 [?] CRAN (R 4.2.0)\n P dbplyr      * 2.2.1      2022-06-27 [?] CRAN (R 4.2.0)\n P downlit     * 0.4.2      2022-07-05 [?] CRAN (R 4.2.0)\n P dplyr       * 1.0.10     2022-09-01 [?] CRAN (R 4.2.1)\n P dtplyr      * 1.2.2      2022-08-20 [?] CRAN (R 4.2.1)\n P duckdb      * 0.5.0      2022-09-03 [?] https://duckdb.r-universe.dev (R 4.2.1)\n P fuzzyjoin   * 0.1.6      2020-05-15 [?] CRAN (R 4.2.0)\n P ggplot2     * 3.3.6      2022-05-03 [?] CRAN (R 4.2.0)\n P ggradar     * 0.2        2022-09-16 [?] Github (ricardo-bion/ggradar@568537a)\n P ggridges    * 0.5.3      2021-01-08 [?] CRAN (R 4.2.0)\n P ggtext      * 0.1.2      2022-09-16 [?] CRAN (R 4.2.1)\n P gt          * 0.7.0      2022-08-25 [?] CRAN (R 4.2.1)\n P gtExtras    * 0.4.2.9000 2022-09-17 [?] Github (jthomasmock/gtExtras@d40baad)\n P gtools      * 3.9.3      2022-07-11 [?] CRAN (R 4.2.0)\n P here        * 1.0.1      2020-12-13 [?] CRAN (R 4.2.0)\n P lubridate   * 1.8.0      2021-10-07 [?] CRAN (R 4.2.0)\n P patchwork   * 1.1.2      2022-08-19 [?] CRAN (R 4.2.1)\n P posterior   * 1.3.1      2022-09-06 [?] CRAN (R 4.2.1)\n P purrr       * 0.3.4      2020-04-17 [?] CRAN (R 4.2.0)\n P quarto      * 1.2        2022-07-06 [?] CRAN (R 4.2.0)\n P readr       * 2.1.2      2022-01-30 [?] CRAN (R 4.2.0)\n P RSQLite     * 2.2.17     2022-09-10 [?] CRAN (R 4.2.1)\n P sessioninfo * 1.2.2      2021-12-06 [?] CRAN (R 4.2.0)\n P stringr     * 1.4.1      2022-08-20 [?] CRAN (R 4.2.1)\n P tibble      * 3.1.8      2022-07-22 [?] CRAN (R 4.2.0)\n P tidybayes   * 3.0.2      2022-01-05 [?] CRAN (R 4.2.0)\n P tidyr       * 1.2.1      2022-09-08 [?] CRAN (R 4.2.1)\n P xml2        * 1.3.3      2021-11-30 [?] CRAN (R 4.2.0)\n\n [1] /home/mar/Dev/Projects/R/ma-riviere.me/renv/library/R-4.2/x86_64-pc-linux-gnu\n [2] /usr/lib/R/library\n\n P ── Loaded and on-disk path mismatch.\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "content/outreach/index.html",
    "href": "content/outreach/index.html",
    "title": "Outreach Activities",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\nCollege Fair of the University of Rouen\n\n\nPresenting my doctoral research project to highschool students during the College Fair of Fall 2017 ()\n\n\n\n\n\n\n\n\n\n\n\nExpérimentarium Science Fair\n\n\nPresenting my doctoral research project to a wide-ranging public of all backgrounds (from middle-school students to adults), during a yearly 3-days long science fair…\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "content/outreach/index.html#conferences-seminars",
    "href": "content/outreach/index.html#conferences-seminars",
    "title": "Outreach Activities",
    "section": "Conferences & Seminars",
    "text": "Conferences & Seminars\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nACCESSPACE: overview and future prospects\n\n\nRencontres Universitaires Numériques Normandes (RUNN’19)\n\n\n\nAssistive Devices\n\n\nAccessibility\n\n\nSensory Substitution\n\n\nSpatial Cognition\n\n\n\n\nAn overview of the ACCESSPACE project’s progress and future endeavors ()\n\n\n\n\n\n\nNov 21, 2019\n\n\nCaen, France\n\n\n\n\n\n\n\n\nSpatial Cognition and Computer Vision for better assistive devices\n\n\nFrench-Norwegian Workshop Day (2019)\n\n\n\nAssistive Devices\n\n\nAccessibility\n\n\nSensory Substitution\n\n\nSpatial Cognition\n\n\nComputer Vision\n\n\n\n\nAcademic talk presenting my work on using Cognitive Neurosciences and Computer Vision to develop better assistive devices for VIP\n\n\n\n\n\n\nJun 2, 2019\n\n\nTrondheim, Norway\n\n\n\n\n\n\n\n\nSensory substitution as a framework to access visual and spatial information for VIP\n\n\nSKERI Brown Bag\n\n\n\nAssistive Devices\n\n\nAccessibility\n\n\nSpatial Cognition\n\n\nSensory Substitution\n\n\nComputer Vision\n\n\n\n\nSeminar hosted at Smith-Kettlewell Eye-Research Institute, presenting the Sensory Substitution framework and its use in designing non-visual interfaces for VIP\n\n\n\n\n\n\nJan 9, 2019\n\n\nSan Francisco, USA\n\n\n\n\n\n\n\n\nTactiBelt: an Electronic Travel Aid prototype for VIP\n\n\nInt. Conf. on Computers Helping People (ICCHP’18)\n\n\n\nAssistive Devices\n\n\nAccessibility\n\n\nSpatial Cognition\n\n\nSensory Substitution\n\n\nVirtual Reality\n\n\n\n\nShort academic talk given during the ICCHP 2018 international conference to present the TactiBelt\n\n\n\n\n\n\nJul 12, 2018\n\n\nLinz, Austria\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "content/outreach/scicom/Exp-JPO/index.html",
    "href": "content/outreach/scicom/Exp-JPO/index.html",
    "title": "Percieving our world without vision",
    "section": "",
    "text": "Here is a video recording of a talk I gave to high-school students during my University’s College Fair, in collaboration with the Expérimentarium program, filmed by the University:"
  },
  {
    "objectID": "content/outreach/scicom/Exp/index.html",
    "href": "content/outreach/scicom/Exp/index.html",
    "title": "Developing assistive decives for VIP: an overview",
    "section": "",
    "text": "For 3 years (2017 to 2020), I participated in the Experimentarium program: a French initiative to popularize research to the wider public. During the year, they would organize single-day interventions of multiple PhD students into local middle & high-schools, where we would each present our research in an accessible manner to multiple groups of students, and answer their questions about the academic world.\nIn addition to that, once a year, they would organize a 3-days long science fair in one French city, where all the PhD students involved in the program (from all around France) would gather and present their research in different settings and in different formats (from interactive presentations in schools to “speed searching” in cafés, or linking our research to relevant Art pieces in Museums, …)."
  },
  {
    "objectID": "content/outreach/talks/FR-NO/index.html",
    "href": "content/outreach/talks/FR-NO/index.html",
    "title": "Spatial Cognition and Computer Vision for better assistive devices",
    "section": "",
    "text": "Slides"
  },
  {
    "objectID": "content/outreach/talks/ICCHP18/index.html",
    "href": "content/outreach/talks/ICCHP18/index.html",
    "title": "TactiBelt: an Electronic Travel Aid prototype for VIP",
    "section": "",
    "text": "Slides"
  },
  {
    "objectID": "content/outreach/talks/RUNN19/index.html",
    "href": "content/outreach/talks/RUNN19/index.html",
    "title": "ACCESSPACE: overview and future prospects",
    "section": "",
    "text": "This talk got the best presentation award of RUNN’19 🥇"
  },
  {
    "objectID": "content/outreach/talks/SKERI/index.html",
    "href": "content/outreach/talks/SKERI/index.html",
    "title": "Sensory substitution as a framework to access visual and spatial information for VIP",
    "section": "",
    "text": "Slides"
  },
  {
    "objectID": "content/posts/big-bayes/index.html#stan-setup",
    "href": "content/posts/big-bayes/index.html#stan-setup",
    "title": "MCMC for ‘Big Data’ with Stan",
    "section": "\n1.1 Stan setup",
    "text": "1.1 Stan setup\n\nInstalling CmdStancmdstanr::check_cmdstan_toolchain(fix = TRUE, quiet = TRUE)\n\ncpp_opts <- list(\n  stan_threads = TRUE\n  , STAN_CPP_OPTIMS = TRUE\n  , STAN_NO_RANGE_CHECKS = TRUE # WARN: remove this if you haven't tested the model\n  , PRECOMPILED_HEADERS = TRUE\n  , CXXFLAGS_OPTIM = \"-march=native -mtune=native\"\n  , CXXFLAGS_OPTIM_TBB = \"-mtune=native -march=native\"\n  , CXXFLAGS_OPTIM_SUNDIALS = \"-mtune=native -march=native\"\n)\n\ncmdstanr::install_cmdstan(cpp_options = cpp_opts, quiet = TRUE)\n\n\n\nLoading CmdStan (if already installed)highest_cmdstan_version <- fs::dir_ls(config$cmdstan_path) |> fs::path_file() |> \n  keep(\\(e) str_detect(e, \"cmdstan-\")) |> \n  bind(x, str_split(x, '-', simplify = TRUE)[,2]) |> \n  reduce(\\(x, y) ifelse(utils::compareVersion(x, y) == 1, x, y))\n\nset_cmdstan_path(glue::glue(\"{config$cmdstan_path}cmdstan-{highest_cmdstan_version}\"))\n\n\n\nSetting up knitr’s engine for CmdStan## Inspired by: https://mpopov.com/blog/2020/07/30/replacing-the-knitr-engine-for-stan/\n\n## Note: We could haved use cmdstanr::register_knitr_engine(), \n##       but it wouldn't include compiler optimizations & multi-threading by default\n\nknitr::knit_engines$set(\n  cmdstan = function(options) {\n    output_var <- options$output.var\n    if (!is.character(output_var) || length(output_var) != 1L) {\n      stop(\n        \"The chunk option output.var must be a character string \",\n        \"providing a name for the returned `CmdStanModel` object.\"\n      )\n    }\n    if (options$eval) {\n      if (options$cache) {\n        cache_path <- options$cache.path\n        if (length(cache_path) == 0L || is.na(cache_path) || cache_path == \"NA\") \n          cache_path <- \"\"\n        dir <- paste0(cache_path, options$label)\n      } else {\n        dir <- tempdir()\n      }\n      file <- write_stan_file(options$code, dir = dir, force_overwrite = TRUE)\n      mod <- cmdstan_model(\n        file, \n        cpp_opts <- list(\n          stan_threads = TRUE\n          , STAN_CPP_OPTIMS = TRUE\n          , STAN_NO_RANGE_CHECKS = TRUE # The model was already tested\n          , PRECOMPILED_HEADERS = TRUE\n          # , CXXFLAGS_OPTIM = \"-march=native -mtune=native\"\n          , CXXFLAGS_OPTIM_TBB = \"-mtune=native -march=native\"\n          , CXXFLAGS_OPTIM_SUNDIALS = \"-mtune=native -march=native\"\n        ),\n        stanc_options = list(\"Oexperimental\")\n      )\n      assign(output_var, mod, envir = knitr::knit_global())\n    }\n    options$engine <- \"stan\"\n    code <- paste(options$code, collapse = \"\\n\")\n    knitr::engine_output(options, code, '')\n  }\n)\n\n\n\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting        value\n version        R version 4.2.1 (2022-06-23)\n os             Ubuntu 20.04.4 LTS\n system         x86_64, linux-gnu\n ui             X11\n language       (EN)\n collate        C.UTF-8\n ctype          C.UTF-8\n tz             Europe/Paris\n date           2022-09-20\n pandoc         2.19.2\n Quarto         1.1.251\n Stan (CmdStan) 2.30.1\n\n─ Packages ───────────────────────────────────────────────────────────────────\n ! package    * version date (UTC) lib source\n P bayesplot  * 1.9.0   2022-03-10 [?] CRAN (R 4.2.0)\n P cmdstanr   * 0.5.2   2022-09-16 [?] Github (ma-riviere/cmdstanr@8c77d4a)\n P data.table * 1.14.3  2022-07-27 [?] Github (Rdatatable/data.table@c4a2085)\n P dplyr      * 1.0.10  2022-09-01 [?] CRAN (R 4.2.1)\n P ggplot2    * 3.3.6   2022-05-03 [?] CRAN (R 4.2.0)\n P ggridges   * 0.5.3   2021-01-08 [?] CRAN (R 4.2.0)\n P here       * 1.0.1   2020-12-13 [?] CRAN (R 4.2.0)\n P lubridate  * 1.8.0   2021-10-07 [?] CRAN (R 4.2.0)\n P patchwork  * 1.1.2   2022-08-19 [?] CRAN (R 4.2.1)\n P pipebind   * 0.1.1   2022-08-10 [?] CRAN (R 4.2.0)\n P posterior  * 1.3.1   2022-09-06 [?] CRAN (R 4.2.1)\n P purrr      * 0.3.4   2020-04-17 [?] CRAN (R 4.2.0)\n P stringr    * 1.4.1   2022-08-20 [?] CRAN (R 4.2.1)\n P tidyr      * 1.2.1   2022-09-08 [?] CRAN (R 4.2.1)\n\n [1] /home/mar/Dev/Projects/R/ma-riviere.me/renv/library/R-4.2/x86_64-pc-linux-gnu\n [2] /usr/lib/R/library\n\n P ── Loaded and on-disk path mismatch.\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "content/posts/big-bayes/index.html#matches-data",
    "href": "content/posts/big-bayes/index.html#matches-data",
    "title": "MCMC for ‘Big Data’ with Stan",
    "section": "\n2.1 Matches data",
    "text": "2.1 Matches data\nLoading the raw matches data:\n\n\n\n\nmatches_data_raw <- purrr::map_dfr(\n  fs::dir_ls(matches_data_path, regexp = \"atp_matches_(.*).csv\"),\n  \\(f) readr::read_csv(f, num_threads = 32, show_col_types = FALSE) |> \n    select(tourney_date, tourney_level, round, winner_id, winner_name, loser_id, loser_name, score)\n) |> mutate(tourney_date = lubridate::ymd(tourney_date))\n\nFiltering matches based on the original posts’ data processing:\n\nround_numbers = list(\n  \"R128\" = 1,\n  \"RR\" = 1,\n  \"R64\" = 2,\n  \"R32\" = 3,\n  \"R16\" = 4,\n  \"QF\" = 5,\n  \"SF\" = 6,\n  \"F\" = 7\n)\n\n(matches_data_clean <- matches_data_raw \n  |> filter(\n    tourney_date %between% c(\"1968-01-01\", \"2021-06-20\"),\n    str_detect(score, \"RET|W/O|DEF|nbsp|Def.\", negate = TRUE),\n    str_length(score) > 4,\n    tourney_level != \"D\",\n    round %in% names(round_numbers)\n  )\n  |> mutate(\n    round_number = sapply(round, \\(r) round_numbers[[r]]),\n    label = 1\n  )\n  |> arrange(tourney_date, round_number)\n  |> select(-round, -tourney_level)\n)\ndata.frame [160,399 x 8]\n\n\n\ntourney_date\n\n\nwinner_id\n\n\nwinner_name\n\n\nloser_id\n\n\nloser_name\n\n\nscore\n\n\nround_number\n\n\nlabel\n\n\n\n\n\n1968-01-19\n\n\n110 023\n\n\nRichard Coulthard\n\n\n107 760\n\n\nMax Senior\n\n\n12-10 7-5 4-6 7-5\n\n\n2\n\n\n1\n\n\n\n\n1968-01-19\n\n\n109 803\n\n\nJohn Brown\n\n\n106 964\n\n\nErnie Mccabe\n\n\n6-3 6-2 6-4\n\n\n2\n\n\n1\n\n\n\n\n1968-01-19\n\n\n100 257\n\n\nRoss Case\n\n\n110 024\n\n\nGondo Widjojo\n\n\n6-4 3-6 6-3 7-5\n\n\n2\n\n\n1\n\n\n\n\n1968-01-19\n\n\n100 105\n\n\nAllan Stone\n\n\n110 025\n\n\nRobert Layton\n\n\n6-4 6-2 6-1\n\n\n2\n\n\n1\n\n\n\n\n1968-01-19\n\n\n109 966\n\n\nWarren Jacques\n\n\n110 026\n\n\nBert Kearney\n\n\n6-4 6-1 7-5\n\n\n2\n\n\n1\n\n\n\n\n1968-01-19\n\n\n107 759\n\n\nMax Pettman\n\n\n110 027\n\n\nTakesji Tsujimoto\n\n\n6-4 6-1 6-2\n\n\n2\n\n\n1\n\n\n\n\n1968-01-19\n\n\n100 101\n\n\nMike Belkin\n\n\n110 028\n\n\nM Marchment\n\n\n6-2 3-6 6-4 9-7\n\n\n2\n\n\n1\n\n\n\n\n1968-01-19\n\n\n100 025\n\n\nBarry Phillips Moore\n\n\n108 430\n\n\nTony Dawson\n\n\n6-3 6-0 6-3\n\n\n2\n\n\n1\n\n\n\n\n1968-01-19\n\n\n108 519\n\n\nWilliam Coghlan\n\n\n110 029\n\n\nPeter Oatey\n\n\n6-0 6-2 9-11 6-3\n\n\n2\n\n\n1\n\n\n\n\n1968-01-19\n\n\n109 799\n\n\nGeoff Pollard\n\n\n110 030\n\n\nChristian Janssens\n\n\n6-4 6-2 6-4\n\n\n2\n\n\n1\n\n\n\n\n1968-01-19\n\n\n100 146\n\n\nJun Kamiwazumi\n\n\n110 031\n\n\nBrian Connor\n\n\n8-6 6-4 6-2\n\n\n2\n\n\n1\n\n\n\n\n1968-01-19\n\n\n100 180\n\n\nBill Lloyd\n\n\n110 032\n\n\nH Nielson\n\n\n6-2 7-5 6-4\n\n\n2\n\n\n1\n\n\n\n\n1968-01-19\n\n\n100 013\n\n\nNeale Fraser\n\n\n110 033\n\n\nR Harvey\n\n\n6-1 6-1 6-0\n\n\n2\n\n\n1\n\n\n\n\n1968-01-19\n\n\n110 034\n\n\nMerv Guse\n\n\n110 035\n\n\nJ May\n\n\n6-1 6-2 6-2\n\n\n2\n\n\n1\n\n\n\n\n1968-01-19\n\n\n100 174\n\n\nManuel Orantes\n\n\n110 036\n\n\nL Weatherhog\n\n\n6-4 6-0 6-2\n\n\n2\n\n\n1\n\n\n\n\n\n[ omitted 160,384 entries ]"
  },
  {
    "objectID": "content/posts/big-bayes/index.html#player-data",
    "href": "content/posts/big-bayes/index.html#player-data",
    "title": "MCMC for ‘Big Data’ with Stan",
    "section": "\n2.2 Player data",
    "text": "2.2 Player data\nLoading the raw player data:\n\n\n\n\n(player_data_raw <- readr::read_csv(player_data_path) \n |> mutate(player_name = str_c(name_first, name_last, sep = \" \"))\n |> select(player_id, player_name)\n)\ndata.frame [55,649 x 2]\n\n\n\nplayer_id\n\n\nplayer_name\n\n\n\n\n\n100 001\n\n\nGardnar Mulloy\n\n\n\n\n100 002\n\n\nPancho Segura\n\n\n\n\n100 003\n\n\nFrank Sedgman\n\n\n\n\n100 004\n\n\nGiuseppe Merlo\n\n\n\n\n100 005\n\n\nRichard Gonzalez\n\n\n\n\n100 006\n\n\nGrant Golden\n\n\n\n\n100 007\n\n\nAbe Segal\n\n\n\n\n100 008\n\n\nKurt Nielsen\n\n\n\n\n100 009\n\n\nIstvan Gulyas\n\n\n\n\n100 010\n\n\nLuis Ayala\n\n\n\n\n100 011\n\n\nTorben Ulrich\n\n\n\n\n100 012\n\n\nNicola Pietrangeli\n\n\n\n\n100 013\n\n\nNeale Fraser\n\n\n\n\n100 014\n\n\nTrevor Fancutt\n\n\n\n\n100 015\n\n\nSammy Giammalva\n\n\n\n\n\n[ omitted 55,634 entries ]\n\n\n\n\nFiltering player_data to only keep the players actually present in our data, and updating their IDs:\n\n(player_data <- with(matches_data_clean, tibble(player_id = union(winner_id, loser_id)))\n |> group_by(player_id) \n |> summarize(player_idx = cur_group_id()) \n |> left_join(player_data_raw)\n)\ndata.frame [4,830 x 3]\n\n\n\nplayer_id\n\n\nplayer_idx\n\n\nplayer_name\n\n\n\n\n\n100 001\n\n\n1\n\n\nGardnar Mulloy\n\n\n\n\n100 002\n\n\n2\n\n\nPancho Segura\n\n\n\n\n100 003\n\n\n3\n\n\nFrank Sedgman\n\n\n\n\n100 004\n\n\n4\n\n\nGiuseppe Merlo\n\n\n\n\n100 005\n\n\n5\n\n\nRichard Gonzalez\n\n\n\n\n100 006\n\n\n6\n\n\nGrant Golden\n\n\n\n\n100 007\n\n\n7\n\n\nAbe Segal\n\n\n\n\n100 009\n\n\n8\n\n\nIstvan Gulyas\n\n\n\n\n100 010\n\n\n9\n\n\nLuis Ayala\n\n\n\n\n100 011\n\n\n10\n\n\nTorben Ulrich\n\n\n\n\n100 012\n\n\n11\n\n\nNicola Pietrangeli\n\n\n\n\n100 013\n\n\n12\n\n\nNeale Fraser\n\n\n\n\n100 014\n\n\n13\n\n\nTrevor Fancutt\n\n\n\n\n100 015\n\n\n14\n\n\nSammy Giammalva\n\n\n\n\n100 016\n\n\n15\n\n\nKen Rosewall\n\n\n\n\n\n[ omitted 4,815 entries ]"
  },
  {
    "objectID": "content/posts/big-bayes/index.html#matches-player-data",
    "href": "content/posts/big-bayes/index.html#matches-player-data",
    "title": "MCMC for ‘Big Data’ with Stan",
    "section": "\n2.3 Matches + Player data",
    "text": "2.3 Matches + Player data\nAllocating the new player IDs (player_idx) to the winner_id and loser_id from matches_data:\n\n(matches_data <- left_join(matches_data_clean, player_data, by = c(\"winner_id\" = \"player_id\")) \n |> rename(winner_idx = player_idx) \n |> relocate(winner_idx, .after = winner_id) \n |> left_join(player_data, by = c(\"loser_id\" = \"player_id\")) \n |> rename(loser_idx = player_idx) \n |> relocate(loser_idx, .after = loser_id)\n |> drop_na(winner_idx, loser_idx)\n |> select(-matches(\"player_name\"))\n)\ndata.frame [160,399 x 10]\n\n\n\ntourney_date\n\n\nwinner_id\n\n\nwinner_idx\n\n\nwinner_name\n\n\nloser_id\n\n\nloser_idx\n\n\nloser_name\n\n\nscore\n\n\nround_number\n\n\nlabel\n\n\n\n\n\n1968-01-19\n\n\n110 023\n\n\n3 655\n\n\nRichard Coulthard\n\n\n107 760\n\n\n3 129\n\n\nMax Senior\n\n\n12-10 7-5 4-6 7-5\n\n\n2\n\n\n1\n\n\n\n\n1968-01-19\n\n\n109 803\n\n\n3 440\n\n\nJohn Brown\n\n\n106 964\n\n\n2 909\n\n\nErnie Mccabe\n\n\n6-3 6-2 6-4\n\n\n2\n\n\n1\n\n\n\n\n1968-01-19\n\n\n100 257\n\n\n253\n\n\nRoss Case\n\n\n110 024\n\n\n3 656\n\n\nGondo Widjojo\n\n\n6-4 3-6 6-3 7-5\n\n\n2\n\n\n1\n\n\n\n\n1968-01-19\n\n\n100 105\n\n\n103\n\n\nAllan Stone\n\n\n110 025\n\n\n3 657\n\n\nRobert Layton\n\n\n6-4 6-2 6-1\n\n\n2\n\n\n1\n\n\n\n\n1968-01-19\n\n\n109 966\n\n\n3 600\n\n\nWarren Jacques\n\n\n110 026\n\n\n3 658\n\n\nBert Kearney\n\n\n6-4 6-1 7-5\n\n\n2\n\n\n1\n\n\n\n\n1968-01-19\n\n\n107 759\n\n\n3 128\n\n\nMax Pettman\n\n\n110 027\n\n\n3 659\n\n\nTakesji Tsujimoto\n\n\n6-4 6-1 6-2\n\n\n2\n\n\n1\n\n\n\n\n1968-01-19\n\n\n100 101\n\n\n99\n\n\nMike Belkin\n\n\n110 028\n\n\n3 660\n\n\nM Marchment\n\n\n6-2 3-6 6-4 9-7\n\n\n2\n\n\n1\n\n\n\n\n1968-01-19\n\n\n100 025\n\n\n24\n\n\nBarry Phillips Moore\n\n\n108 430\n\n\n3 325\n\n\nTony Dawson\n\n\n6-3 6-0 6-3\n\n\n2\n\n\n1\n\n\n\n\n1968-01-19\n\n\n108 519\n\n\n3 349\n\n\nWilliam Coghlan\n\n\n110 029\n\n\n3 661\n\n\nPeter Oatey\n\n\n6-0 6-2 9-11 6-3\n\n\n2\n\n\n1\n\n\n\n\n1968-01-19\n\n\n109 799\n\n\n3 436\n\n\nGeoff Pollard\n\n\n110 030\n\n\n3 662\n\n\nChristian Janssens\n\n\n6-4 6-2 6-4\n\n\n2\n\n\n1\n\n\n\n\n1968-01-19\n\n\n100 146\n\n\n144\n\n\nJun Kamiwazumi\n\n\n110 031\n\n\n3 663\n\n\nBrian Connor\n\n\n8-6 6-4 6-2\n\n\n2\n\n\n1\n\n\n\n\n1968-01-19\n\n\n100 180\n\n\n178\n\n\nBill Lloyd\n\n\n110 032\n\n\n3 664\n\n\nH Nielson\n\n\n6-2 7-5 6-4\n\n\n2\n\n\n1\n\n\n\n\n1968-01-19\n\n\n100 013\n\n\n12\n\n\nNeale Fraser\n\n\n110 033\n\n\n3 665\n\n\nR Harvey\n\n\n6-1 6-1 6-0\n\n\n2\n\n\n1\n\n\n\n\n1968-01-19\n\n\n110 034\n\n\n3 666\n\n\nMerv Guse\n\n\n110 035\n\n\n3 667\n\n\nJ May\n\n\n6-1 6-2 6-2\n\n\n2\n\n\n1\n\n\n\n\n1968-01-19\n\n\n100 174\n\n\n172\n\n\nManuel Orantes\n\n\n110 036\n\n\n3 668\n\n\nL Weatherhog\n\n\n6-4 6-0 6-2\n\n\n2\n\n\n1\n\n\n\n\n\n[ omitted 160,384 entries ]"
  },
  {
    "objectID": "content/posts/big-bayes/index.html#stan-code",
    "href": "content/posts/big-bayes/index.html#stan-code",
    "title": "MCMC for ‘Big Data’ with Stan",
    "section": "\n3.1 Stan code",
    "text": "3.1 Stan code\n\n\n\n\n\n\nNote\n\n\n\nUpdated Stan code with within-chain parallelization\n\n\n\nfunctions {\n  array[] int sequence(int start, int end) {\n    array[end - start + 1] int seq;\n    for (n in 1 : num_elements(seq)) {\n      seq[n] = n + start - 1;\n    }\n    return seq;\n  }\n\n  // Compute partial sums of the log-likelihood\n  real partial_log_lik_lpmf(array[] int seq, int start, int end,\n                            data array[] int labels, \n                            data array[] int winner_ids, \n                            data array[] int loser_ids, \n                            vector player_skills) {\n    real ptarget = 0;\n    int N = end - start + 1;\n\n    vector[N] mu = rep_vector(0.0, N);\n    for (n in 1 : N) {\n      int nn = n + start - 1;\n      mu[n] += player_skills[winner_ids[nn]] - player_skills[loser_ids[nn]];\n    }\n    ptarget += bernoulli_logit_lpmf(labels[start : end] | mu);\n    return ptarget;\n  }\n}\ndata {\n    int n_players;\n    int n_matches;\n    \n    array[n_matches] int<lower=1, upper=n_players> winner_ids; // Winner of game n\n    array[n_matches] int<lower=1, upper=n_players> loser_ids;  // Loser of game n\n    array[n_matches] int<lower=0, upper=1> labels;             // Always 1 in this model\n    \n    int grainsize;\n}\ntransformed data {\n    array[n_matches] int seq = sequence(1, n_matches);\n}\nparameters {\n    real<lower=0> player_sd;          // Scale of ability variation (hierarchical prior)\n    vector[n_players] player_skills;  // Ability of player k\n}\nmodel {   \n  player_sd ~ std_normal();\n  player_skills ~ normal(0, player_sd);\n    \n  target += reduce_sum(\n    partial_log_lik_lpmf, seq, grainsize, \n    labels, winner_ids, loser_ids, player_skills\n  );\n}"
  },
  {
    "objectID": "content/posts/big-bayes/index.html#stan-data",
    "href": "content/posts/big-bayes/index.html#stan-data",
    "title": "MCMC for ‘Big Data’ with Stan",
    "section": "\n3.2 Stan data",
    "text": "3.2 Stan data\n\ntennis_data_stan <- list(\n  n_matches = nrow(matches_data),\n  n_players = with(matches_data, length(union(winner_id, loser_id))),\n  winner_ids = matches_data$winner_idx,\n  loser_ids = matches_data$loser_idx,\n  labels = matches_data$label,\n  grainsize = max(100, nrow(matches_data) / 60)\n)\n\n\n\nList of 6\n $ n_matches : int 160399\n $ n_players : int 4830\n $ winner_ids: int [1:160399] 3655 3440 253 103 3600 3128 99 24 3349 3436 ...\n $ loser_ids : int [1:160399] 3129 2909 3656 3657 3658 3659 3660 3325 3661 3662 ...\n $ labels    : num [1:160399] 1 1 1 1 1 1 1 1 1 1 ...\n $ grainsize : num 2673"
  },
  {
    "objectID": "content/posts/big-bayes/index.html#model-fit",
    "href": "content/posts/big-bayes/index.html#model-fit",
    "title": "MCMC for ‘Big Data’ with Stan",
    "section": "\n3.3 Model fit",
    "text": "3.3 Model fit\n\n\n\n\ntennis_mod_fit <- tennis_mod_exe$sample(\n  data = tennis_data_stan, seed = 256,\n  iter_warmup = 1000, iter_sampling = 1000, refresh = 0,\n  chains = 4, parallel_chains = 4, threads_per_chain = 7\n)\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nSampling takes ~2.67 minutes on my CPU (Ryzen 5950X, 16 Cores/32 Threads), on WSL2 (Ubuntu 20.04)\n\ndata.table [4 x 2]\n\n\n\nChain\n\n\nTime\n\n\n\n\n\n1\n\n\n161.834s (~2.7 minutes)\n\n\n\n\n2\n\n\n160.699s (~2.68 minutes)\n\n\n\n\n3\n\n\n159.521s (~2.66 minutes)\n\n\n\n\n4\n\n\n159.712s (~2.66 minutes)"
  },
  {
    "objectID": "content/posts/big-bayes/index.html#posterior-data",
    "href": "content/posts/big-bayes/index.html#posterior-data",
    "title": "MCMC for ‘Big Data’ with Stan",
    "section": "\n5.1 Posterior data",
    "text": "5.1 Posterior data\nGetting our Posterior Predictions into long format and joining the result with player_data:\n\n(player_skills <- as.data.table(tennis_mod_fit$draws(variables = \"player_skills\") |> \n    bind(x, subset_draws(x, \"player_skills\", regex = T, draw = sample.int(ndraws(x), size = 500))))\n   [, .(player_skills = list(value)), by = variable\n  ][, `:=`(player_idx = as.integer(str_extract(variable, \"\\\\d{1,4}\")), variable = NULL)\n  ][, `:=`(skill_mean = sapply(player_skills, mean), skill_sd = sapply(player_skills, sd))\n  ][as.data.table(player_data), on = \"player_idx\", nomatch = NULL\n  ][order(-skill_mean), .(player_name, player_id, player_idx, skill_mean, skill_sd, player_skills)]\n)\ndata.table [4,830 x 6]\n\n\n\nplayer_name\n\n\nplayer_id\n\n\nplayer_idx\n\n\nskill_mean\n\n\nskill_sd\n\n\nplayer_skills\n\n\n\n\n\nNovak Djokovic\n\n\n104 925\n\n\n2 415\n\n\n3.542\n\n\n0.093\n\n\n<numeric [500]>\n\n\n\n\nRafael Nadal\n\n\n104 745\n\n\n2 367\n\n\n3.425\n\n\n0.089\n\n\n<numeric [500]>\n\n\n\n\nRoger Federer\n\n\n103 819\n\n\n2 082\n\n\n3.314\n\n\n0.084\n\n\n<numeric [500]>\n\n\n\n\nBjorn Borg\n\n\n100 437\n\n\n423\n\n\n3.246\n\n\n0.103\n\n\n<numeric [500]>\n\n\n\n\nIvan Lendl\n\n\n100 656\n\n\n613\n\n\n3.231\n\n\n0.084\n\n\n<numeric [500]>\n\n\n\n\nJohn McEnroe\n\n\n100 581\n\n\n553\n\n\n3.185\n\n\n0.089\n\n\n<numeric [500]>\n\n\n\n\nJimmy Connors\n\n\n100 284\n\n\n280\n\n\n3.161\n\n\n0.075\n\n\n<numeric [500]>\n\n\n\n\nRod Laver\n\n\n100 029\n\n\n28\n\n\n3.008\n\n\n0.111\n\n\n<numeric [500]>\n\n\n\n\nAndy Murray\n\n\n104 918\n\n\n2 413\n\n\n2.934\n\n\n0.102\n\n\n<numeric [500]>\n\n\n\n\nPete Sampras\n\n\n101 948\n\n\n1 408\n\n\n2.922\n\n\n0.087\n\n\n<numeric [500]>\n\n\n\n\nBoris Becker\n\n\n101 414\n\n\n1 127\n\n\n2.836\n\n\n0.087\n\n\n<numeric [500]>\n\n\n\n\nAndre Agassi\n\n\n101 736\n\n\n1 310\n\n\n2.763\n\n\n0.079\n\n\n<numeric [500]>\n\n\n\n\nStefan Edberg\n\n\n101 222\n\n\n993\n\n\n2.734\n\n\n0.079\n\n\n<numeric [500]>\n\n\n\n\nAndy Roddick\n\n\n104 053\n\n\n2 157\n\n\n2.708\n\n\n0.097\n\n\n<numeric [500]>\n\n\n\n\nJuan Martin del Potro\n\n\n105 223\n\n\n2 503\n\n\n2.673\n\n\n0.106\n\n\n<numeric [500]>\n\n\n\n\n\n[ omitted 4,815 entries ]"
  },
  {
    "objectID": "content/posts/big-bayes/index.html#posterior-plots",
    "href": "content/posts/big-bayes/index.html#posterior-plots",
    "title": "MCMC for ‘Big Data’ with Stan",
    "section": "\n5.2 Posterior plots",
    "text": "5.2 Posterior plots\n\nPlot coderidgeline_plot <- function(dat, var) {\n  dat[, .(player_skills = unlist(player_skills)), by = setdiff(names(dat), 'player_skills')\n     ][, player_name := factor(player_name, levels = unique(player_name))] -> dat\n  \n  ggplot(dat, aes_string(y = var)) +\n    ggridges::geom_density_ridges(\n      aes_string(x = \"player_skills\", fill = var), \n      alpha = 0.5, scale = 2, color = \"grey30\"\n    ) +\n    labs(x = \"Player Skills\", y = \"\") +\n    scale_y_discrete(\n      position = \"right\", \n      limits = \\(x) rev(x), \n      labels = \\(x) str_replace_all(x, \"\\\\s\", \"\\n\")\n    ) +\n    theme(legend.position = \"none\", axis.line.y = element_blank())\n}\n\n\nPlotting the player_skills posteriors of the top 10 players:\n\nridgeline_plot(head(player_skills, 10), \"player_name\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlotting the player_skills posteriors of the bottom 10 players:\n\nridgeline_plot(tail(player_skills, 10), \"player_name\")"
  },
  {
    "objectID": "content/posts/climbing/index.html#stan-setup",
    "href": "content/posts/climbing/index.html#stan-setup",
    "title": "Bayesian Rock Climbing Rankings",
    "section": "\n1.1 Stan setup",
    "text": "1.1 Stan setup\n\nInstalling CmdStancmdstanr::check_cmdstan_toolchain(fix = TRUE, quiet = TRUE)\n\ncpp_opts <- list(\n  stan_threads = TRUE\n  , STAN_CPP_OPTIMS = TRUE\n  , STAN_NO_RANGE_CHECKS = TRUE # WARN: remove this if you haven't tested the model\n  , PRECOMPILED_HEADERS = TRUE\n  , CXXFLAGS_OPTIM = \"-march=native -mtune=native\"\n  , CXXFLAGS_OPTIM_TBB = \"-mtune=native -march=native\"\n  , CXXFLAGS_OPTIM_SUNDIALS = \"-mtune=native -march=native\"\n)\n\ncmdstanr::install_cmdstan(cpp_options = cpp_opts, quiet = TRUE)\n\n\n\nLoading CmdStan (if already installed)highest_cmdstan_version <- fs::dir_ls(config$cmdstan_path) |> fs::path_file() |> \n  keep(\\(e) str_detect(e, \"cmdstan-\")) |> \n  bind(x, str_split(x, '-', simplify = TRUE)[,2]) |> \n  reduce(\\(x, y) ifelse(utils::compareVersion(x, y) == 1, x, y))\n\nset_cmdstan_path(glue::glue(\"{config$cmdstan_path}cmdstan-{highest_cmdstan_version}\"))\n\n\n\nSetting up knitr’s engine for CmdStan## Inspired by: https://mpopov.com/blog/2020/07/30/replacing-the-knitr-engine-for-stan/\n\n## Note: We could haved use cmdstanr::register_knitr_engine(), \n##       but it wouldn't include compiler optimizations & multi-threading by default\n\nknitr::knit_engines$set(\n  cmdstan = function(options) {\n    output_var <- options$output.var\n    if (!is.character(output_var) || length(output_var) != 1L) {\n      stop(\n        \"The chunk option output.var must be a character string \",\n        \"providing a name for the returned `CmdStanModel` object.\"\n      )\n    }\n    if (options$eval) {\n      if (options$cache) {\n        cache_path <- options$cache.path\n        if (length(cache_path) == 0L || is.na(cache_path) || cache_path == \"NA\") \n          cache_path <- \"\"\n        dir <- paste0(cache_path, options$label)\n      } else {\n        dir <- tempdir()\n      }\n      file <- write_stan_file(options$code, dir = dir, force_overwrite = TRUE)\n      mod <- cmdstan_model(\n        file, \n        cpp_opts <- list(\n          stan_threads = TRUE\n          , STAN_CPP_OPTIMS = TRUE\n          , STAN_NO_RANGE_CHECKS = TRUE # The model was already tested\n          , PRECOMPILED_HEADERS = TRUE\n          # , CXXFLAGS_OPTIM = \"-march=native -mtune=native\"\n          , CXXFLAGS_OPTIM_TBB = \"-mtune=native -march=native\"\n          , CXXFLAGS_OPTIM_SUNDIALS = \"-mtune=native -march=native\"\n        ),\n        stanc_options = list(\"Oexperimental\")\n      )\n      assign(output_var, mod, envir = knitr::knit_global())\n    }\n    options$engine <- \"stan\"\n    code <- paste(options$code, collapse = \"\\n\")\n    knitr::engine_output(options, code, '')\n  }\n)\n\n\n\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting        value\n version        R version 4.2.1 (2022-06-23)\n os             Ubuntu 20.04.4 LTS\n system         x86_64, linux-gnu\n ui             X11\n language       (EN)\n collate        C.UTF-8\n ctype          C.UTF-8\n tz             Europe/Paris\n date           2022-09-20\n pandoc         2.19.2\n Quarto         1.1.251\n Stan (CmdStan) 2.30.1\n\n─ Packages ───────────────────────────────────────────────────────────────────\n ! package    * version date (UTC) lib source\n P bayesplot  * 1.9.0   2022-03-10 [?] CRAN (R 4.2.0)\n P cmdstanr   * 0.5.2   2022-09-16 [?] Github (ma-riviere/cmdstanr@8c77d4a)\n P data.table * 1.14.3  2022-07-27 [?] Github (Rdatatable/data.table@c4a2085)\n P DBI        * 1.1.3   2022-06-18 [?] CRAN (R 4.2.0)\n P dbplyr     * 2.2.1   2022-06-27 [?] CRAN (R 4.2.0)\n P dplyr      * 1.0.10  2022-09-01 [?] CRAN (R 4.2.1)\n P dtplyr     * 1.2.2   2022-08-20 [?] CRAN (R 4.2.1)\n P ggplot2    * 3.3.6   2022-05-03 [?] CRAN (R 4.2.0)\n P ggridges   * 0.5.3   2021-01-08 [?] CRAN (R 4.2.0)\n P here       * 1.0.1   2020-12-13 [?] CRAN (R 4.2.0)\n P lubridate  * 1.8.0   2021-10-07 [?] CRAN (R 4.2.0)\n P patchwork  * 1.1.2   2022-08-19 [?] CRAN (R 4.2.1)\n P pipebind   * 0.1.1   2022-08-10 [?] CRAN (R 4.2.0)\n P posterior  * 1.3.1   2022-09-06 [?] CRAN (R 4.2.1)\n P purrr      * 0.3.4   2020-04-17 [?] CRAN (R 4.2.0)\n P RSQLite    * 2.2.17  2022-09-10 [?] CRAN (R 4.2.1)\n P stringr    * 1.4.1   2022-08-20 [?] CRAN (R 4.2.1)\n\n [1] /home/mar/Dev/Projects/R/ma-riviere.me/renv/library/R-4.2/x86_64-pc-linux-gnu\n [2] /usr/lib/R/library\n\n P ── Loaded and on-disk path mismatch.\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "content/posts/climbing/index.html#loading-from-sql",
    "href": "content/posts/climbing/index.html#loading-from-sql",
    "title": "Bayesian Rock Climbing Rankings",
    "section": "\n2.1 Loading from SQL",
    "text": "2.1 Loading from SQL\n\n\n\n\ncon <- DBI::dbConnect(RSQLite::SQLite(), dbname = climb_path)\n\n\n\n\n\n\n\nNote\n\n\n\nComparing raw SQL and dbplyr:\n\n\n\n\ndbplyr\nSQL\n\n\n\n\n\n\n\n\n\nNote\n\n\n\ndbplyr automatically translates dplyr code into SQL\n\n\n\nclimb_dbp <- (reduce(\n    list(\n      tbl(con, \"ascent\") |> filter(country %like% \"USA\") |> \n        select(user_id, grade_id, method_id, crag, climb_type, route_name = name, ascent_date = date),\n      tbl(con, \"grade\") |> select(grade_id = id, usa_routes, usa_boulders), \n      tbl(con, \"method\") |> select(method_id = id, method_name = name)\n    ),\n    .f = \\(acc, i) left_join(acc, i)\n  ) \n  |> select(-grade_id, -method_id)\n  |> collect()\n)\n\n\ndata.frame [658,822 x 8]\n\n\n\nuser_id\n\n\ncrag\n\n\nclimb_type\n\n\nroute_name\n\n\nascent_date\n\n\nusa_routes\n\n\nusa_boulders\n\n\nmethod_name\n\n\n\n\n\n25\n\n\nHueco Tanks\n\n\n1\n\n\nFrogger\n\n\n917 823 600\n\n\n5.12d\n\n\nV9\n\n\nRedpoint\n\n\n\n\n25\n\n\nHueco Tanks\n\n\n1\n\n\nSex After Death\n\n\n917 823 600\n\n\n5.12d\n\n\nV9\n\n\nRedpoint\n\n\n\n\n25\n\n\nHueco Tanks\n\n\n1\n\n\nRed\n\n\n915 145 200\n\n\n5.12d\n\n\nV9\n\n\nRedpoint\n\n\n\n\n25\n\n\nHueco Tanks\n\n\n1\n\n\nBetter Eat Your Wheaties\n\n\n949 359 600\n\n\n5.12c\n\n\nV8/9\n\n\nRedpoint\n\n\n\n\n25\n\n\nHorse Flats\n\n\n1\n\n\nBlank Generation\n\n\n957 132 000\n\n\n5.12d\n\n\nV9\n\n\nRedpoint\n\n\n\n\n25\n\n\nBishop\n\n\n1\n\n\nShazam\n\n\n933 458 400\n\n\n5.12d\n\n\nV9\n\n\nRedpoint\n\n\n\n\n25\n\n\nBishop\n\n\n1\n\n\nIt’s All About Love\n\n\n938 728 800\n\n\n5.12c\n\n\nV8/9\n\n\nRedpoint\n\n\n\n\n25\n\n\nJoshua Tree\n\n\n1\n\n\nCrypic Tips\n\n\n957 132 000\n\n\n5.12d\n\n\nV9\n\n\nRedpoint\n\n\n\n\n25\n\n\nHueco Tanks\n\n\n1\n\n\nMushroom Roof\n\n\n946 681 200\n\n\n5.12c\n\n\nV8/9\n\n\nRedpoint\n\n\n\n\n26\n\n\nThe Pit\n\n\n0\n\n\nCastillo\n\n\n969 660 000\n\n\n5.13c\n\n\nV12\n\n\nRedpoint\n\n\n\n\n26\n\n\nThe Pit\n\n\n0\n\n\nSister of Mercy\n\n\n969 660 000\n\n\n5.12c\n\n\nV8/9\n\n\nFlash\n\n\n\n\n26\n\n\nThe Pit\n\n\n0\n\n\nRage\n\n\n965 858 400\n\n\n5.13b\n\n\nV11\n\n\nRedpoint\n\n\n\n\n26\n\n\nThe Pit\n\n\n0\n\n\nFresh Squeezed\n\n\n949 359 600\n\n\n5.13a\n\n\nV10\n\n\nRedpoint\n\n\n\n\n26\n\n\nThe Pit\n\n\n0\n\n\nThe Specialist\n\n\n957 132 000\n\n\n5.13a\n\n\nV10\n\n\nRedpoint\n\n\n\n\n26\n\n\nThe Pit\n\n\n0\n\n\nNo Joke\n\n\n965 080 800\n\n\n5.13a\n\n\nV10\n\n\nRedpoint\n\n\n\n\n\n[ omitted 658,807 entries ]\n\n\nTime difference of 1.362 secs\n\n\n\n\nSELECT\n  ascent.user_id\n  , ascent.crag\n  , ascent.climb_type\n  , ascent.name AS route_name\n  , ascent.date AS ascent_date\n  , grade.usa_routes\n  , grade.usa_boulders\n  , method.name AS method_name\nFROM ascent\nJOIN grade ON grade.id = ascent.grade_id\nJOIN method ON method.id = ascent.method_id\nWHERE ascent.country = 'USA'\n\n\ndata.frame [658,822 x 8]\n\n\n\nuser_id\n\n\ncrag\n\n\nclimb_type\n\n\nroute_name\n\n\nascent_date\n\n\nusa_routes\n\n\nusa_boulders\n\n\nmethod_name\n\n\n\n\n\n25\n\n\nHueco Tanks\n\n\n1\n\n\nFrogger\n\n\n917 823 600\n\n\n5.12d\n\n\nV9\n\n\nRedpoint\n\n\n\n\n25\n\n\nHueco Tanks\n\n\n1\n\n\nSex After Death\n\n\n917 823 600\n\n\n5.12d\n\n\nV9\n\n\nRedpoint\n\n\n\n\n25\n\n\nHueco Tanks\n\n\n1\n\n\nRed\n\n\n915 145 200\n\n\n5.12d\n\n\nV9\n\n\nRedpoint\n\n\n\n\n25\n\n\nHueco Tanks\n\n\n1\n\n\nBetter Eat Your Wheaties\n\n\n949 359 600\n\n\n5.12c\n\n\nV8/9\n\n\nRedpoint\n\n\n\n\n25\n\n\nHorse Flats\n\n\n1\n\n\nBlank Generation\n\n\n957 132 000\n\n\n5.12d\n\n\nV9\n\n\nRedpoint\n\n\n\n\n25\n\n\nBishop\n\n\n1\n\n\nShazam\n\n\n933 458 400\n\n\n5.12d\n\n\nV9\n\n\nRedpoint\n\n\n\n\n25\n\n\nBishop\n\n\n1\n\n\nIt’s All About Love\n\n\n938 728 800\n\n\n5.12c\n\n\nV8/9\n\n\nRedpoint\n\n\n\n\n25\n\n\nJoshua Tree\n\n\n1\n\n\nCrypic Tips\n\n\n957 132 000\n\n\n5.12d\n\n\nV9\n\n\nRedpoint\n\n\n\n\n25\n\n\nHueco Tanks\n\n\n1\n\n\nMushroom Roof\n\n\n946 681 200\n\n\n5.12c\n\n\nV8/9\n\n\nRedpoint\n\n\n\n\n26\n\n\nThe Pit\n\n\n0\n\n\nCastillo\n\n\n969 660 000\n\n\n5.13c\n\n\nV12\n\n\nRedpoint\n\n\n\n\n26\n\n\nThe Pit\n\n\n0\n\n\nSister of Mercy\n\n\n969 660 000\n\n\n5.12c\n\n\nV8/9\n\n\nFlash\n\n\n\n\n26\n\n\nThe Pit\n\n\n0\n\n\nRage\n\n\n965 858 400\n\n\n5.13b\n\n\nV11\n\n\nRedpoint\n\n\n\n\n26\n\n\nThe Pit\n\n\n0\n\n\nFresh Squeezed\n\n\n949 359 600\n\n\n5.13a\n\n\nV10\n\n\nRedpoint\n\n\n\n\n26\n\n\nThe Pit\n\n\n0\n\n\nThe Specialist\n\n\n957 132 000\n\n\n5.13a\n\n\nV10\n\n\nRedpoint\n\n\n\n\n26\n\n\nThe Pit\n\n\n0\n\n\nNo Joke\n\n\n965 080 800\n\n\n5.13a\n\n\nV10\n\n\nRedpoint\n\n\n\n\n\n[ omitted 658,807 entries ]\n\n\nTime difference of 1.007 secs"
  },
  {
    "objectID": "content/posts/climbing/index.html#processing",
    "href": "content/posts/climbing/index.html#processing",
    "title": "Bayesian Rock Climbing Rankings",
    "section": "\n2.2 Processing",
    "text": "2.2 Processing\n\nroute_ratings <- c(\n  str_c(\"5.\", 1:9), \n  map(str_c(\"5.\", 10:15), \\(x) str_c(x, letters[1:4])) |> unlist()\n)\n\nbouldering_grades <- c(paste0(\"V\", 0:20))\n\n## Mode for non-numerical data\nmode <- \\(x) levels(x)[which.max(tabulate(match(x, levels(x))))]\n\n\n\n\n\n\n\nNote\n\n\n\nComparing data.table, dplyr, and dtplyr:\n\n\n\n\ndata.table\ndplyr\ndtplyr\n\n\n\n\nclimb_dt <- as.data.table(climb_dbp)\n\nthreshold_ascents_dt <- function(old_dt, limit = 20) {\n  new_dt <- old_dt[, if(.N >= limit) .SD, by = user_id\n                 ][, if(.N >= limit) .SD, by = route_id]\n  \n  if (!identical(dim(old_dt), dim(new_dt))) \n    threshold_ascents_dt(new_dt, limit)\n  else return(new_dt)\n}\n\n\nclimb_dt <- climb_dt[,\n    `:=`(\n      route_id = str_c(\n        str_replace_all(crag, ' ', '_'), \"__\", \n        str_replace_all(route_name, ' ', '_'), \"__\", \n        fifelse(climb_type == 1, 'boulder', 'rope')\n      ),\n      ascent_date = lubridate::as_datetime(ascent_date),\n      usa_boulders = factor(usa_boulders, levels = bouldering_grades),\n      usa_routes = factor(usa_routes, levels = route_ratings),\n      label = as.integer(method_name %chin% c(\"Onsight\", \"Flash\"))\n    )\n  ][climb_dt[, .I[which.min(ascent_date)], by = .(user_id, route_id)]$V1\n  ][, `:=`(route_rating = mode(usa_routes), bouldering_grade = mode(usa_boulders)),\n      by = route_id\n  ]\n\n(dt_clean <- threshold_ascents_dt(climb_dt)\n   [, route_idx := .GRP, keyby = route_id\n  ][, user_idx := .GRP, keyby = user_id\n  ][, -c(\"usa_routes\", \"usa_boulders\")]\n)\ndata.table [232,887 x 12]\n\n\n\nroute_id\n\n\nuser_id\n\n\ncrag\n\n\nclimb_type\n\n\nroute_name\n\n\nascent_date\n\n\nmethod_name\n\n\nlabel\n\n\nroute_rating\n\n\nbouldering_grade\n\n\nroute_idx\n\n\nuser_idx\n\n\n\n\n\nMt_Potasi__Moment_of_Clarity__rope\n\n\n4\n\n\nMt Potasi\n\n\n0\n\n\nMoment of Clarity\n\n\n2006-12-19 23:00:00\n\n\nOnsight\n\n\n1\n\n\n5.12a\n\n\nV7\n\n\n2 258\n\n\n1\n\n\n\n\nMt_Potasi__The_Natural__rope\n\n\n4\n\n\nMt Potasi\n\n\n0\n\n\nThe Natural\n\n\n2006-12-23 23:00:00\n\n\nRedpoint\n\n\n0\n\n\n5.12d\n\n\nV9\n\n\n2 259\n\n\n1\n\n\n\n\nObed__Deathblow__rope\n\n\n4\n\n\nObed\n\n\n0\n\n\nDeathblow\n\n\n2006-02-28 23:00:00\n\n\nFlash\n\n\n1\n\n\n5.11b\n\n\nV6\n\n\n2 443\n\n\n1\n\n\n\n\nObed__Jungle_Jane__rope\n\n\n4\n\n\nObed\n\n\n0\n\n\nJungle Jane\n\n\n2006-11-18 23:00:00\n\n\nOnsight\n\n\n1\n\n\n5.12a\n\n\nV7\n\n\n2 459\n\n\n1\n\n\n\n\nObed__Maximum_Overdrive_Face__rope\n\n\n4\n\n\nObed\n\n\n0\n\n\nMaximum Overdrive Face\n\n\n2006-02-28 23:00:00\n\n\nRedpoint\n\n\n0\n\n\n5.12b\n\n\nV8\n\n\n2 464\n\n\n1\n\n\n\n\nObed__Pet_Cemetary__rope\n\n\n4\n\n\nObed\n\n\n0\n\n\nPet Cemetary\n\n\n2006-02-28 23:00:00\n\n\nFlash\n\n\n1\n\n\n5.11a\n\n\nV5\n\n\n2 471\n\n\n1\n\n\n\n\nObed__Rage__rope\n\n\n4\n\n\nObed\n\n\n0\n\n\nRage\n\n\n2006-02-28 23:00:00\n\n\nRedpoint\n\n\n0\n\n\n5.12c\n\n\nV9\n\n\n2 475\n\n\n1\n\n\n\n\nObed__Solstice__rope\n\n\n4\n\n\nObed\n\n\n0\n\n\nSolstice\n\n\n2006-02-28 23:00:00\n\n\nOnsight\n\n\n1\n\n\n5.12a\n\n\nV7\n\n\n2 482\n\n\n1\n\n\n\n\nObed__Tierrany__rope\n\n\n4\n\n\nObed\n\n\n0\n\n\nTierrany\n\n\n2006-11-18 23:00:00\n\n\nOnsight\n\n\n1\n\n\n5.12a\n\n\nV7\n\n\n2 495\n\n\n1\n\n\n\n\nRed_River_Gorge__Ale-8-One__rope\n\n\n4\n\n\nRed River Gorge\n\n\n0\n\n\nAle-8-One\n\n\n2006-11-23 23:00:00\n\n\nOnsight\n\n\n1\n\n\n5.12b\n\n\nV8\n\n\n2 715\n\n\n1\n\n\n\n\nRed_River_Gorge__Blue_Eyed_Honkey_Jesus__rope\n\n\n4\n\n\nRed River Gorge\n\n\n0\n\n\nBlue Eyed Honkey Jesus\n\n\n2006-11-28 23:00:00\n\n\nRedpoint\n\n\n0\n\n\n5.12c\n\n\nV8\n\n\n2 759\n\n\n1\n\n\n\n\nRed_River_Gorge__Chainsaw_Massacre__rope\n\n\n4\n\n\nRed River Gorge\n\n\n0\n\n\nChainsaw Massacre\n\n\n2006-11-23 23:00:00\n\n\nOnsight\n\n\n1\n\n\n5.12a\n\n\nV7\n\n\n2 787\n\n\n1\n\n\n\n\nRed_River_Gorge__Fuzzy_Undercling__rope\n\n\n4\n\n\nRed River Gorge\n\n\n0\n\n\nFuzzy Undercling\n\n\n2006-11-20 23:00:00\n\n\nOnsight\n\n\n1\n\n\n5.11b\n\n\nV5\n\n\n2 850\n\n\n1\n\n\n\n\nRed_River_Gorge__Gung_Ho__rope\n\n\n4\n\n\nRed River Gorge\n\n\n0\n\n\nGung Ho\n\n\n2006-11-20 23:00:00\n\n\nOnsight\n\n\n1\n\n\n5.12b\n\n\nV8\n\n\n2 870\n\n\n1\n\n\n\n\nRed_River_Gorge__Kick_Me_In_The_Jimmie__rope\n\n\n4\n\n\nRed River Gorge\n\n\n0\n\n\nKick Me In The Jimmie\n\n\n2006-11-23 23:00:00\n\n\nOnsight\n\n\n1\n\n\n5.12a\n\n\nV7\n\n\n2 910\n\n\n1\n\n\n\n\n\n[ omitted 232,872 entries ]\n\n\n\n\n\n\nTime difference of 10.29 secs\n\n\n\n\n\nthreshold_ascents_df <- function(old_df, limit = 20) {\n  new_df <- old_df |> \n    group_by(user_id) |> filter(n() >= limit) |> \n    group_by(route_id) |> filter(n() >= limit) |> \n    ungroup()\n  \n  if (!identical(dim(old_df), dim(new_df))) \n    threshold_ascents_df(new_df, limit)\n  else return(new_df)\n}\n\n\n(df_clean <- climb_dbp\n  |> mutate(\n    route_id = str_c(\n      str_replace_all(crag, ' ', '_'), \"__\", \n      str_replace_all(route_name, ' ', '_'), \"__\", \n      if_else(climb_type == 1, 'boulder', 'rope')\n    ),\n    ascent_date = lubridate::as_datetime(ascent_date),\n    usa_boulders = factor(usa_boulders, levels = bouldering_grades),\n    usa_routes = factor(usa_routes, levels = route_ratings)\n  )\n  |> group_by(route_id) \n  |> mutate(route_rating = mode(usa_routes), bouldering_grade = mode(usa_boulders)) \n  |> ungroup()\n  |> select(-c(usa_routes, usa_boulders))\n  |> mutate(label = as.integer(method_name %in% c(\"Onsight\", \"Flash\")))\n  |> group_by(user_id, route_id) |> slice(which.min(ascent_date)) |> ungroup()\n  |> threshold_ascents_df(limit = 20) |> ungroup()\n  |> group_by(route_id) |> mutate(route_idx = cur_group_id()) |> ungroup()\n  |> group_by(user_id) |> mutate(user_idx = cur_group_id()) |> ungroup()\n)\ndata.frame [232,887 x 12]\n\n\n\nuser_id\n\n\ncrag\n\n\nclimb_type\n\n\nroute_name\n\n\nascent_date\n\n\nmethod_name\n\n\nroute_id\n\n\nroute_rating\n\n\nbouldering_grade\n\n\nlabel\n\n\nroute_idx\n\n\nuser_idx\n\n\n\n\n\n4\n\n\nMt Potasi\n\n\n0\n\n\nMoment of Clarity\n\n\n2006-12-19 23:00:00\n\n\nOnsight\n\n\nMt_Potasi__Moment_of_Clarity__rope\n\n\n5.12a\n\n\nV7\n\n\n1\n\n\n2 260\n\n\n1\n\n\n\n\n4\n\n\nMt Potasi\n\n\n0\n\n\nThe Natural\n\n\n2006-12-23 23:00:00\n\n\nRedpoint\n\n\nMt_Potasi__The_Natural__rope\n\n\n5.12d\n\n\nV9\n\n\n0\n\n\n2 261\n\n\n1\n\n\n\n\n4\n\n\nObed\n\n\n0\n\n\nDeathblow\n\n\n2006-02-28 23:00:00\n\n\nFlash\n\n\nObed__Deathblow__rope\n\n\n5.11b\n\n\nV5\n\n\n1\n\n\n2 445\n\n\n1\n\n\n\n\n4\n\n\nObed\n\n\n0\n\n\nJungle Jane\n\n\n2006-11-18 23:00:00\n\n\nOnsight\n\n\nObed__Jungle_Jane__rope\n\n\n5.12a\n\n\nV7\n\n\n1\n\n\n2 461\n\n\n1\n\n\n\n\n4\n\n\nObed\n\n\n0\n\n\nMaximum Overdrive Face\n\n\n2006-02-28 23:00:00\n\n\nRedpoint\n\n\nObed__Maximum_Overdrive_Face__rope\n\n\n5.12b\n\n\nV8\n\n\n0\n\n\n2 467\n\n\n1\n\n\n\n\n4\n\n\nObed\n\n\n0\n\n\nPet Cemetary\n\n\n2006-02-28 23:00:00\n\n\nFlash\n\n\nObed__Pet_Cemetary__rope\n\n\n5.11a\n\n\nV5\n\n\n1\n\n\n2 473\n\n\n1\n\n\n\n\n4\n\n\nObed\n\n\n0\n\n\nRage\n\n\n2006-02-28 23:00:00\n\n\nRedpoint\n\n\nObed__Rage__rope\n\n\n5.12c\n\n\nV9\n\n\n0\n\n\n2 477\n\n\n1\n\n\n\n\n4\n\n\nObed\n\n\n0\n\n\nSolstice\n\n\n2006-02-28 23:00:00\n\n\nOnsight\n\n\nObed__Solstice__rope\n\n\n5.12a\n\n\nV7\n\n\n1\n\n\n2 484\n\n\n1\n\n\n\n\n4\n\n\nObed\n\n\n0\n\n\nTierrany\n\n\n2006-11-18 23:00:00\n\n\nOnsight\n\n\nObed__Tierrany__rope\n\n\n5.12a\n\n\nV7\n\n\n1\n\n\n2 497\n\n\n1\n\n\n\n\n4\n\n\nRed River Gorge\n\n\n0\n\n\nAle-8-One\n\n\n2006-11-23 23:00:00\n\n\nOnsight\n\n\nRed_River_Gorge__Ale-8-One__rope\n\n\n5.12b\n\n\nV8\n\n\n1\n\n\n2 619\n\n\n1\n\n\n\n\n4\n\n\nRed River Gorge\n\n\n0\n\n\nBlue Eyed Honkey Jesus\n\n\n2006-11-28 23:00:00\n\n\nRedpoint\n\n\nRed_River_Gorge__Blue_Eyed_Honkey_Jesus__rope\n\n\n5.12c\n\n\nV8\n\n\n0\n\n\n2 663\n\n\n1\n\n\n\n\n4\n\n\nRed River Gorge\n\n\n0\n\n\nChainsaw Massacre\n\n\n2006-11-23 23:00:00\n\n\nOnsight\n\n\nRed_River_Gorge__Chainsaw_Massacre__rope\n\n\n5.12a\n\n\nV7\n\n\n1\n\n\n2 691\n\n\n1\n\n\n\n\n4\n\n\nRed River Gorge\n\n\n0\n\n\nFuzzy Undercling\n\n\n2006-11-20 23:00:00\n\n\nOnsight\n\n\nRed_River_Gorge__Fuzzy_Undercling__rope\n\n\n5.11b\n\n\nV5\n\n\n1\n\n\n2 756\n\n\n1\n\n\n\n\n4\n\n\nRed River Gorge\n\n\n0\n\n\nGung Ho\n\n\n2006-11-20 23:00:00\n\n\nOnsight\n\n\nRed_River_Gorge__Gung_Ho__rope\n\n\n5.12b\n\n\nV8\n\n\n1\n\n\n2 776\n\n\n1\n\n\n\n\n4\n\n\nRed River Gorge\n\n\n0\n\n\nKick Me In The Jimmie\n\n\n2006-11-23 23:00:00\n\n\nOnsight\n\n\nRed_River_Gorge__Kick_Me_In_The_Jimmie__rope\n\n\n5.12a\n\n\nV7\n\n\n1\n\n\n2 817\n\n\n1\n\n\n\n\n\n[ omitted 232,872 entries ]\n\n\n\n\n\n\nTime difference of 38.88 secs\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\ndtplyr automatically translates dplyr code into data.table\n\n\n\nthreshold_ascents_dtp <- function(old_df, limit = 20) {\n  new_df <- lazy_dt(old_df) |> \n    group_by(user_id) |> filter(n() >= limit) |> \n    group_by(route_id) |> filter(n() >= limit) |> \n    ungroup() |> collect()\n  \n  if (!identical(dim(old_df), dim(new_df)))\n    threshold_ascents_dtp(new_df, limit)\n  else return(new_df)\n}\n\n\n(dtp_clean <- climb_dbp\n  |> lazy_dt()\n  |> mutate(\n    route_id = str_c(\n      str_replace_all(crag, ' ', '_'), \"__\", \n      str_replace_all(route_name, ' ', '_'), \"__\", \n      if_else(climb_type == 1, 'boulder', 'rope')\n    ),\n    ascent_date = lubridate::as_datetime(ascent_date),\n    usa_boulders = factor(usa_boulders, levels = bouldering_grades),\n    usa_routes = factor(usa_routes, levels = route_ratings)\n  )\n  |> group_by(route_id) \n  |> mutate(route_rating = mode(usa_routes), bouldering_grade = mode(usa_boulders)) \n  |> ungroup()\n  |> select(-c(usa_routes, usa_boulders))\n  |> mutate(label = as.integer(method_name %in% c(\"Onsight\", \"Flash\")))\n  |> group_by(user_id, route_id) |> slice(which.min(ascent_date)) |> ungroup()\n  |> threshold_ascents_dtp(limit = 20) |> ungroup()\n  |> group_by(route_id) |> mutate(route_idx = cur_group_id()) |> ungroup()\n  |> group_by(user_id) |> mutate(user_idx = cur_group_id()) |> ungroup()\n  |> collect()\n)\ndata.frame [232,887 x 12]\n\n\n\nuser_id\n\n\ncrag\n\n\nclimb_type\n\n\nroute_name\n\n\nascent_date\n\n\nmethod_name\n\n\nroute_id\n\n\nroute_rating\n\n\nbouldering_grade\n\n\nlabel\n\n\nroute_idx\n\n\nuser_idx\n\n\n\n\n\n312\n\n\nRed Rocks\n\n\n0\n\n\nYaak Crack\n\n\n1998-03-31 22:00:00\n\n\nRedpoint\n\n\nRed_Rocks__Yaak_Crack__rope\n\n\n5.11d\n\n\nV6\n\n\n0\n\n\n3 263\n\n\n19\n\n\n\n\n630\n\n\nRed Rocks\n\n\n0\n\n\nYaak Crack\n\n\n2003-12-31 23:00:00\n\n\nRedpoint\n\n\nRed_Rocks__Yaak_Crack__rope\n\n\n5.11d\n\n\nV6\n\n\n0\n\n\n3 263\n\n\n47\n\n\n\n\n790\n\n\nRed Rocks\n\n\n0\n\n\nYaak Crack\n\n\n2001-01-01 23:00:00\n\n\nFlash\n\n\nRed_Rocks__Yaak_Crack__rope\n\n\n5.11d\n\n\nV6\n\n\n1\n\n\n3 263\n\n\n66\n\n\n\n\n932\n\n\nRed Rocks\n\n\n0\n\n\nYaak Crack\n\n\n2008-12-20 23:00:00\n\n\nOnsight\n\n\nRed_Rocks__Yaak_Crack__rope\n\n\n5.11d\n\n\nV6\n\n\n1\n\n\n3 263\n\n\n74\n\n\n\n\n970\n\n\nRed Rocks\n\n\n0\n\n\nYaak Crack\n\n\n2001-11-03 23:00:00\n\n\nOnsight\n\n\nRed_Rocks__Yaak_Crack__rope\n\n\n5.11d\n\n\nV6\n\n\n1\n\n\n3 263\n\n\n75\n\n\n\n\n1 145\n\n\nRed Rocks\n\n\n0\n\n\nYaak Crack\n\n\n2003-12-20 23:00:00\n\n\nToprope\n\n\nRed_Rocks__Yaak_Crack__rope\n\n\n5.11d\n\n\nV6\n\n\n0\n\n\n3 263\n\n\n87\n\n\n\n\n1 146\n\n\nRed Rocks\n\n\n0\n\n\nYaak Crack\n\n\n2002-03-26 23:00:00\n\n\nRedpoint\n\n\nRed_Rocks__Yaak_Crack__rope\n\n\n5.11d\n\n\nV6\n\n\n0\n\n\n3 263\n\n\n88\n\n\n\n\n1 266\n\n\nRed Rocks\n\n\n0\n\n\nYaak Crack\n\n\n2004-10-25 22:00:00\n\n\nOnsight\n\n\nRed_Rocks__Yaak_Crack__rope\n\n\n5.11d\n\n\nV6\n\n\n1\n\n\n3 263\n\n\n93\n\n\n\n\n1 315\n\n\nRed Rocks\n\n\n0\n\n\nYaak Crack\n\n\n2005-02-03 23:00:00\n\n\nFlash\n\n\nRed_Rocks__Yaak_Crack__rope\n\n\n5.11d\n\n\nV6\n\n\n1\n\n\n3 263\n\n\n96\n\n\n\n\n1 455\n\n\nRed Rocks\n\n\n0\n\n\nYaak Crack\n\n\n2014-09-27 22:00:00\n\n\nRedpoint\n\n\nRed_Rocks__Yaak_Crack__rope\n\n\n5.11d\n\n\nV6\n\n\n0\n\n\n3 263\n\n\n103\n\n\n\n\n1 603\n\n\nRed Rocks\n\n\n0\n\n\nYaak Crack\n\n\n2004-05-29 22:00:00\n\n\nRedpoint\n\n\nRed_Rocks__Yaak_Crack__rope\n\n\n5.11d\n\n\nV6\n\n\n0\n\n\n3 263\n\n\n113\n\n\n\n\n2 011\n\n\nRed Rocks\n\n\n0\n\n\nYaak Crack\n\n\n2009-04-02 22:00:00\n\n\nOnsight\n\n\nRed_Rocks__Yaak_Crack__rope\n\n\n5.11d\n\n\nV6\n\n\n1\n\n\n3 263\n\n\n142\n\n\n\n\n2 034\n\n\nRed Rocks\n\n\n0\n\n\nYaak Crack\n\n\n1998-12-13 23:00:00\n\n\nOnsight\n\n\nRed_Rocks__Yaak_Crack__rope\n\n\n5.11d\n\n\nV6\n\n\n1\n\n\n3 263\n\n\n144\n\n\n\n\n1 140\n\n\nRed Rocks\n\n\n0\n\n\nYaak Crack\n\n\n2009-01-02 23:00:00\n\n\nRedpoint\n\n\nRed_Rocks__Yaak_Crack__rope\n\n\n5.11d\n\n\nV6\n\n\n0\n\n\n3 263\n\n\n86\n\n\n\n\n2 055\n\n\nRed Rocks\n\n\n0\n\n\nYaak Crack\n\n\n2013-03-04 23:00:00\n\n\nFlash\n\n\nRed_Rocks__Yaak_Crack__rope\n\n\n5.11d\n\n\nV6\n\n\n1\n\n\n3 263\n\n\n145\n\n\n\n\n\n[ omitted 232,872 entries ]\n\n\n\n\n\n\nTime difference of 11.54 secs"
  },
  {
    "objectID": "content/posts/climbing/index.html#stan-code",
    "href": "content/posts/climbing/index.html#stan-code",
    "title": "Bayesian Rock Climbing Rankings",
    "section": "\n3.1 Stan code",
    "text": "3.1 Stan code\n\n\n\n\n\n\nNote\n\n\n\nUpdated Stan code using within-chain parallelization\n\n\n\nfunctions {\n  array[] int sequence(int start, int end) {\n    array[end - start + 1] int seq;\n    for (n in 1 : num_elements(seq)) {\n      seq[n] = n + start - 1;\n    }\n    return seq;\n  }\n\n  // Compute partial sums of the log-likelihood\n  real partial_log_lik_lpmf(array[] int seq, int start, int end,\n                            data array[] int labels, real mean_ability,\n                            data array[] int users, vector user_ability,\n                            data array[] int routes, vector route_difficulty) {\n    real ptarget = 0;\n    int N = end - start + 1;\n\n    vector[N] mu = mean_ability + rep_vector(0.0, N);\n    for (n in 1 : N) {\n      int nn = n + start - 1;\n      mu[n] += user_ability[users[nn]] - route_difficulty[routes[nn]];\n    }\n    ptarget += bernoulli_logit_lpmf(labels[start : end] | mu);\n    return ptarget;\n  }\n}\ndata {\n  int<lower=1> num_ascents;\n  int<lower=1> num_users;\n  int<lower=1> num_routes;\n  array[num_ascents] int<lower=1, upper=num_users> users;\n  array[num_ascents] int<lower=1, upper=num_routes> routes;\n  array[num_ascents] int<lower=0, upper=1> labels;\n\n  int grainsize;\n}\ntransformed data {\n  array[num_ascents] int seq = sequence(1, num_ascents);\n}\nparameters {\n  real mean_ability;\n  vector[num_users] user_ability;\n  vector[num_routes] route_difficulty;\n}\nmodel {\n  user_ability ~ std_normal();\n  route_difficulty ~ std_normal();\n  mean_ability ~ std_normal();\n\n  target += reduce_sum(\n    partial_log_lik_lpmf, seq, grainsize, \n    labels, mean_ability, users, user_ability, routes, route_difficulty\n  );\n}"
  },
  {
    "objectID": "content/posts/climbing/index.html#stan-data",
    "href": "content/posts/climbing/index.html#stan-data",
    "title": "Bayesian Rock Climbing Rankings",
    "section": "\n3.2 Stan data",
    "text": "3.2 Stan data\n\nstan_data <- list(\n  num_ascents = nrow(dt_clean),\n  num_users = n_distinct(dt_clean$user_id),\n  num_routes = n_distinct(dt_clean$route_id),\n  routes = pull(dt_clean, route_idx),\n  users = pull(dt_clean, user_idx),\n  labels = pull(dt_clean, label) |> as.integer(),\n  grainsize = max(100, nrow(dt_clean) / 50)\n)\n\n\n\nList of 7\n $ num_ascents: int 232887\n $ num_users  : int 2977\n $ num_routes : int 4288\n $ routes     : int [1:232887] 2258 2259 2443 2459 2464 2471 2475 2482 2495 2715 ...\n $ users      : int [1:232887] 1 1 1 1 1 1 1 1 1 1 ...\n $ labels     : int [1:232887] 1 0 1 1 0 1 0 1 1 1 ...\n $ grainsize  : num 4658"
  },
  {
    "objectID": "content/posts/climbing/index.html#model-fit",
    "href": "content/posts/climbing/index.html#model-fit",
    "title": "Bayesian Rock Climbing Rankings",
    "section": "\n3.3 Model fit",
    "text": "3.3 Model fit\n\n\n\n\nmod_stan <- mod_stan_exe$sample(\n  data = stan_data, seed = 666,\n  iter_warmup = 500, iter_sampling = 1000, refresh = 0,\n  chains = 6, parallel_chains = 6, threads_per_chain = 5\n)\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nSampling takes ~4.89 minutes on my CPU (Ryzen 5950X, 16 Cores/32 Threads), on WSL2 (Ubuntu 20.04)\n\ndata.table [6 x 2]\n\n\n\nChain\n\n\nTime\n\n\n\n\n\n1\n\n\n284.245s (~4.74 minutes)\n\n\n\n\n2\n\n\n297.297s (~4.95 minutes)\n\n\n\n\n3\n\n\n294.22s (~4.9 minutes)\n\n\n\n\n4\n\n\n289.123s (~4.82 minutes)\n\n\n\n\n5\n\n\n295.178s (~4.92 minutes)\n\n\n\n\n6\n\n\n299.366s (~4.99 minutes)"
  },
  {
    "objectID": "content/posts/climbing/index.html#posterior-data",
    "href": "content/posts/climbing/index.html#posterior-data",
    "title": "Bayesian Rock Climbing Rankings",
    "section": "\n5.1 Posterior data",
    "text": "5.1 Posterior data\nGetting our Posterior Predictions (subset of 500 draws per route) into long format:\n\n\n\n\n\n\nNote\n\n\n\nComparing data.table and dplyr (using the rvar format from posterior):\n\n\n\n\ndata.table\ndplyr\n\n\n\n\nunique(dt_clean[, .(route_idx, bouldering_grade, route_rating, climb_type)], by = \"route_idx\")[\n  as.data.table(mod_stan$draws(variables = \"route_difficulty\") |> \n   bind(x, subset_draws(x, \"route_difficulty\", regex = T, draw = sample.int(ndraws(x), size = 500))))\n   [, .(route_difficulty = list(value)), by = variable\n  ][, `:=`(route_idx = as.integer(str_extract(variable, \"\\\\d{1,4}\")), variable = NULL)],\n  on = \"route_idx\", nomatch = NULL\n][, `:=`(\n  bouldering_grade = factor(bouldering_grade, levels = bouldering_grades), \n  route_rating = factor(route_rating, levels = route_ratings)\n)][order(route_idx)] -> pp\n\n\ndata.table [4,288 x 5]\n\n\n\nroute_idx\n\n\nbouldering_grade\n\n\nroute_rating\n\n\nclimb_type\n\n\nroute_difficulty\n\n\n\n\n\n1\n\n\nV7\n\n\n5.12a\n\n\n1\n\n\n<numeric [500]>\n\n\n\n\n2\n\n\nV7\n\n\n5.12a\n\n\n1\n\n\n<numeric [500]>\n\n\n\n\n3\n\n\nV5\n\n\n5.11a\n\n\n1\n\n\n<numeric [500]>\n\n\n\n\n4\n\n\nV7\n\n\n5.12a\n\n\n1\n\n\n<numeric [500]>\n\n\n\n\n5\n\n\nV4\n\n\n5.10c\n\n\n1\n\n\n<numeric [500]>\n\n\n\n\n6\n\n\nV5\n\n\n5.11a\n\n\n1\n\n\n<numeric [500]>\n\n\n\n\n7\n\n\nV9\n\n\n5.12d\n\n\n1\n\n\n<numeric [500]>\n\n\n\n\n8\n\n\nV3\n\n\n5.10a\n\n\n1\n\n\n<numeric [500]>\n\n\n\n\n9\n\n\nV9\n\n\n5.12d\n\n\n1\n\n\n<numeric [500]>\n\n\n\n\n10\n\n\nV8\n\n\n5.12c\n\n\n1\n\n\n<numeric [500]>\n\n\n\n\n11\n\n\nV5\n\n\n5.11a\n\n\n1\n\n\n<numeric [500]>\n\n\n\n\n12\n\n\nV5\n\n\n5.11a\n\n\n1\n\n\n<numeric [500]>\n\n\n\n\n13\n\n\nV3\n\n\n5.10a\n\n\n1\n\n\n<numeric [500]>\n\n\n\n\n14\n\n\nV6\n\n\n5.11d\n\n\n1\n\n\n<numeric [500]>\n\n\n\n\n15\n\n\nV5\n\n\n5.11b\n\n\n0\n\n\n<numeric [500]>\n\n\n\n\n\n[ omitted 4,273 entries ]\n\n\nTime difference of 1.707 secs\n\n\n\nWith dplyr, we can use the rvar format to encapsulate the samples from the model, which drastically reduces the size of the samples’ data.frame\n\npp_df <- (inner_join(\n    select(df_clean, route_idx, bouldering_grade, route_rating, climb_type) |> \n      distinct(route_idx, .keep_all = TRUE),\n    tidybayes::spread_rvars(mod_stan, route_difficulty[route_idx], ndraws = 500),\n    by = \"route_idx\"\n  )\n  |> mutate(\n    bouldering_grade = factor(bouldering_grade, levels = bouldering_grades), \n    route_rating = factor(route_rating, levels = route_ratings)\n  )\n  |> arrange(route_idx)\n)\n\n\ndata.frame [4,288 x 5]\n\n\n\nroute_idx\n\n\nbouldering_grade\n\n\nroute_rating\n\n\nclimb_type\n\n\nroute_difficulty\n\n\n\n\n\n1\n\n\nV7\n\n\n5.12a\n\n\n1\n\n\n<rvar [1 x NA]>\n\n\n\n\n2\n\n\nV7\n\n\n5.12a\n\n\n1\n\n\n<rvar [1 x NA]>\n\n\n\n\n3\n\n\nV5\n\n\n5.11a\n\n\n1\n\n\n<rvar [1 x NA]>\n\n\n\n\n4\n\n\nV7\n\n\n5.12a\n\n\n1\n\n\n<rvar [1 x NA]>\n\n\n\n\n5\n\n\nV4\n\n\n5.10c\n\n\n1\n\n\n<rvar [1 x NA]>\n\n\n\n\n6\n\n\nV5\n\n\n5.11a\n\n\n1\n\n\n<rvar [1 x NA]>\n\n\n\n\n7\n\n\nV9\n\n\n5.12d\n\n\n1\n\n\n<rvar [1 x NA]>\n\n\n\n\n8\n\n\nV3\n\n\n5.10a\n\n\n1\n\n\n<rvar [1 x NA]>\n\n\n\n\n9\n\n\nV9\n\n\n5.12d\n\n\n1\n\n\n<rvar [1 x NA]>\n\n\n\n\n10\n\n\nV8\n\n\n5.12c\n\n\n1\n\n\n<rvar [1 x NA]>\n\n\n\n\n11\n\n\nV5\n\n\n5.11a\n\n\n1\n\n\n<rvar [1 x NA]>\n\n\n\n\n12\n\n\nV5\n\n\n5.11a\n\n\n1\n\n\n<rvar [1 x NA]>\n\n\n\n\n13\n\n\nV3\n\n\n5.10a\n\n\n1\n\n\n<rvar [1 x NA]>\n\n\n\n\n14\n\n\nV6\n\n\n5.11d\n\n\n1\n\n\n<rvar [1 x NA]>\n\n\n\n\n15\n\n\nV7\n\n\n5.12a\n\n\n0\n\n\n<rvar [1 x NA]>\n\n\n\n\n\n[ omitted 4,273 entries ]\n\n\nTime difference of 1.03 secs"
  },
  {
    "objectID": "content/posts/climbing/index.html#posterior-plots",
    "href": "content/posts/climbing/index.html#posterior-plots",
    "title": "Bayesian Rock Climbing Rankings",
    "section": "\n5.2 Posterior plots:",
    "text": "5.2 Posterior plots:\n\nPlot coderidgeline_plot <- function(dat, var) {\n  if (class(dat[, route_difficulty]) == \"list\")\n    dat <- dat[, .(route_difficulty = unlist(route_difficulty)), by = setdiff(names(dat), 'route_difficulty')]\n  \n  ggplot(dat, aes_string(y = var)) +\n  ggridges::geom_density_ridges(\n    aes_string(x = \"route_difficulty\", fill = var), \n    alpha = 0.5, scale = 2.5, color = \"grey30\"\n  ) +\n  geom_vline(xintercept = 0, linetype = \"dashed\", color = \"grey50\") +\n  labs(x = str_to_title(str_replace_all(var, \"_\", \" \")), y = \"\") +\n  scale_y_discrete(position = \"right\") +\n  theme(legend.position = \"none\", axis.line.y = element_blank())\n}\n\n\nRoute Rating:\n\nridgeline_plot(pp[climb_type == 0], \"route_rating\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBouldering Grade:\n\nridgeline_plot(pp[climb_type == 1 & bouldering_grade != \"V0\"], \"bouldering_grade\")"
  },
  {
    "objectID": "content/posts/index.html",
    "href": "content/posts/index.html",
    "title": "Blog Posts",
    "section": "",
    "text": "Reusehttps://creativecommons.org/licenses/by/4.0/"
  },
  {
    "objectID": "content/posts/spatial/index.html",
    "href": "content/posts/spatial/index.html",
    "title": "Fast spatial data matching in R",
    "section": "",
    "text": "Tip\n\n\n\nYou can check the source code by clicking on the </> Code button at the top-right."
  },
  {
    "objectID": "content/posts/spatial/index.html#wide-format-original",
    "href": "content/posts/spatial/index.html#wide-format-original",
    "title": "Fast spatial data matching in R",
    "section": "\n2.1 Wide format (original)",
    "text": "2.1 Wide format (original)\n\n\ndata.table\nSQL (DuckDB)\n\n\n\n\nrides <- (purrr::map_dfr(\n    fs::dir_ls(data_path, glob = \"*.csv\"),\n    \\(file) fread(file, na.strings = \"\")\n  )\n)\n\nsetkey(rides, ride_id)\n\n\n\nTime difference of 16.66 secs\n\n\n\n\n\nrides_con <- DBI::dbConnect(duckdb::duckdb())\n\n\n\n\n\nduckdb::duckdb_read_csv(\n  rides_con, \n  \"rides\", \n  fs::dir_ls(here::here(\"res\", \"data\", \"stations\"), glob = \"*.csv\")\n)\n\n\nCREATE INDEX ride_idx ON rides (ride_id)\n\n\n\nTime difference of 8.977 secs\n\n\n\n\n\n\n\ndata.frame [5,860,776 x 13]\n\n\n\nride_id\n\n\nrideable_type\n\n\nstarted_at\n\n\nended_at\n\n\nstart_station_name\n\n\nstart_station_id\n\n\nend_station_name\n\n\nend_station_id\n\n\nstart_lat\n\n\nstart_lng\n\n\nend_lat\n\n\nend_lng\n\n\nmember_casual\n\n\n\n\n\n00000123F60251E6\n\n\nclassic_bike\n\n\n2022-02-07 15:47:40\n\n\n2022-02-07 15:49:28\n\n\nWells St & Hubbard St\n\n\nTA1307000151\n\n\nKingsbury St & Kinzie St\n\n\nKA1503000043\n\n\n41.89\n\n\n−87.634\n\n\n41.889\n\n\n−87.639\n\n\nmember\n\n\n\n\n000002EBE159AE82\n\n\nelectric_bike\n\n\n2021-06-22 17:25:15\n\n\n2021-06-22 17:31:34\n\n\nClinton St & Jackson Blvd\n\n\n638\n\n\nMilwaukee Ave & Grand Ave\n\n\n13033\n\n\n41.878\n\n\n−87.641\n\n\n41.891\n\n\n−87.648\n\n\nmember\n\n\n\n\n0000080D43BAA9E4\n\n\nclassic_bike\n\n\n2021-08-29 15:38:05\n\n\n2021-08-29 16:24:03\n\n\nDearborn St & Van Buren St\n\n\n624\n\n\nFederal St & Polk St\n\n\nSL-008\n\n\n41.876\n\n\n−87.629\n\n\n41.872\n\n\n−87.63\n\n\ncasual\n\n\n\n\n00000B4F1F71F9C2\n\n\nelectric_bike\n\n\n2021-09-08 16:31:38\n\n\n2021-09-08 16:37:54\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n41.91\n\n\n−87.69\n\n\n41.91\n\n\n−87.7\n\n\nmember\n\n\n\n\n00000CAE95438C9D\n\n\nclassic_bike\n\n\n2021-07-20 15:40:46\n\n\n2021-07-20 17:38:17\n\n\nStreeter Dr & Grand Ave\n\n\n13022\n\n\nFairbanks Ct & Grand Ave\n\n\nTA1305000003\n\n\n41.892\n\n\n−87.612\n\n\n41.892\n\n\n−87.621\n\n\ncasual\n\n\n\n\n00000E22FBA89D81\n\n\nelectric_bike\n\n\n2022-05-19 14:42:55\n\n\n2022-05-19 14:54:03\n\n\nNA\n\n\nNA\n\n\nClark St & Armitage Ave\n\n\n13146\n\n\n41.9\n\n\n−87.62\n\n\n41.918\n\n\n−87.636\n\n\nmember\n\n\n\n\n00000EBBC119168C\n\n\nclassic_bike\n\n\n2021-10-31 11:30:37\n\n\n2021-10-31 11:39:27\n\n\nDorchester Ave & 49th St\n\n\nKA1503000069\n\n\nKimbark Ave & 53rd St\n\n\nTA1309000037\n\n\n41.806\n\n\n−87.592\n\n\n41.8\n\n\n−87.595\n\n\nmember\n\n\n\n\n000018B1D040DB44\n\n\nelectric_bike\n\n\n2022-04-25 10:37:22\n\n\n2022-04-25 10:44:19\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n41.79\n\n\n−87.6\n\n\n41.79\n\n\n−87.59\n\n\nmember\n\n\n\n\n000019B7F053D461\n\n\nclassic_bike\n\n\n2021-08-13 19:57:28\n\n\n2021-08-13 20:02:56\n\n\nLarrabee St & Webster Ave\n\n\n13193\n\n\nSheffield Ave & Webster Ave\n\n\nTA1309000033\n\n\n41.922\n\n\n−87.644\n\n\n41.922\n\n\n−87.654\n\n\nmember\n\n\n\n\n00001B4F79D102B5\n\n\nclassic_bike\n\n\n2021-07-28 07:58:27\n\n\n2021-07-28 08:05:00\n\n\nDuSable Lake Shore Dr & Belmont Ave\n\n\nTA1309000049\n\n\nBroadway & Waveland Ave\n\n\n13325\n\n\n41.941\n\n\n−87.639\n\n\n41.949\n\n\n−87.649\n\n\ncasual\n\n\n\n\n\n[ omitted 5,860,761 entries ]"
  },
  {
    "objectID": "content/posts/spatial/index.html#long-format",
    "href": "content/posts/spatial/index.html#long-format",
    "title": "Fast spatial data matching in R",
    "section": "\n2.2 Long format",
    "text": "2.2 Long format\n\n\ndata.table\ndtplyr\nSQL (DuckDB)\ndbplyr\n\n\n\n\nrides_l <- melt(\n  rides,\n  measure = measure(way, value.name, pattern = \"(end|start).*(name|id|lat|lng)\")\n)\n\nsetkey(rides_l, ride_id, id)\n\n\n\nTime difference of 6.023 secs\n\n\n\n\n\nrides_l.dtp <- (pivot_longer(\n    rides,\n    matches(\"^end_|^start_\"),\n    names_pattern = \"(end|start).*(name|id|lat|lng)\",\n    names_to = c(\"way\", \".value\")\n  ) \n  |> as.data.table()\n)\n\nsetkey(rides_l.dtp, ride_id, id)\n\n\n\nTime difference of 9.999 secs\n\n\n\n\n\nCREATE TABLE rides_l AS \n(\n  SELECT\n    ride_id, rideable_type, started_at, ended_at,member_casual\n    , 'start' AS way\n    , start_station_name AS name\n    , start_station_id AS id\n    , start_lat AS lat\n    , start_lng AS lng\n  FROM rides\n)\nUNION ALL\n(\n  SELECT\n    ride_id, rideable_type, started_at, ended_at, member_casual\n    , 'end' AS way\n    , end_station_name AS name\n    , end_station_id AS id\n    , end_lat AS lat\n    , end_lng AS lng\n  FROM rides\n);\n\nCREATE INDEX station_idx ON rides_l (id);\n\n\n\nTime difference of 7.302 secs\n\n\n\n\n\n\n\n\nAlternatively\n\n\n\n\n\nWe can reuse an existinf df and directly add it (or bind it as a view) to the database:\n\nDBI::dbWriteTable(rides_con, \"rides_l\", rides_l) # As a TABLE\n\nduckdb::duckdb_register(rides_con, \"rides_l\", rides_l) # As a VIEW\n\n\n\n\n\n\n\n(dplyr::tbl(rides_con, \"rides\") \n  |> pivot_longer(\n    matches(\"^end_|^start_\"),\n    names_pattern = \"(end|start).*(name|id|lat|lng)\", \n    names_to = c(\"way\", \".value\")\n  )\n  |> dplyr::copy_to(\n    rides_con, \n    df = _, \n    \"rides_l_dbp\",\n    temporary = FALSE,\n    indexes = list(\"ride_id\", \"id\")\n  )\n)\n\n\n\nTime difference of 13.37 secs\n\n\n\n\n\n\n\ndata.frame [11,721,552 x 10]\n\n\n\nride_id\n\n\nrideable_type\n\n\nstarted_at\n\n\nended_at\n\n\nmember_casual\n\n\nway\n\n\nname\n\n\nid\n\n\nlat\n\n\nlng\n\n\n\n\n\n99FEC93BA843FB20\n\n\nelectric_bike\n\n\n2021-06-13 14:31:28\n\n\n2021-06-13 14:34:11\n\n\nmember\n\n\nstart\n\n\nNA\n\n\nNA\n\n\n41.8\n\n\n−87.59\n\n\n\n\n06048DCFC8520CAF\n\n\nelectric_bike\n\n\n2021-06-04 11:18:02\n\n\n2021-06-04 11:24:19\n\n\nmember\n\n\nstart\n\n\nNA\n\n\nNA\n\n\n41.79\n\n\n−87.59\n\n\n\n\n9598066F68045DF2\n\n\nelectric_bike\n\n\n2021-06-04 09:49:35\n\n\n2021-06-04 09:55:34\n\n\nmember\n\n\nstart\n\n\nNA\n\n\nNA\n\n\n41.8\n\n\n−87.6\n\n\n\n\nB03C0FE48C412214\n\n\nelectric_bike\n\n\n2021-06-03 19:56:05\n\n\n2021-06-03 20:21:55\n\n\nmember\n\n\nstart\n\n\nNA\n\n\nNA\n\n\n41.78\n\n\n−87.58\n\n\n\n\nB9EEA89F8FEE73B7\n\n\nelectric_bike\n\n\n2021-06-04 14:05:51\n\n\n2021-06-04 14:09:59\n\n\nmember\n\n\nstart\n\n\nNA\n\n\nNA\n\n\n41.8\n\n\n−87.59\n\n\n\n\n62B943CEAAA420BA\n\n\nelectric_bike\n\n\n2021-06-03 19:32:01\n\n\n2021-06-03 19:38:46\n\n\nmember\n\n\nstart\n\n\nNA\n\n\nNA\n\n\n41.78\n\n\n−87.58\n\n\n\n\n7E2546FBA79C46EE\n\n\nelectric_bike\n\n\n2021-06-10 16:30:10\n\n\n2021-06-10 16:36:21\n\n\nmember\n\n\nstart\n\n\nNA\n\n\nNA\n\n\n41.79\n\n\n−87.6\n\n\n\n\n3DDF3BBF6C4C3C89\n\n\nelectric_bike\n\n\n2021-06-10 17:00:30\n\n\n2021-06-10 17:06:48\n\n\nmember\n\n\nstart\n\n\nNA\n\n\nNA\n\n\n41.79\n\n\n−87.59\n\n\n\n\n2608805637155AB6\n\n\nelectric_bike\n\n\n2021-06-10 12:46:16\n\n\n2021-06-10 12:55:02\n\n\nmember\n\n\nstart\n\n\nNA\n\n\nNA\n\n\n41.93\n\n\n−87.67\n\n\n\n\nAF529C946F28ED42\n\n\nelectric_bike\n\n\n2021-06-23 17:57:29\n\n\n2021-06-23 18:06:40\n\n\nmember\n\n\nstart\n\n\nNA\n\n\nNA\n\n\n41.88\n\n\n−87.61\n\n\n\n\n\n[ omitted 11,721,537 entries ]"
  },
  {
    "objectID": "content/posts/spatial/index.html#cleaning-useless-coordinates",
    "href": "content/posts/spatial/index.html#cleaning-useless-coordinates",
    "title": "Fast spatial data matching in R",
    "section": "\n3.1 Cleaning useless coordinates",
    "text": "3.1 Cleaning useless coordinates\nRemoving entries were lat/lng do not have sufficient precision to be reliably matched to a station (i.e. entries having less than 4 decimals, which corresponds to a 11 meters “radius” at the equator).\n\n\n\n\n\n\nDegrees to distance equivalence\n\n\n\n\n\n\n\nDecimal\nDistance at the equator (m)\n\n\n\n0\n111,120\n\n\n1\n11,112\n\n\n2\n1,111.2\n\n\n3\n111.12\n\n\n4\n11.112\n\n\n5\n1.1112\n\n\n\n\n\n\n\ndecp <- \\(x) str_length(str_remove(as.character(abs(x)), \".*\\\\.\")) >= 4\n\n\nCREATE FUNCTION decp(x) AS length(str_split(CAST(abs(x) AS VARCHAR(10)), '.')[2]) >= 4\n\n\n\n\n\n\ndata.table\ndtplyr\nSQL (DuckDB)\ndbplyr\n\n\n\n\nrides_l_clean <- rides_l[decp(lat) & decp(lng), ]\n\nsetkey(rides_l_clean, ride_id)\n\n\n\nTime difference of 25.13 secs\n\n\n\n\n\nrides_l_clean.dtp <- (rides_l\n  |> filter(decp(lat) & decp(lng))\n  |> as.data.table()\n)\n\nsetkey(rides_l_clean.dtp, ride_id)\n\n\n\nTime difference of 25.42 secs\n\n\n\n\n\nCREATE TABLE rides_l_clean AS \nSELECT * FROM rides_l \nWHERE decp(lat) AND decp(lng)\n\n\n\nTime difference of 6.128 secs\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nHere, dbplyr will leave the decp call as-is in the SQL translation, but since we have previously defined a decp SQL function, this function will get called when the SQL query is executed.\n\n\n\n(dplyr::tbl(rides_con, \"rides_l\") \n  |> filter(if_all(c(lat, lng), \\(x) decp(x)))\n  |> dplyr::copy_to(\n    rides_con, \n    df = _, \n    \"rides_l_clean_dbp\",\n    temporary = FALSE,\n    indexes = list(\"ride_id\", \"id\")\n  )\n)\n\n\n\nTime difference of 17.76 secs\n\n\n\n\n\n\n\n\n\n\ndata.table [9,937,077 x 10]\n\n\n\nride_id\n\n\nrideable_type\n\n\nstarted_at\n\n\nended_at\n\n\nmember_casual\n\n\nway\n\n\nname\n\n\nid\n\n\nlat\n\n\nlng\n\n\n\n\n\n00000123F60251E6\n\n\nclassic_bike\n\n\n2022-02-07 15:47:40\n\n\n2022-02-07 15:49:28\n\n\nmember\n\n\nend\n\n\nKingsbury St & Kinzie St\n\n\nKA1503000043\n\n\n41.889\n\n\n−87.639\n\n\n\n\n00000123F60251E6\n\n\nclassic_bike\n\n\n2022-02-07 15:47:40\n\n\n2022-02-07 15:49:28\n\n\nmember\n\n\nstart\n\n\nWells St & Hubbard St\n\n\nTA1307000151\n\n\n41.89\n\n\n−87.634\n\n\n\n\n000002EBE159AE82\n\n\nelectric_bike\n\n\n2021-06-22 17:25:15\n\n\n2021-06-22 17:31:34\n\n\nmember\n\n\nend\n\n\nMilwaukee Ave & Grand Ave\n\n\n13033\n\n\n41.891\n\n\n−87.648\n\n\n\n\n000002EBE159AE82\n\n\nelectric_bike\n\n\n2021-06-22 17:25:15\n\n\n2021-06-22 17:31:34\n\n\nmember\n\n\nstart\n\n\nClinton St & Jackson Blvd\n\n\n638\n\n\n41.878\n\n\n−87.641\n\n\n\n\n0000080D43BAA9E4\n\n\nclassic_bike\n\n\n2021-08-29 15:38:05\n\n\n2021-08-29 16:24:03\n\n\ncasual\n\n\nstart\n\n\nDearborn St & Van Buren St\n\n\n624\n\n\n41.876\n\n\n−87.629\n\n\n\n\n0000080D43BAA9E4\n\n\nclassic_bike\n\n\n2021-08-29 15:38:05\n\n\n2021-08-29 16:24:03\n\n\ncasual\n\n\nend\n\n\nFederal St & Polk St\n\n\nSL-008\n\n\n41.872\n\n\n−87.63\n\n\n\n\n00000CAE95438C9D\n\n\nclassic_bike\n\n\n2021-07-20 15:40:46\n\n\n2021-07-20 17:38:17\n\n\ncasual\n\n\nstart\n\n\nStreeter Dr & Grand Ave\n\n\n13022\n\n\n41.892\n\n\n−87.612\n\n\n\n\n00000CAE95438C9D\n\n\nclassic_bike\n\n\n2021-07-20 15:40:46\n\n\n2021-07-20 17:38:17\n\n\ncasual\n\n\nend\n\n\nFairbanks Ct & Grand Ave\n\n\nTA1305000003\n\n\n41.892\n\n\n−87.621\n\n\n\n\n00000E22FBA89D81\n\n\nelectric_bike\n\n\n2022-05-19 14:42:55\n\n\n2022-05-19 14:54:03\n\n\nmember\n\n\nend\n\n\nClark St & Armitage Ave\n\n\n13146\n\n\n41.918\n\n\n−87.636\n\n\n\n\n00000EBBC119168C\n\n\nclassic_bike\n\n\n2021-10-31 11:30:37\n\n\n2021-10-31 11:39:27\n\n\nmember\n\n\nstart\n\n\nDorchester Ave & 49th St\n\n\nKA1503000069\n\n\n41.806\n\n\n−87.592\n\n\n\n\n00000EBBC119168C\n\n\nclassic_bike\n\n\n2021-10-31 11:30:37\n\n\n2021-10-31 11:39:27\n\n\nmember\n\n\nend\n\n\nKimbark Ave & 53rd St\n\n\nTA1309000037\n\n\n41.8\n\n\n−87.595\n\n\n\n\n000019B7F053D461\n\n\nclassic_bike\n\n\n2021-08-13 19:57:28\n\n\n2021-08-13 20:02:56\n\n\nmember\n\n\nstart\n\n\nLarrabee St & Webster Ave\n\n\n13193\n\n\n41.922\n\n\n−87.644\n\n\n\n\n000019B7F053D461\n\n\nclassic_bike\n\n\n2021-08-13 19:57:28\n\n\n2021-08-13 20:02:56\n\n\nmember\n\n\nend\n\n\nSheffield Ave & Webster Ave\n\n\nTA1309000033\n\n\n41.922\n\n\n−87.654\n\n\n\n\n00001B4F79D102B5\n\n\nclassic_bike\n\n\n2021-07-28 07:58:27\n\n\n2021-07-28 08:05:00\n\n\ncasual\n\n\nend\n\n\nBroadway & Waveland Ave\n\n\n13325\n\n\n41.949\n\n\n−87.649\n\n\n\n\n00001B4F79D102B5\n\n\nclassic_bike\n\n\n2021-07-28 07:58:27\n\n\n2021-07-28 08:05:00\n\n\ncasual\n\n\nstart\n\n\nDuSable Lake Shore Dr & Belmont Ave\n\n\nTA1309000049\n\n\n41.941\n\n\n−87.639\n\n\n\n\n\n[ omitted 9,937,062 entries ]"
  },
  {
    "objectID": "content/posts/spatial/index.html#whats-missing",
    "href": "content/posts/spatial/index.html#whats-missing",
    "title": "Fast spatial data matching in R",
    "section": "\n3.2 What’s missing ?",
    "text": "3.2 What’s missing ?\nEntries missing one or both coordinates but having an id or name:\n\n\ndata.table\nSQL (DuckDB)\ndbplyr\n\n\n\n\nrides_l_clean[(is.na(lat) | is.na(lng)) & (!is.na(id) | !is.na(name)), ]\n\n\n\n\nSELECT * FROM rides_l_clean \nWHERE ((lat IS NULL) OR (lng IS NULL) \n  AND (NOT((id IS NULL)) OR NOT((name IS NULL))))\n\n\n\n\n(dplyr::tbl(rides_con, \"rides_l_clean\")\n  |> filter(\n    if_any(matches(\"lat$|lng$\"), \\(v) is.na(v)) & \n    (!is.na(id) | !is.na(name))\n  )\n  |> collect()\n)\n\n\n\n\n\n\ndata.frame [0 x 10]\n\n\n\nride_id\n\n\nrideable_type\n\n\nstarted_at\n\n\nended_at\n\n\nmember_casual\n\n\nway\n\n\nname\n\n\nid\n\n\nlat\n\n\nlng\n\n\n\n\n\nEntries missing either name or id, but having coordinates:\n\n\ndata.table\ndtplyr\nSQL (DuckDB)\ndbplyr\n\n\n\n\nrides_l_clean[(!is.na(lat) & !is.na(lng)) & (is.na(id) | is.na(name)), ]\n\n\n\n\nrides_l_clean_unk <- (rides_l_clean \n  |> filter(\n    if_all(matches(\"lat$|lng$\"), \\(v) !is.na(v)) & \n    (is.na(id) | is.na(name))\n  )\n  |> as.data.table()\n)\n\n\n\n\nCREATE TABLE rides_l_clean_unk AS\nSELECT * FROM rides_l_clean\nWHERE ((id IS NULL) OR (name IS NULL)) \n  AND (NOT((lat IS NULL)) AND NOT((lng IS NULL)))\n\n\n\n\n\n\n\n(dplyr::tbl(rides_con, \"rides_l_clean\") \n  |> filter(\n    if_all(matches(\"lat$|lng$\"), \\(v) !is.na(v)) & \n    (is.na(id) | is.na(name))\n  )\n  |> collect()\n)\n\n\n\n\n\n\ndata.frame [3 x 10]\n\n\n\nride_id\n\n\nrideable_type\n\n\nstarted_at\n\n\nended_at\n\n\nmember_casual\n\n\nway\n\n\nname\n\n\nid\n\n\nlat\n\n\nlng\n\n\n\n\n\n176105D1F8A1216B\n\n\nelectric_bike\n\n\n2021-07-18 03:44:22\n\n\n2021-07-18 04:12:23\n\n\ncasual\n\n\nstart\n\n\nNA\n\n\n13221\n\n\n41.908\n\n\n−87.673\n\n\n\n\nDE82A15026BA3056\n\n\nelectric_bike\n\n\n2021-09-21 18:18:59\n\n\n2021-09-21 18:21:48\n\n\ncasual\n\n\nstart\n\n\nNA\n\n\n20215\n\n\n41.648\n\n\n−87.546\n\n\n\n\nEE197EDA4CF8CFE5\n\n\nelectric_bike\n\n\n2021-09-22 07:14:42\n\n\n2021-09-22 07:22:38\n\n\ncasual\n\n\nstart\n\n\nNA\n\n\nWL-008\n\n\n41.867\n\n\n−87.641\n\n\n\n\n\nIt seems there are only 3 entries missing identification that could be matched based on their coordinates at the level of precision we use (11m / 4 decimals).\n\n\n\n\n\n\nWarning\n\n\n\nAlthough, if we look at the original dataset (before filtering the inaccurate coordinates):\n\n\n\n\ndata.table\ndtplyr\nSQL (DuckDB)\ndbplyr\n\n\n\n\nrides_l[(!is.na(lat) & !is.na(lng)) & (is.na(id) | is.na(name)), ]\n\n\n\n\nrides_l_unk <- (rides_l\n  |> filter(\n    if_all(matches(\"lat$|lng$\"), \\(v) !is.na(v)) & \n    (is.na(id) | is.na(name))\n  )\n  |> as.data.table()\n)\n\n\n\n\nCREATE TABLE rides_l_unk AS\nSELECT * FROM rides_l\nWHERE ((id IS NULL) OR (name IS NULL)) \n  AND (NOT((lat IS NULL)) AND NOT((lng IS NULL)))\n\n\n\n\n\n\n\n(dplyr::tbl(rides_con, \"rides_l\") \n  |> filter(\n    if_all(matches(\"lat$|lng$\"), \\(v) !is.na(v)) & \n    (is.na(id) | is.na(name))\n  )\n  |> collect()\n)\n\n\n\n\n\n\ndata.frame [1,696,469 x 10]\n\n\n\nride_id\n\n\nrideable_type\n\n\nstarted_at\n\n\nended_at\n\n\nmember_casual\n\n\nway\n\n\nname\n\n\nid\n\n\nlat\n\n\nlng\n\n\n\n\n\n00000B4F1F71F9C2\n\n\nelectric_bike\n\n\n2021-09-08 16:31:38\n\n\n2021-09-08 16:37:54\n\n\nmember\n\n\nend\n\n\nNA\n\n\nNA\n\n\n41.91\n\n\n−87.7\n\n\n\n\n00000B4F1F71F9C2\n\n\nelectric_bike\n\n\n2021-09-08 16:31:38\n\n\n2021-09-08 16:37:54\n\n\nmember\n\n\nstart\n\n\nNA\n\n\nNA\n\n\n41.91\n\n\n−87.69\n\n\n\n\n00000E22FBA89D81\n\n\nelectric_bike\n\n\n2022-05-19 14:42:55\n\n\n2022-05-19 14:54:03\n\n\nmember\n\n\nstart\n\n\nNA\n\n\nNA\n\n\n41.9\n\n\n−87.62\n\n\n\n\n000018B1D040DB44\n\n\nelectric_bike\n\n\n2022-04-25 10:37:22\n\n\n2022-04-25 10:44:19\n\n\nmember\n\n\nend\n\n\nNA\n\n\nNA\n\n\n41.79\n\n\n−87.59\n\n\n\n\n000018B1D040DB44\n\n\nelectric_bike\n\n\n2022-04-25 10:37:22\n\n\n2022-04-25 10:44:19\n\n\nmember\n\n\nstart\n\n\nNA\n\n\nNA\n\n\n41.79\n\n\n−87.6\n\n\n\n\n000025C113FEB7B6\n\n\nelectric_bike\n\n\n2021-10-25 11:15:21\n\n\n2021-10-25 11:20:21\n\n\nmember\n\n\nstart\n\n\nNA\n\n\nNA\n\n\n41.81\n\n\n−87.62\n\n\n\n\n000025C113FEB7B6\n\n\nelectric_bike\n\n\n2021-10-25 11:15:21\n\n\n2021-10-25 11:20:21\n\n\nmember\n\n\nend\n\n\nNA\n\n\nNA\n\n\n41.81\n\n\n−87.62\n\n\n\n\n00002E385DB2888C\n\n\nelectric_bike\n\n\n2022-05-07 16:28:53\n\n\n2022-05-07 16:40:28\n\n\ncasual\n\n\nend\n\n\nNA\n\n\nNA\n\n\n41.87\n\n\n−87.75\n\n\n\n\n00002E385DB2888C\n\n\nelectric_bike\n\n\n2022-05-07 16:28:53\n\n\n2022-05-07 16:40:28\n\n\ncasual\n\n\nstart\n\n\nNA\n\n\nNA\n\n\n41.89\n\n\n−87.75\n\n\n\n\n000043B681BFB305\n\n\nelectric_bike\n\n\n2021-10-14 16:24:41\n\n\n2021-10-14 16:29:02\n\n\ncasual\n\n\nend\n\n\nNA\n\n\nNA\n\n\n41.9\n\n\n−87.7\n\n\n\n\n\n[ omitted 1,696,454 entries ]\n\n\n\n\nThere were 1,696,469 missing stations’ id or name that could have been filled in the original data, but it seems that all of them disappeared when we filtered the coordinates with less than 4 decimals of precision. It would seem that those entries were missing their id/name in the source data because their coordinates were too imprecise to be matched to any station in the first place.\n\n\n\n\n\n\nIf one were to do the macthing anyway, here’s how:"
  },
  {
    "objectID": "content/posts/spatial/index.html#creating-stations-data",
    "href": "content/posts/spatial/index.html#creating-stations-data",
    "title": "Fast spatial data matching in R",
    "section": "\n4.1 Creating stations data",
    "text": "4.1 Creating stations data\nFirst, we need to assemble a dataset linking each unique station id (and name) with a set of coordinates (here, we use the average lat & lng)\n\n\ndata.table\nSQL (DuckDB)\ndbplyr\n\n\n\n\nstations_clean <- ((rides_l_clean\n  |> na.omit(cols = c(\"id\", \"name\"))\n  |> dcast(id + name ~ ., fun.aggregate = list(min, max, mean), value.var = c(\"lat\", \"lng\"))\n  |> pipebind::bind(x, setcolorder(x, c(\"id\", \"name\", str_subset(names(x), \"lat_|_lng\"))))\n  |> unique(by = \"id\")\n  )\n)\n\nsetkey(stations_clean, id)\n\n\n\n\nCREATE TABLE stations_clean AS \nSELECT DISTINCT on(id)\n  id, name\n  , MIN(lat) AS lat_min\n  , MAX(lat) AS lat_max\n  , AVG(lat) AS lat_mean\n  , MIN(lng) AS lng_min\n  , MAX(lng) AS lng_max\n  , AVG(lng) AS lng_mean\nFROM rides_l_clean\nWHERE (NOT((id IS NULL))) AND (NOT((name IS NULL)))\nGROUP BY id, name;\n\n\n\n\n(dplyr::tbl(rides_con, \"rides_l_clean\")\n  |> filter(!is.na(id), !is.na(name))\n  |> group_by(id, name)\n  |> summarize(across(c(lat, lng), list(min, max, mean), .names = \"{.col}_{.fn}\"))\n  |> ungroup()\n  |> distinct(id, .keep_all = TRUE)\n  |> arrange(id)\n  |> collect()\n)\n\n\n\n\n\n\ndata.frame [693 x 8]\n\n\n\nid\n\n\nname\n\n\nlat_min\n\n\nlat_max\n\n\nlat_mean\n\n\nlng_min\n\n\nlng_max\n\n\nlng_mean\n\n\n\n\n\n13001\n\n\nMichigan Ave & Washington St\n\n\n41.813\n\n\n41.958\n\n\n41.884\n\n\n−87.657\n\n\n−87.59\n\n\n−87.625\n\n\n\n\n13006\n\n\nLaSalle St & Washington St\n\n\n41.872\n\n\n41.952\n\n\n41.883\n\n\n−87.833\n\n\n−87.619\n\n\n−87.633\n\n\n\n\n13008\n\n\nMillennium Park\n\n\n41.809\n\n\n41.96\n\n\n41.881\n\n\n−87.785\n\n\n−87.587\n\n\n−87.624\n\n\n\n\n13011\n\n\nCanal St & Adams St\n\n\n41.871\n\n\n41.902\n\n\n41.879\n\n\n−87.657\n\n\n−87.626\n\n\n−87.64\n\n\n\n\n13016\n\n\nSt. Clair St & Erie St\n\n\n41.841\n\n\n41.931\n\n\n41.894\n\n\n−87.744\n\n\n−87.616\n\n\n−87.623\n\n\n\n\n13017\n\n\nFranklin St & Chicago Ave\n\n\n41.873\n\n\n41.917\n\n\n41.897\n\n\n−87.663\n\n\n−87.625\n\n\n−87.636\n\n\n\n\n13021\n\n\nClinton St & Lake St\n\n\n41.876\n\n\n41.909\n\n\n41.886\n\n\n−87.661\n\n\n−87.617\n\n\n−87.642\n\n\n\n\n13022\n\n\nStreeter Dr & Grand Ave\n\n\n41.772\n\n\n41.969\n\n\n41.892\n\n\n−87.785\n\n\n−87.586\n\n\n−87.612\n\n\n\n\n13028\n\n\n900 W Harrison St\n\n\n41.836\n\n\n41.881\n\n\n41.875\n\n\n−87.679\n\n\n−87.607\n\n\n−87.65\n\n\n\n\n13029\n\n\nField Museum\n\n\n41.81\n\n\n41.896\n\n\n41.865\n\n\n−87.625\n\n\n−87.588\n\n\n−87.618\n\n\n\n\n\n[ omitted 678 entries ]"
  },
  {
    "objectID": "content/posts/spatial/index.html#matching-on-the-cleaned-data",
    "href": "content/posts/spatial/index.html#matching-on-the-cleaned-data",
    "title": "Fast spatial data matching in R",
    "section": "\n5.1 Matching on the cleaned data",
    "text": "5.1 Matching on the cleaned data\nTo save time, let’s only apply the procedure to the entries that actually need to be matched (i.e. the ones having coordinates but missing either name or id).\n\n\nfuzzyjoin\nSQL (DuckDB)\n\n\n\nThere are 3 entries from rides_l_clean that could be position-matched to a known station.\n\nmatched_clean <- (fuzzyjoin::geo_inner_join(\n    as.data.frame(rides_l_clean_unk),\n    as.data.frame(stations_clean),\n    by = c(\"lng\" = \"lng_mean\", \"lat\" = \"lat_mean\"),\n    method = \"haversine\",\n    unit = \"km\",\n    max_dist = 0.011, # 11 meters\n    distance_col = \"dist\"\n  ) \n  |> mutate(name = coalesce(name.x, name.y), id = coalesce(id.x, id.y)) \n  |> select(names(rides_l_clean), dist)\n  |> arrange(ride_id)\n  |> drop_na(ride_id, id, name)\n  |> setDT()\n)\n\nsetkey(matched_clean, ride_id, id)\n\n\n\nTime difference of 0.1274 secs\n\n\n\n\nThere are 3 entries from rides_l_clean that could be position-matched to a known station.\nCreating the haversine distance function:\n\n\n\n\n\nCREATE FUNCTION haversine(lat1, lng1, lat2, lng2) \n    AS ( 6371 * acos( cos( radians(lat1) ) *\n       cos( radians(lat2) ) * cos( radians(lng2) - radians(lng1) ) +\n       sin( radians(lat1) ) * sin( radians(lat2) ) ) \n    );\n\nDoing the matching:\n\nCREATE TABLE matched_clean AS\nSELECT\n  ride_id, rideable_type, started_at, ended_at, member_casual, way  \n  , COALESCE(r.name, s.name) AS name\n  , COALESCE(r.id, s.id) AS id\n  , r.lat, r.lng\n  , haversine(s.lat_mean, s.lng_mean, r.lat, r.lng) AS dist\nFROM rides_l_clean_unk r, stations_clean s\nWHERE dist <= 0.011\n\n\n\nTime difference of 0.003556 secs\n\n\n\n\n\n\ndata.table [3 x 11]\n\n\n\nride_id\n\n\nrideable_type\n\n\nstarted_at\n\n\nended_at\n\n\nmember_casual\n\n\nway\n\n\nname\n\n\nid\n\n\nlat\n\n\nlng\n\n\ndist\n\n\n\n\n\n176105D1F8A1216B\n\n\nelectric_bike\n\n\n2021-07-18 03:44:22\n\n\n2021-07-18 04:12:23\n\n\ncasual\n\n\nstart\n\n\nWood St & Milwaukee Ave\n\n\n13221\n\n\n41.908\n\n\n−87.673\n\n\n0.002\n\n\n\n\nDE82A15026BA3056\n\n\nelectric_bike\n\n\n2021-09-21 18:18:59\n\n\n2021-09-21 18:21:48\n\n\ncasual\n\n\nstart\n\n\nHegewisch Metra Station\n\n\n20215\n\n\n41.648\n\n\n−87.546\n\n\n0.009\n\n\n\n\nEE197EDA4CF8CFE5\n\n\nelectric_bike\n\n\n2021-09-22 07:14:42\n\n\n2021-09-22 07:22:38\n\n\ncasual\n\n\nstart\n\n\nClinton St & Roosevelt Rd\n\n\nWL-008\n\n\n41.867\n\n\n−87.641\n\n\n0.001\n\n\n\n\n\nAnd we indeed get three matches !\n\n\n\n\n\n\nNote\n\n\n\nBut those three already had an id, so we could probably have filled their missing name using stations_clean directly, instead of a convoluted proximity-based matching (which is more ressource intensive and less precise).\n\n\n\nstations_clean[matched_clean, on = .(id)\n             ][, .(id, name.stations = name, name.proximity = i.name, lat, lng)]\ndata.table [3 x 5]\n\n\n\nid\n\n\nname.stations\n\n\nname.proximity\n\n\nlat\n\n\nlng\n\n\n\n\n\n13221\n\n\nWood St & Milwaukee Ave\n\n\nWood St & Milwaukee Ave\n\n\n41.908\n\n\n−87.673\n\n\n\n\n20215\n\n\nHegewisch Metra Station\n\n\nHegewisch Metra Station\n\n\n41.648\n\n\n−87.546\n\n\n\n\nWL-008\n\n\nClinton St & Roosevelt Rd\n\n\nClinton St & Roosevelt Rd\n\n\n41.867\n\n\n−87.641\n\n\n\n\n\nAt least, we can see that the proximity-based matched name and the one associated to that station in stations_clean are the same, so the proximity-matching method works reasonably well."
  },
  {
    "objectID": "content/posts/spatial/index.html#matching-on-the-original-data",
    "href": "content/posts/spatial/index.html#matching-on-the-original-data",
    "title": "Fast spatial data matching in R",
    "section": "\n5.2 Matching on the original data",
    "text": "5.2 Matching on the original data\nWhat if we did the same procedure on the non-cleaned data (the one with coordinates less precise than our criteria for matching) ?\n\n5.2.1 Unfiltered stations data\nFirst, we need to recompute the stations data from rides_l (i.e. rides data before cleaning):\n\n\ndata.table\nSQL (DuckDB)\n\n\n\n\nstations <- ((rides_l\n  |> na.omit(cols = c(\"id\", \"name\"))\n  |> dcast(id + name ~ ., fun.aggregate = list(min, max, mean), value.var = c(\"lat\", \"lng\"))\n  |> pipebind::bind(x, setcolorder(x, c(\"id\", \"name\", str_subset(names(x), \"lat_|_lng\"))))\n  |> unique(by = \"id\")\n  )\n)\n\nsetkey(stations, id, name)\n\n\n\n\nCREATE TABLE stations AS \nSELECT DISTINCT on(id)\n  id, name\n  , MIN(lat) AS lat_min\n  , MAX(lat) AS lat_max\n  , AVG(lat) AS lat_mean\n  , MIN(lng) AS lng_min\n  , MAX(lng) AS lng_max\n  , AVG(lng) AS lng_mean\nFROM rides_l\nWHERE (NOT((id IS NULL))) AND (NOT((name IS NULL)))\nGROUP BY id, name;\n\n\n\n\n\n\ndata.frame [1,078 x 8]\n\n\n\nid\n\n\nname\n\n\nlat_min\n\n\nlat_max\n\n\nlat_mean\n\n\nlng_min\n\n\nlng_max\n\n\nlng_mean\n\n\n\n\n\n021320\n\n\nMTV Hubbard St\n\n\n41.89\n\n\n41.89\n\n\n41.89\n\n\n−87.68\n\n\n−87.68\n\n\n−87.68\n\n\n\n\n13001\n\n\nMichigan Ave & Washington St\n\n\n41.813\n\n\n41.958\n\n\n41.884\n\n\n−87.657\n\n\n−87.59\n\n\n−87.625\n\n\n\n\n13006\n\n\nLaSalle St & Washington St\n\n\n41.872\n\n\n41.952\n\n\n41.883\n\n\n−87.833\n\n\n−87.619\n\n\n−87.633\n\n\n\n\n13008\n\n\nMillennium Park\n\n\n41.809\n\n\n41.96\n\n\n41.881\n\n\n−87.785\n\n\n−87.587\n\n\n−87.624\n\n\n\n\n13011\n\n\nCanal St & Adams St\n\n\n41.871\n\n\n41.902\n\n\n41.879\n\n\n−87.657\n\n\n−87.626\n\n\n−87.64\n\n\n\n\n13016\n\n\nSt. Clair St & Erie St\n\n\n41.841\n\n\n41.931\n\n\n41.894\n\n\n−87.744\n\n\n−87.616\n\n\n−87.623\n\n\n\n\n13017\n\n\nFranklin St & Chicago Ave\n\n\n41.873\n\n\n41.917\n\n\n41.897\n\n\n−87.663\n\n\n−87.625\n\n\n−87.636\n\n\n\n\n13021\n\n\nClinton St & Lake St\n\n\n41.876\n\n\n41.909\n\n\n41.886\n\n\n−87.661\n\n\n−87.617\n\n\n−87.642\n\n\n\n\n13022\n\n\nStreeter Dr & Grand Ave\n\n\n41.772\n\n\n41.969\n\n\n41.892\n\n\n−87.785\n\n\n−87.586\n\n\n−87.612\n\n\n\n\n13028\n\n\n900 W Harrison St\n\n\n41.836\n\n\n41.881\n\n\n41.875\n\n\n−87.679\n\n\n−87.607\n\n\n−87.65\n\n\n\n\n\n[ omitted 1,063 entries ]\n\n\n\n\nCleaning the results:\nNotice we get a lot more entries in our stations: 1078 entries vs 693 entries in the filtered version.\nWhich entries are in stations but not in stations_clean ?\n\n(stations_diff <- stations[!stations_clean, on = .(id, name)])\ndata.table [417 x 8]\n\n\n\nid\n\n\nname\n\n\nlat_min\n\n\nlat_max\n\n\nlat_mean\n\n\nlng_min\n\n\nlng_max\n\n\nlng_mean\n\n\n\n\n\n021320\n\n\nMTV Hubbard St\n\n\n41.89\n\n\n41.89\n\n\n41.89\n\n\n−87.68\n\n\n−87.68\n\n\n−87.68\n\n\n\n\n20.0\n\n\nDamen Ave & Wabansia Ave\n\n\n41.91\n\n\n41.91\n\n\n41.91\n\n\n−87.68\n\n\n−87.68\n\n\n−87.68\n\n\n\n\n20126\n\n\nS Aberdeen St & W 106th St\n\n\n41.7\n\n\n41.7\n\n\n41.7\n\n\n−87.65\n\n\n−87.65\n\n\n−87.65\n\n\n\n\n20128\n\n\nS Wentworth Ave & W 111th St\n\n\n41.69\n\n\n41.69\n\n\n41.69\n\n\n−87.63\n\n\n−87.63\n\n\n−87.63\n\n\n\n\n20133\n\n\nWoodlawn & 103rd - Olive Harvey Vaccination Site\n\n\n41.71\n\n\n41.71\n\n\n41.71\n\n\n−87.59\n\n\n−87.59\n\n\n−87.59\n\n\n\n\n20134\n\n\nMaryland Ave & 104th St\n\n\n41.71\n\n\n41.71\n\n\n41.71\n\n\n−87.6\n\n\n−87.6\n\n\n−87.6\n\n\n\n\n20201\n\n\nKedzie Ave & 104th St\n\n\n41.7\n\n\n41.7\n\n\n41.7\n\n\n−87.7\n\n\n−87.7\n\n\n−87.7\n\n\n\n\n20202\n\n\nW 103rd St & S Avers Ave\n\n\n41.71\n\n\n41.71\n\n\n41.71\n\n\n−87.72\n\n\n−87.72\n\n\n−87.72\n\n\n\n\n20209\n\n\nS Michigan Ave & E 118th St\n\n\n41.68\n\n\n41.68\n\n\n41.68\n\n\n−87.62\n\n\n−87.62\n\n\n−87.62\n\n\n\n\n20220\n\n\nAvenue L & 114th St\n\n\n41.69\n\n\n41.69\n\n\n41.69\n\n\n−87.54\n\n\n−87.54\n\n\n−87.54\n\n\n\n\n20240\n\n\nIndiana Ave & 133rd St\n\n\n41.65\n\n\n41.65\n\n\n41.65\n\n\n−87.62\n\n\n−87.62\n\n\n−87.62\n\n\n\n\n20241\n\n\nSteelworkers Park\n\n\n41.74\n\n\n41.74\n\n\n41.74\n\n\n−87.53\n\n\n−87.53\n\n\n−87.53\n\n\n\n\n20246.0\n\n\nN Green St & W Lake St\n\n\n41.89\n\n\n41.89\n\n\n41.89\n\n\n−87.65\n\n\n−87.65\n\n\n−87.65\n\n\n\n\n20247.0\n\n\nW Washington Blvd & N Peoria St\n\n\n41.88\n\n\n41.88\n\n\n41.88\n\n\n−87.65\n\n\n−87.65\n\n\n−87.65\n\n\n\n\n202480.0\n\n\nHampden Ct & Diversey Ave\n\n\n41.93\n\n\n41.93\n\n\n41.93\n\n\n−87.64\n\n\n−87.64\n\n\n−87.64\n\n\n\n\n\n[ omitted 402 entries ]\n\n\n\n\nAnd which of those 417 entries have the necessary coordinate precision to be used later on to match against the unknown stations ?\n\nstations_diff[stations_diff[, Reduce(`&`, lapply(.SD, decp)), .SDcols = patterns(\"^lat|^lng\")]]\ndata.table [0 x 8]\n\n\n\nid\n\n\nname\n\n\nlat_min\n\n\nlat_max\n\n\nlat_mean\n\n\nlng_min\n\n\nlng_max\n\n\nlng_mean\n\n\n\n\n\nAs expected, none. But we’re still going to do the matching, for posterity !\n\n5.2.2 Position-matching on stations\n\nTo save time, let’s only apply the procedure to the entries that actually need to be matched (i.e. the ones having coordinates but missing either name or id):\n\n\nfuzzyjoin\nSQL (DuckDB)\n\n\n\nThere are 1,696,469 entries from rides_l that could be position-matched to a known station.\n\nmatched <- (fuzzyjoin::geo_inner_join(\n    as.data.frame(rides_l_unk),\n    as.data.frame(stations),\n    by = c(\"lng\" = \"lng_mean\", \"lat\" = \"lat_mean\"),\n    method = \"haversine\",\n    unit = \"km\",\n    max_dist = 0.011, # 11 meters\n    distance_col = \"dist\"\n  ) \n  |> mutate(name = coalesce(name.x, name.y), id = coalesce(id.x, id.y)) \n  |> select(names(rides_l), dist)\n  |> arrange(ride_id)\n  |> drop_na(ride_id, id, name)\n  |> setDT()\n)\n\nsetkey(matched, ride_id, id)\n\n\n\nTime difference of 2.634 secs\n\n\n\n\nThere are 1,696,469 entries from rides_l that could be position-matched to a known station.\n\nSELECT\n  ride_id, rideable_type, started_at, ended_at, member_casual, way  \n  , COALESCE(r.name, s.name) AS name\n  , COALESCE(r.id, s.id) AS id\n  , r.lat, r.lng\n  , haversine(s.lat_mean, s.lng_mean, r.lat, r.lng) AS dist\nFROM rides_l_unk r, stations s\nWHERE dist <= 0.011\n\n\n\nTime difference of 9.91 secs\n\n\n\n\n\n\n\ndata.table [939,829 x 11]\n\n\n\nride_id\n\n\nrideable_type\n\n\nstarted_at\n\n\nended_at\n\n\nmember_casual\n\n\nway\n\n\nname\n\n\nid\n\n\nlat\n\n\nlng\n\n\ndist\n\n\n\n\n\n00000B4F1F71F9C2\n\n\nelectric_bike\n\n\n2021-09-08 16:31:38\n\n\n2021-09-08 16:37:54\n\n\nmember\n\n\nend\n\n\nFrancisco Ave & Bloomingdale Ave\n\n\n429\n\n\n41.91\n\n\n−87.7\n\n\n0\n\n\n\n\n000025C113FEB7B6\n\n\nelectric_bike\n\n\n2021-10-25 11:15:21\n\n\n2021-10-25 11:20:21\n\n\nmember\n\n\nstart\n\n\nPrairie Ave & 47th St - midblock\n\n\n814\n\n\n41.81\n\n\n−87.62\n\n\n0\n\n\n\n\n000025C113FEB7B6\n\n\nelectric_bike\n\n\n2021-10-25 11:15:21\n\n\n2021-10-25 11:20:21\n\n\nmember\n\n\nend\n\n\nPrairie Ave & 47th St - midblock\n\n\n814\n\n\n41.81\n\n\n−87.62\n\n\n0\n\n\n\n\n000025C113FEB7B6\n\n\nelectric_bike\n\n\n2021-10-25 11:15:21\n\n\n2021-10-25 11:20:21\n\n\nmember\n\n\nstart\n\n\nMartin Luther King Dr & 44th St\n\n\n914\n\n\n41.81\n\n\n−87.62\n\n\n0\n\n\n\n\n000025C113FEB7B6\n\n\nelectric_bike\n\n\n2021-10-25 11:15:21\n\n\n2021-10-25 11:20:21\n\n\nmember\n\n\nend\n\n\nMartin Luther King Dr & 44th St\n\n\n914\n\n\n41.81\n\n\n−87.62\n\n\n0\n\n\n\n\n000043B681BFB305\n\n\nelectric_bike\n\n\n2021-10-14 16:24:41\n\n\n2021-10-14 16:29:02\n\n\ncasual\n\n\nend\n\n\nCalifornia Ave & Cortez St\n\n\n512\n\n\n41.9\n\n\n−87.7\n\n\n0\n\n\n\n\n00009A0299026096\n\n\nelectric_bike\n\n\n2021-07-04 17:10:35\n\n\n2021-07-04 17:21:29\n\n\ncasual\n\n\nstart\n\n\nLake Park Ave & 44th St\n\n\n787\n\n\n41.81\n\n\n−87.6\n\n\n0\n\n\n\n\n00009F76371B5B23\n\n\nelectric_bike\n\n\n2021-12-12 14:10:54\n\n\n2021-12-12 14:42:44\n\n\nmember\n\n\nend\n\n\nDamen Ave & Wabansia Ave\n\n\n20.0\n\n\n41.91\n\n\n−87.68\n\n\n0\n\n\n\n\n00009FC70913FC9F\n\n\nelectric_bike\n\n\n2021-11-09 15:02:41\n\n\n2021-11-09 15:07:55\n\n\ncasual\n\n\nend\n\n\nLincoln Ave & Balmoral Ave\n\n\n442\n\n\n41.98\n\n\n−87.69\n\n\n0\n\n\n\n\n0000D2CE5AF46802\n\n\nelectric_bike\n\n\n2021-10-21 17:41:43\n\n\n2021-10-21 17:58:18\n\n\nmember\n\n\nend\n\n\nElston Ave & George St\n\n\n472\n\n\n41.93\n\n\n−87.69\n\n\n0\n\n\n\n\n0000D8A70B8D59B7\n\n\nelectric_bike\n\n\n2021-06-23 18:28:49\n\n\n2021-06-23 19:08:40\n\n\ncasual\n\n\nstart\n\n\nParnell Ave & 103rd St\n\n\n605\n\n\n41.71\n\n\n−87.64\n\n\n0\n\n\n\n\n0000D8A70B8D59B7\n\n\nelectric_bike\n\n\n2021-06-23 18:28:49\n\n\n2021-06-23 19:08:40\n\n\ncasual\n\n\nend\n\n\nParnell Ave & 103rd St\n\n\n605\n\n\n41.71\n\n\n−87.64\n\n\n0\n\n\n\n\n0000D8A70B8D59B7\n\n\nelectric_bike\n\n\n2021-06-23 18:28:49\n\n\n2021-06-23 19:08:40\n\n\ncasual\n\n\nstart\n\n\nHalsted St & 102nd St\n\n\n623\n\n\n41.71\n\n\n−87.64\n\n\n0\n\n\n\n\n0000D8A70B8D59B7\n\n\nelectric_bike\n\n\n2021-06-23 18:28:49\n\n\n2021-06-23 19:08:40\n\n\ncasual\n\n\nend\n\n\nHalsted St & 102nd St\n\n\n623\n\n\n41.71\n\n\n−87.64\n\n\n0\n\n\n\n\n0000D8A70B8D59B7\n\n\nelectric_bike\n\n\n2021-06-23 18:28:49\n\n\n2021-06-23 19:08:40\n\n\ncasual\n\n\nstart\n\n\nGreen St & 103rd St\n\n\n878\n\n\n41.71\n\n\n−87.64\n\n\n0\n\n\n\n\n\n[ omitted 939,814 entries ]\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNotice how fast the procedure is, with close to 1 million matches (even if the results are mostly garbage).\n\n\nWhat’s inside those matches ?\n\nmatched[, .(`Number of matches for an entry` = .N), by = .(ride_id, way)\n      ][, .(`Number of times it happens` = .N), by = `Number of matches for an entry`]\ndata.table [5 x 2]\n\n\n\nNumber of matches for an entry\n\n\nNumber of times it happens\n\n\n\n\n\n1\n\n\n437 864\n\n\n\n\n2\n\n\n130 830\n\n\n\n\n3\n\n\n51 620\n\n\n\n\n4\n\n\n19 615\n\n\n\n\n5\n\n\n1 397\n\n\n\n\n\nWe can see that more than half of the matches are coordinates that matched 2 or more stations, which we should definitely not keep.\nBut, among the ones with only one match, how many have coordinates precise enough to make that match in the first place (i.e. have 4 or more decimals or precision) ?\n\nmatched[, if(.N == 1) .SD, by = .(ride_id, way)][decp(lat) & decp(lng)]\ndata.table [3 x 11]\n\n\n\nride_id\n\n\nway\n\n\nrideable_type\n\n\nstarted_at\n\n\nended_at\n\n\nmember_casual\n\n\nname\n\n\nid\n\n\nlat\n\n\nlng\n\n\ndist\n\n\n\n\n\n176105D1F8A1216B\n\n\nstart\n\n\nelectric_bike\n\n\n2021-07-18 03:44:22\n\n\n2021-07-18 04:12:23\n\n\ncasual\n\n\nWood St & Milwaukee Ave\n\n\n13221\n\n\n41.908\n\n\n−87.673\n\n\n0.002\n\n\n\n\nDE82A15026BA3056\n\n\nstart\n\n\nelectric_bike\n\n\n2021-09-21 18:18:59\n\n\n2021-09-21 18:21:48\n\n\ncasual\n\n\nHegewisch Metra Station\n\n\n20215\n\n\n41.648\n\n\n−87.546\n\n\n0.009\n\n\n\n\nEE197EDA4CF8CFE5\n\n\nstart\n\n\nelectric_bike\n\n\n2021-09-22 07:14:42\n\n\n2021-09-22 07:22:38\n\n\ncasual\n\n\nClinton St & Roosevelt Rd\n\n\nWL-008\n\n\n41.867\n\n\n−87.641\n\n\n0.001\n\n\n\n\n\nAs it turns out ? Only 3. And those are the same three matches we got from the filtered data.\nIn the end, those three are the only three position-based matches we should reasonably keep !"
  },
  {
    "objectID": "content/posts/spatial/index.html#merging-the-two-datasets",
    "href": "content/posts/spatial/index.html#merging-the-two-datasets",
    "title": "Fast spatial data matching in R",
    "section": "\n6.1 Merging the two datasets",
    "text": "6.1 Merging the two datasets\n\n\ndata.table\ndtplyr\ndplyr\nSQL (DuckDB)\n\n\n\n\nmatched_clean[rides_l_clean, on = setdiff(names(rides_l_clean), c(\"id\", \"name\"))\n            ][, `:=`(name = fcoalesce(name, i.name), id = fcoalesce(id, i.id))\n            ][, nms, env = list(nms = as.list(names(rides_l_clean)))] -> rides_l_merged\n\n# setkey(rides_l_merged, ride_id, id)\n\n\n\nTime difference of 7.429 secs\n\n\n\n\n\nrides_l_merged.dtp <- (dplyr::right_join(\n    matched_clean,\n    rides_l_clean,\n    by = setdiff(names(rides_l_clean), c(\"id\", \"name\"))\n  ) \n  |> mutate(name = coalesce(name.x, name.y), id = coalesce(id.x, id.y))\n  |> select(-matches(\"\\\\.x|\\\\.y\"), -dist)\n  |> collect()\n)\n\n# setkey(rides_l_merged.dtp, ride_id, id)\n\n\n\nTime difference of 8.923 secs\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\ndplyr has the neat rows_* series of functions that can easily replace or patch (i.e. only replace missing values) the content of one dataset by another, when the rows match, which is quite fast !\n\n\n\nrides_l_merged.dp <- (dplyr::rows_patch(\n    rides_l_clean,\n    matched_clean[, -\"dist\"],\n    by = setdiff(names(rides_l_clean), c(\"name\", \"id\")),\n    unmatched = \"ignore\"\n  )\n)\n\n\n\nTime difference of 3.288 secs\n\n\n\n\n\nCREATE TABLE rides_l_merged AS\nSELECT \n  ride_id, rideable_type, started_at, ended_at, member_casual, way,\n  COALESCE(id_x, id_y) AS id,\n  COALESCE(name_x, name_y) AS name,\n  lat, lng\nFROM (\n  SELECT\n    r.ride_id AS ride_id,\n    r.rideable_type AS rideable_type,\n    r.started_at AS started_at,\n    r.ended_at AS ended_at,\n    r.member_casual AS member_casual,\n    r.way AS way,\n    m.name AS name_x,\n    m.id AS id_x,\n    r.lat AS lat,\n    r.lng AS lng,\n    r.name AS name_y,\n    r.id AS id_y\n  FROM matched_clean AS m\n  RIGHT JOIN rides_l_clean AS r\n  ON m.ride_id = r.ride_id \n     AND m.rideable_type = r.rideable_type \n     AND m.started_at = r.started_at\n     AND m.ended_at = r.ended_at\n     AND m.member_casual = r.member_casual\n     AND m.way = r.way\n);\n\n\n\n\n\n\nTime difference of 5.144 secs\n\n\n\n\n\n\n\ndata.table [9,937,077 x 10]\n\n\n\nride_id\n\n\nrideable_type\n\n\nstarted_at\n\n\nended_at\n\n\nmember_casual\n\n\nway\n\n\nname\n\n\nid\n\n\nlat\n\n\nlng\n\n\n\n\n\n00000123F60251E6\n\n\nclassic_bike\n\n\n2022-02-07 15:47:40\n\n\n2022-02-07 15:49:28\n\n\nmember\n\n\nend\n\n\nKingsbury St & Kinzie St\n\n\nKA1503000043\n\n\n41.889\n\n\n−87.639\n\n\n\n\n00000123F60251E6\n\n\nclassic_bike\n\n\n2022-02-07 15:47:40\n\n\n2022-02-07 15:49:28\n\n\nmember\n\n\nstart\n\n\nWells St & Hubbard St\n\n\nTA1307000151\n\n\n41.89\n\n\n−87.634\n\n\n\n\n000002EBE159AE82\n\n\nelectric_bike\n\n\n2021-06-22 17:25:15\n\n\n2021-06-22 17:31:34\n\n\nmember\n\n\nend\n\n\nMilwaukee Ave & Grand Ave\n\n\n13033\n\n\n41.891\n\n\n−87.648\n\n\n\n\n000002EBE159AE82\n\n\nelectric_bike\n\n\n2021-06-22 17:25:15\n\n\n2021-06-22 17:31:34\n\n\nmember\n\n\nstart\n\n\nClinton St & Jackson Blvd\n\n\n638\n\n\n41.878\n\n\n−87.641\n\n\n\n\n0000080D43BAA9E4\n\n\nclassic_bike\n\n\n2021-08-29 15:38:05\n\n\n2021-08-29 16:24:03\n\n\ncasual\n\n\nstart\n\n\nDearborn St & Van Buren St\n\n\n624\n\n\n41.876\n\n\n−87.629\n\n\n\n\n0000080D43BAA9E4\n\n\nclassic_bike\n\n\n2021-08-29 15:38:05\n\n\n2021-08-29 16:24:03\n\n\ncasual\n\n\nend\n\n\nFederal St & Polk St\n\n\nSL-008\n\n\n41.872\n\n\n−87.63\n\n\n\n\n00000CAE95438C9D\n\n\nclassic_bike\n\n\n2021-07-20 15:40:46\n\n\n2021-07-20 17:38:17\n\n\ncasual\n\n\nstart\n\n\nStreeter Dr & Grand Ave\n\n\n13022\n\n\n41.892\n\n\n−87.612\n\n\n\n\n00000CAE95438C9D\n\n\nclassic_bike\n\n\n2021-07-20 15:40:46\n\n\n2021-07-20 17:38:17\n\n\ncasual\n\n\nend\n\n\nFairbanks Ct & Grand Ave\n\n\nTA1305000003\n\n\n41.892\n\n\n−87.621\n\n\n\n\n00000E22FBA89D81\n\n\nelectric_bike\n\n\n2022-05-19 14:42:55\n\n\n2022-05-19 14:54:03\n\n\nmember\n\n\nend\n\n\nClark St & Armitage Ave\n\n\n13146\n\n\n41.918\n\n\n−87.636\n\n\n\n\n00000EBBC119168C\n\n\nclassic_bike\n\n\n2021-10-31 11:30:37\n\n\n2021-10-31 11:39:27\n\n\nmember\n\n\nstart\n\n\nDorchester Ave & 49th St\n\n\nKA1503000069\n\n\n41.806\n\n\n−87.592\n\n\n\n\n00000EBBC119168C\n\n\nclassic_bike\n\n\n2021-10-31 11:30:37\n\n\n2021-10-31 11:39:27\n\n\nmember\n\n\nend\n\n\nKimbark Ave & 53rd St\n\n\nTA1309000037\n\n\n41.8\n\n\n−87.595\n\n\n\n\n000019B7F053D461\n\n\nclassic_bike\n\n\n2021-08-13 19:57:28\n\n\n2021-08-13 20:02:56\n\n\nmember\n\n\nstart\n\n\nLarrabee St & Webster Ave\n\n\n13193\n\n\n41.922\n\n\n−87.644\n\n\n\n\n000019B7F053D461\n\n\nclassic_bike\n\n\n2021-08-13 19:57:28\n\n\n2021-08-13 20:02:56\n\n\nmember\n\n\nend\n\n\nSheffield Ave & Webster Ave\n\n\nTA1309000033\n\n\n41.922\n\n\n−87.654\n\n\n\n\n00001B4F79D102B5\n\n\nclassic_bike\n\n\n2021-07-28 07:58:27\n\n\n2021-07-28 08:05:00\n\n\ncasual\n\n\nend\n\n\nBroadway & Waveland Ave\n\n\n13325\n\n\n41.949\n\n\n−87.649\n\n\n\n\n00001B4F79D102B5\n\n\nclassic_bike\n\n\n2021-07-28 07:58:27\n\n\n2021-07-28 08:05:00\n\n\ncasual\n\n\nstart\n\n\nDuSable Lake Shore Dr & Belmont Ave\n\n\nTA1309000049\n\n\n41.941\n\n\n−87.639\n\n\n\n\n\n[ omitted 9,937,062 entries ]"
  },
  {
    "objectID": "content/posts/spatial/index.html#validating-the-merge",
    "href": "content/posts/spatial/index.html#validating-the-merge",
    "title": "Fast spatial data matching in R",
    "section": "\n6.2 Validating the merge:",
    "text": "6.2 Validating the merge:\n\nrides_l_merged[(is.na(id) | is.na(name)) & (!is.na(lat) & !is.na(lng))]\ndata.table [0 x 10]\n\n\n\nride_id\n\n\nrideable_type\n\n\nstarted_at\n\n\nended_at\n\n\nmember_casual\n\n\nway\n\n\nname\n\n\nid\n\n\nlat\n\n\nlng\n\n\n\n\n\nWe can see that the resulting dataset no longer has any entries that have coordinates but miss a name or an id, whereas there were three before. We have successfully updated them !"
  },
  {
    "objectID": "content/posts/spatial/index.html#pivoting-back-to-the-original-wide-format",
    "href": "content/posts/spatial/index.html#pivoting-back-to-the-original-wide-format",
    "title": "Fast spatial data matching in R",
    "section": "\n6.3 Pivoting back to the original (wide) format",
    "text": "6.3 Pivoting back to the original (wide) format\nTo finish, let’s pivot the resulting data back into the wider format it was originally in:\n\n\ndata.table\ndtplyr\nSQL (DuckDB)\n\n\n\n\nrides_merged <- dcast(\n  rides_l_merged, \n  ... ~ way, \n  value.var = c(\"name\", \"id\", \"lat\", \"lng\"), sep = \"_station_\"\n)\n\n\n\nTime difference of 9.308 secs\n\n\n\n\n\nrides_merged.dtp <- (rides_l_merged \n  |> pivot_wider(\n    names_from = \"way\", \n    values_from = c(\"name\", \"id\", \"lat\", \"lng\"), \n    names_glue = \"{way}_station_{.value}\"\n  )\n  |> collect()\n)\n\n\n\nTime difference of 9.819 secs\n\n\n\n\n\nCREATE TABLE rides_merged AS\nSELECT\n  ride_id, rideable_type, started_at, ended_at, member_casual,\n  MAX(CASE WHEN (way = 'start') THEN name END) AS start_station_name,\n  MAX(CASE WHEN (way = 'end') THEN name END) AS end_station_name,\n  MAX(CASE WHEN (way = 'start') THEN id END) AS start_station_id,\n  MAX(CASE WHEN (way = 'end') THEN id END) AS end_station_id,\n  MAX(CASE WHEN (way = 'start') THEN lat END) AS start_lat,\n  MAX(CASE WHEN (way = 'end') THEN lat END) AS end_lat,\n  MAX(CASE WHEN (way = 'start') THEN lng END) AS start_lng,\n  MAX(CASE WHEN (way = 'end') THEN lng END) AS end_lng\nFROM rides_l_merged\nGROUP BY ride_id, rideable_type, started_at, ended_at, member_casual\n\n\n\n\n\n\nTime difference of 7.33 secs\n\n\n\n\n\n\n\ndata.table [5,316,218 x 13]\n\n\n\nride_id\n\n\nrideable_type\n\n\nstarted_at\n\n\nended_at\n\n\nmember_casual\n\n\nname_station_end\n\n\nname_station_start\n\n\nid_station_end\n\n\nid_station_start\n\n\nlat_station_end\n\n\nlat_station_start\n\n\nlng_station_end\n\n\nlng_station_start\n\n\n\n\n\n00000123F60251E6\n\n\nclassic_bike\n\n\n2022-02-07 15:47:40\n\n\n2022-02-07 15:49:28\n\n\nmember\n\n\nKingsbury St & Kinzie St\n\n\nWells St & Hubbard St\n\n\nKA1503000043\n\n\nTA1307000151\n\n\n41.889\n\n\n41.89\n\n\n−87.639\n\n\n−87.634\n\n\n\n\n000002EBE159AE82\n\n\nelectric_bike\n\n\n2021-06-22 17:25:15\n\n\n2021-06-22 17:31:34\n\n\nmember\n\n\nMilwaukee Ave & Grand Ave\n\n\nClinton St & Jackson Blvd\n\n\n13033\n\n\n638\n\n\n41.891\n\n\n41.878\n\n\n−87.648\n\n\n−87.641\n\n\n\n\n0000080D43BAA9E4\n\n\nclassic_bike\n\n\n2021-08-29 15:38:05\n\n\n2021-08-29 16:24:03\n\n\ncasual\n\n\nFederal St & Polk St\n\n\nDearborn St & Van Buren St\n\n\nSL-008\n\n\n624\n\n\n41.872\n\n\n41.876\n\n\n−87.63\n\n\n−87.629\n\n\n\n\n00000CAE95438C9D\n\n\nclassic_bike\n\n\n2021-07-20 15:40:46\n\n\n2021-07-20 17:38:17\n\n\ncasual\n\n\nFairbanks Ct & Grand Ave\n\n\nStreeter Dr & Grand Ave\n\n\nTA1305000003\n\n\n13022\n\n\n41.892\n\n\n41.892\n\n\n−87.621\n\n\n−87.612\n\n\n\n\n00000E22FBA89D81\n\n\nelectric_bike\n\n\n2022-05-19 14:42:55\n\n\n2022-05-19 14:54:03\n\n\nmember\n\n\nClark St & Armitage Ave\n\n\nNA\n\n\n13146\n\n\nNA\n\n\n41.918\n\n\nNA\n\n\n−87.636\n\n\nNA\n\n\n\n\n00000EBBC119168C\n\n\nclassic_bike\n\n\n2021-10-31 11:30:37\n\n\n2021-10-31 11:39:27\n\n\nmember\n\n\nKimbark Ave & 53rd St\n\n\nDorchester Ave & 49th St\n\n\nTA1309000037\n\n\nKA1503000069\n\n\n41.8\n\n\n41.806\n\n\n−87.595\n\n\n−87.592\n\n\n\n\n000019B7F053D461\n\n\nclassic_bike\n\n\n2021-08-13 19:57:28\n\n\n2021-08-13 20:02:56\n\n\nmember\n\n\nSheffield Ave & Webster Ave\n\n\nLarrabee St & Webster Ave\n\n\nTA1309000033\n\n\n13193\n\n\n41.922\n\n\n41.922\n\n\n−87.654\n\n\n−87.644\n\n\n\n\n00001B4F79D102B5\n\n\nclassic_bike\n\n\n2021-07-28 07:58:27\n\n\n2021-07-28 08:05:00\n\n\ncasual\n\n\nBroadway & Waveland Ave\n\n\nDuSable Lake Shore Dr & Belmont Ave\n\n\n13325\n\n\nTA1309000049\n\n\n41.949\n\n\n41.941\n\n\n−87.649\n\n\n−87.639\n\n\n\n\n00001BEE76AB24E0\n\n\nelectric_bike\n\n\n2021-11-30 16:55:38\n\n\n2021-11-30 17:08:53\n\n\nmember\n\n\nAshland Ave & Division St\n\n\nDaley Center Plaza\n\n\n13061\n\n\nTA1306000010\n\n\n41.903\n\n\n41.884\n\n\n−87.668\n\n\n−87.629\n\n\n\n\n00001DCF2BC423F4\n\n\ndocked_bike\n\n\n2021-06-13 12:00:49\n\n\n2021-06-13 12:29:51\n\n\ncasual\n\n\nFort Dearborn Dr & 31st St\n\n\nMillennium Park\n\n\nTA1307000048\n\n\n13008\n\n\n41.839\n\n\n41.881\n\n\n−87.608\n\n\n−87.624\n\n\n\n\n000020C92AA9D6F7\n\n\nclassic_bike\n\n\n2021-09-12 09:53:00\n\n\n2021-09-12 10:12:52\n\n\ncasual\n\n\nDusable Harbor\n\n\nClark St & North Ave\n\n\nKA1503000064\n\n\n13128\n\n\n41.887\n\n\n41.912\n\n\n−87.613\n\n\n−87.632\n\n\n\n\n0000228A4B430869\n\n\nelectric_bike\n\n\n2021-10-18 10:42:20\n\n\n2021-10-18 10:47:58\n\n\nmember\n\n\nCalumet Ave & 18th St\n\n\nMLK Jr Dr & 29th St\n\n\n13102\n\n\nTA1307000139\n\n\n41.857\n\n\n41.842\n\n\n−87.619\n\n\n−87.617\n\n\n\n\n000022C3D3CE7DD5\n\n\nclassic_bike\n\n\n2022-04-30 09:57:39\n\n\n2022-04-30 10:03:12\n\n\ncasual\n\n\nSheffield Ave & Willow St\n\n\nHalsted St & Clybourn Ave\n\n\nTA1306000032\n\n\n331\n\n\n41.914\n\n\n41.91\n\n\n−87.653\n\n\n−87.648\n\n\n\n\n0000278F02EFFEF9\n\n\nclassic_bike\n\n\n2021-09-18 16:09:39\n\n\n2021-09-18 16:32:06\n\n\nmember\n\n\nMichigan Ave & Washington St\n\n\nBurnham Harbor\n\n\n13001\n\n\n15545\n\n\n41.884\n\n\n41.856\n\n\n−87.625\n\n\n−87.613\n\n\n\n\n000027C557F9372D\n\n\ndocked_bike\n\n\n2022-05-13 11:01:17\n\n\n2022-05-13 11:09:05\n\n\ncasual\n\n\nLincoln Ave & Roscoe St*\n\n\nAshland Ave & Belle Plaine Ave\n\n\nchargingstx5\n\n\n13249\n\n\n41.943\n\n\n41.956\n\n\n−87.671\n\n\n−87.669\n\n\n\n\n\n[ omitted 5,316,203 entries ]\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe get less than the original (wide format) ~6 millions entries due to having removed (filtered) the entries with bad coordinates."
  },
  {
    "objectID": "content/projects/ACCESSPACE/index.html#our-interface-the-tactibelt",
    "href": "content/projects/ACCESSPACE/index.html#our-interface-the-tactibelt",
    "title": "ACCESSPACE",
    "section": "1.1 Our interface: the TactiBelt",
    "text": "1.1 Our interface: the TactiBelt\nTo provide the proposed egocentric encoding scheme to the user, we designed a vibro-tactile belt, the TactiBelt: it comprises of 46 ERM motors spread into three layers, controlled by an Arduino Mega, through a specialized software written in Java:\n\n\n\nFigure 2: First prototype of the TactiBelt"
  },
  {
    "objectID": "content/projects/ACCESSPACE/index.html#our-tools",
    "href": "content/projects/ACCESSPACE/index.html#our-tools",
    "title": "ACCESSPACE",
    "section": "1.2 Our tools",
    "text": "1.2 Our tools\nTo capture and extract the information we need from the VIP’s environment, we devised a series of software tools relying mostly on Computer Vision:\n1) Obstacle detection and indoor localisation using the ORB-SLAM algorithm:\n\n\n\n\n\n2) Depth estimation from a monocular RGB camera, using the MonoDepth algorithm:\n\n\n\n\n\n3) Generating a mobility graph of the environment during movement using Reinforcement Learning:\nApplied to an artificial agent exploring a virtual maze, looking for food:\n\n\n\n\n\nApplied to a real agent (human pushing a cart with a camera and the computer running the algorithm around a meeting table):\n\n\n\n\n\n4) A virtual environment to test the TactiBelt and our candidate spatial encoding schemes:"
  },
  {
    "objectID": "content/projects/ACCESSPACE/index.html#project-dissemination",
    "href": "content/projects/ACCESSPACE/index.html#project-dissemination",
    "title": "ACCESSPACE",
    "section": "1.3 Project dissemination",
    "text": "1.3 Project dissemination\nThe ACCESSPACE project was promoted in various mainstream and technical media, such as:\n- On RTL, a French national radio station ()\n- On PhDTalent, a platform and network for PhD Students who wish to transition to industry ()\n- On Guide Néret, a specialized website on Handicap in France ()\n- On Acuité, a specialized website dedicated to Opticians and news around visual impairment ()\n- On Oxytude, a weekly podcast reviewing news related to visual impairment ()\n- On FIRAH, the French Foundation on Applied Research for Handicap ()\nThis project has been warmly welcomed by the VIP community and was awarded the “Applied research on disability” award from the CCAH in 2017 🥇."
  },
  {
    "objectID": "content/projects/AdViS/index.html",
    "href": "content/projects/AdViS/index.html",
    "title": "AdViS",
    "section": "",
    "text": "1 Project summary\n\nAdViS aims to explore various ways to provide visuo-spatial information through auditory feedback, based on the Sensory Substitution framework. Since its inception, the project investigated visuo-auditive substitution possibilities for multiple tasks in which vision plays a crucial role:\n\nNavigating a small maze using a depth-map-to-auditory-cues transcoding\n\nFinger-guided image exploration (on a touch screen)\n\nEye-movement guided image exploration (on a turned off computer screen)\n\nPointing towards and reaching a virtual target in 3D space using a motion capture environment\n\n\n\n\n\n\nAdViS - Depth Map navigation\n\n\n\n\n\nAdViS - Motion Capture\n\n\n\n\nThe AdViS platform is coded in C++ (and Qt for the GUI). It currently uses PureData for complex sound generation, and the VICON system to track participant’s movements in an augmented reality environment.\n\n\n2 My role in this project\n\n1) Propose a new model for image exploration using a touch-to-audio-feedback loop, where a VIP explores an image by moving its finger across it and gets auditive feedback from the explored regions and its surroundings.\n2) Modify the existing AdViS code to include the ability to transcode grey-scale images into soundscapes, and to capture finger movements information on a touchscreen.\n3) Organize experimental evaluations with blindfolded students, tasked with recognizing geometrical shapes on a touchscreen, and analyse the results.\n\n\n\n\n\n4) Participate in implementing an eye-tracking-to-audio-feedback loop in order to evaluate the possibility of exploring images (on a turned off screen) with eye-movements (which are still controllable by most of the non-congenital VIP)."
  },
  {
    "objectID": "content/projects/CamIO/index.html",
    "href": "content/projects/CamIO/index.html",
    "title": "CamIO",
    "section": "",
    "text": "1 Project summary\n\n\n\n\n2 My role in this project\n\n1) Explore new solutions to improve the localisation & tracking capabilities of CamIO:\nTheir existing solution, iLocalize (Fusco & Coughlan, 2018) (Swift / iOS), used a combination of Visuo-Inertial Odometry (VIO) through Apple’s ARKit, particle filtering based on a simplified map of the environment, and drift-correction through visual identification of known landmarks (using a gradient boosting algorithm).\n\n\n\n\n\nI developed a web app to send the live camera stream from a mobile phone (JavaScript / socket.io) to a backend server (Python / Flask). The goal of the application was to facilitate the exploration of new Computer Vision algorithms to process the captured video and IMU data, which would send back location or navigational information.\nI also explored existing 3rd-party services for indoor localization, such as Indoor Atlas (which combines VIO, GPS data, WiFi & geomagnetic fingerprinting, dead-reckoning, and barometric readings for altitude changes), for which I made a small demo.\n\n\n\n\n\n\n(a) Indoor Atlas’ localization\n\n\n\n\n\n(b) Indoor Atlas’ navigation graph\n\n\n\nFigure 1: Indoor Atlas\n\n\n2) Assist in writing a scientific paper presenting the project.\n\n\n\n\nReferences\n\nFusco, G., & Coughlan, J. M. (2018). Indoor localization using computer vision and visual-inertial odometry (pp. 86–93). Springer International Publishing. https://doi.org/10.1007/978-3-319-94274-2_13"
  },
  {
    "objectID": "content/projects/DE-AoP/index.html",
    "href": "content/projects/DE-AoP/index.html",
    "title": "DE-AoP",
    "section": "",
    "text": "1 My role in this project\n\n1) Develop tools to assist the project’s researchers exploration of the collected data. To this end, I developed a modular Shiny dashboard to assist in the data exploration process.\n2) Handle the RT-qPCR data processing and analysis.\n3) Participate in writing the final scientific paper resulting from this project (ongoing)."
  },
  {
    "objectID": "content/projects/LT-AoP/index.html",
    "href": "content/projects/LT-AoP/index.html",
    "title": "LT-AoP",
    "section": "",
    "text": "1 My role in this project\n\n1) Handle the data processing and analysis, for both immunohistochemistry and RT-qPCR data.\n2) Make a website documenting and showcasing the project’s data, analyses, and results. The website uses Quarto and relies on templates to automatically generates documentation for each of the ~70 variables analyzed during the project:\n\n\nClick to see a preview of the documentation"
  },
  {
    "objectID": "content/projects/NAV-VIR/index.html#our-interface-f2t-v2",
    "href": "content/projects/NAV-VIR/index.html#our-interface-f2t-v2",
    "title": "NAV-VIR",
    "section": "1.1 Our interface: F2T (v2)",
    "text": "1.1 Our interface: F2T (v2)\nDuring this project, we improved upon the first iteration of the Force Feedback Tablet (F2T) from the TETMOST project to design the finalized prototype of this interface:"
  },
  {
    "objectID": "content/projects/NAV-VIR/index.html#our-tools",
    "href": "content/projects/NAV-VIR/index.html#our-tools",
    "title": "NAV-VIR",
    "section": "1.2 Our tools",
    "text": "1.2 Our tools\n1) We developed a Java application to create or convert images into simplified tactile representations, which can then be explored using the F2T:\n\n\n\n\n\n2) We investigated and developed tools to automatically generate a navigation graph from a floor plan, which can then be converted into a tactile image and explored with the F2T:"
  },
  {
    "objectID": "content/projects/SAM-Guide/index.html",
    "href": "content/projects/SAM-Guide/index.html",
    "title": "SAM-Guide",
    "section": "",
    "text": "1 Project summary\n\n\nInteracting with space is a constant challenge for Visually Impaired People (VIP) since spatial information in Humans is typically provided by vision. Sensory Substitution Devices (SSDs) have been promising Human-Machine Interfaces (HMI) to assist VIP. They re-code missing visual information as stimuli for other sensory channels. Our project redirects somehow from SSD’s initial ambition for a single universal integrated device that would replace the whole sense organ, towards common encoding schemes for multiple applications.\nSAM-Guide will search for the most natural way to give online access to geometric variables that are necessary to achieve a range of tasks without eyes. Defining such encoding schemes requires selecting a crucial set of geometrical variables, and building efficient and comfortable auditory and/or tactile signals to represent them. We propose to concentrate on action-perception loops representing target-reaching affordances, where spatial properties are defined as ego-centered deviations from selected beacons.\nThe same grammar of cues could better help VIP to get autonomy along with a range of vital or leisure activities. Among such activities, the consortium has advances in orienting and navigating, object locating and reaching, laser shooting. Based on current neurocognitive models of human action-perception and spatial cognition, the design of the encoding schemes will lay on common theoretical principles: parsimony (minimum yet sufficient information for a task), congruency (leverage existing sensorimotor control laws), and multimodality (redundant or complementary signals across modalities). To ensure an efficient collaboration all partners will develop and evaluate their transcoding schemes based on common principles, methodology, and tools. An inclusive user-centered “living-lab” approach will ensure constant adequacy of our solutions with VIP’s needs.\nFive labs (three campuses) comprising ergonomists, neuroscientists, engineers, and mathematicians, united by their interest and experience with designing assistive devices for VIP, will duplicate, combine and share their pre-existing SSDs prototypes: a vibrotactile navigation belt, an audio-spatialized virtual guide for jogging, and an object-reaching sonic pointer. Using those prototypes, they will iteratively evaluate and improve their transcoding schemes in a 3-phase approach: First, in controlled experimental settings through augmented-reality serious games in motion capture (virtual prototyping indeed facilitates the creation of ad-hoc environments, and gaming eases the participants’ engagement). Next, spatial interaction subtasks will be progressively combined and tested in wider and more ecological indoor and outdoor environments. Finally, SAM-Guide’s system will be fully transitioned to real-world conditions through a friendly sporting event of laser-run, a novel handi-sport, which will involve each subtask.\nSAM-Guide will develop action-perception and spatial cognition theories relevant to nonvisual interfaces. It will provide guidelines for the efficient representation of spatial interactions to facilitate the emergence of spatial awareness in a task-oriented perspective. Our portable modular transcoding libraries are independent of hardware consideration. The principled experimental platform offered by AR games will be a tool for evaluating VIP spatial cognition, and novel strategies for mobility training.\n\n\n\n\n2 My role in this project\n\n1) I was the driving force behind the genesis of this project. I connected the consortium members together and wrote most of the grant proposal (ANR AAPG 2021, funding of 609k€). This project will last 4 years and allow the recruitment of 2 PhD students, one post-doc, and one Research Engineer.\n2) Participated in the Data Management plan creation (compliance to the GPDR).\n3) Designed and participated in the development of the second prototype of the TactiBelt, which features wireless communication and amovible vibrators:\n\n\n\nFigure 1: Second prototype of the TactiBelt\n\n\n4) Lead the design and development of the project’s experimental platform (choice of tools, lead developer). The platform uses Unity, connects to various motion tracking devices used by the consortium (Polhemus, VICON, pozyx), uses PureData for sound-wave generation, uses Steam Audio for 3D audio modeling, and communicates to the TactiBelt wirelessly using the OSC protocol.\n\n\n\n\n\n\n(a) Testing environment with a PureData audio beacon\n\n\n\n \n\n\n\n\n(b) Auto-generated maze with 3D audio beacons on waypoints\n\n\n\nFigure 2: Screenshots from SAM-Guide’s experimental platform (in development)\n\n\n5) Handling the experimental design of the first wave of experiments (ongoing)."
  },
  {
    "objectID": "content/projects/TETMOST/index.html#exploring-existing-haptic-interfaces",
    "href": "content/projects/TETMOST/index.html#exploring-existing-haptic-interfaces",
    "title": "TETMOST",
    "section": "1.1 Exploring existing haptic interfaces",
    "text": "1.1 Exploring existing haptic interfaces\nWe researched and tried different categories of haptic interfaces in order to asses their strengths and weaknesses for our purposes:\n\n\n\n\n\n\n(a) Taxel mechanical interfaces\n\n\n\n\n\n(b) Electro-friction interfaces\n\n\n\n\n\n(c) Vibrational interfaces\n\n\n\nFigure 1: The three main categories of haptic interfaces\n\n\nOur experience with the existing categories of haptic interfaces allowed us to designed one best adapted to our need: the Force-Feedback Tablet (F2T)"
  },
  {
    "objectID": "content/projects/TETMOST/index.html#our-interface-f2t-v1",
    "href": "content/projects/TETMOST/index.html#our-interface-f2t-v1",
    "title": "TETMOST",
    "section": "1.2 Our interface: F2T (v1)",
    "text": "1.2 Our interface: F2T (v1)\nThe first prototype of the F2T was assembled with legos and a camera to better asses the position of the joystick within the frame of the device."
  },
  {
    "objectID": "content/projects/TETMOST/index.html#our-tools",
    "href": "content/projects/TETMOST/index.html#our-tools",
    "title": "TETMOST",
    "section": "1.3 Our tools",
    "text": "1.3 Our tools\n1) We developed a Java application to create or convert images into simplified tactile representations, which can then be explored using the F2T:\n\n\n\n\n\n2) In order to display an image haptically, we first needed a way to simplify the image’s content without losing its meaning. To do so, we explored various Computer Vision techniques such as image segmentation and edge detection:"
  },
  {
    "objectID": "content/projects/index.html",
    "href": "content/projects/index.html",
    "title": "Past & Current Projects",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\n\nSpatial Awareness for Multimodal Guidance\n\n\n\n\nAssistive Devices\n\n\nAccessibility\n\n\nVisual Impairment\n\n\nAugmented Reality\n\n\nSensory Substitution\n\n\nAuditory Interface\n\n\nHaptic Interface\n\n\nComputer Vision\n\n\n\n\nDesigning an efficient multi-modal interface to help VIP during spatial interactions and sports.\n\n\n\n\n\n\nANR PRC (AAPG 2021)\n\n\n\n\n\n\n  \n\n\n\n\n\nDevelopmental effects of Apnea of Prematurity\n\n\n\n\nBiostatistics\n\n\nTranscriptomics\n\n\nData Science\n\n\nCerebellum\n\n\nHypoxia\n\n\nRT-qPCR\n\n\n\n\nThis project studies the underlying molecular and cellular mechanisms of apnea of prematurity at play during cerebellar development, using intermittent hypoxia in a mouse model.\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\n\nVirtual Map exploration for Visually Impaired People\n\n\n\n\nAssistive Devices\n\n\nAccessibility\n\n\nVisual Impairment\n\n\nVirtual Reality\n\n\nSensory Substitution\n\n\nHaptic Interface\n\n\nAuditory Interface\n\n\n\n\nDeveloping a multi-modal interface for Visually Impaired People to virtually explore a map in order to prepare for a journey.\n\n\n\n\n\n\nPHC Polonium (French-Polish EU grant)\n\n\n\n\n\n\n  \n\n\n\n\n\nCamera Input-Output\n\n\n\n\nAssistive Devices\n\n\nAccessibility\n\n\nVisual Impairment\n\n\nAugmented Reality\n\n\nSensory Substitution\n\n\nAuditory Interface\n\n\nComputer Vision\n\n\n\n\nSmart pen providing real-time audio-feedback on objects using a smartphone built-in camera.\n\n\n\n\n\n\nNIH/NEI & NIDILRR RERC\n\n\n\n\n\n\n  \n\n\n\n\n\nMaking Art more accessible to Visually Impaired People\n\n\n\n\nAssistive Devices\n\n\nAccessibility\n\n\nVisual Impairment\n\n\nVirtual Reality\n\n\nSensory Substitution\n\n\nHaptic Interface\n\n\n\n\nDevelopping a haptic interface and studying ways to intuitively represent images and Art pieces haptically for Visually Impaired People.\n\n\n\n\n\n\nAUTON (CNRS)\n\n\n\n\n\n\n  \n\n\n\n\n\nHelping Visually Impaired People travel autonomously\n\n\n\n\nAssistive Devices\n\n\nAccessibility\n\n\nVisual Impairment\n\n\nAugmented Reality\n\n\nSensory Substitution\n\n\nHaptic Interface\n\n\nComputer Vision\n\n\n\n\nDeveloping a wearable vibro-tactile electronic Orientation & Travel Aid for the autonomous navigation of VIP, based on Spatial Cognition models.\n\n\n\n\n\n\nCCAH & FIRAH\n\n\n\n\n\n\n  \n\n\n\n\n\nLong Term effects of Apnea of Prematurity\n\n\n\n\nBiostatistics\n\n\nTranscriptomics\n\n\nData Science\n\n\nCerebellum\n\n\nHypoxia\n\n\nRT-qPCR\n\n\n\n\nThis project studied the impact of apnea of prematurity on cerebellar development and the long-term functional deficits resulting from it, using intermittent hypoxia in a mouse model.\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\n\nAdaptative Visual Substitution\n\n\n\n\nAssistive Devices\n\n\nAccessibility\n\n\nVisual Impairment\n\n\nAugmented Reality\n\n\nSensory Substitution\n\n\nAuditory Interface\n\n\nComputer Vision\n\n\n\n\nDeveloping a wearable visuo-auditive substitution system to assist Visually Impaired People in navigation and object-reaching tasks.\n\n\n\n\n\n\nAUTON (CNRS) & LabEx PERSYVAL (PIA)\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "content/pubs/ICCHP18-F2T/index.html",
    "href": "content/pubs/ICCHP18-F2T/index.html",
    "title": "Towards Haptic Surface Devices with Force Feedback for Visually Impaired People",
    "section": "",
    "text": "BibTeX citation:@inproceedings{gay2018,\n  author = {Simon Gay and Marc-Aurèle Rivière and Edwige Pissaloux},\n  editor = {Miesenberger Klaus and Kouroupetroglou Georgios},\n  publisher = {Springer International Publishing},\n  title = {Towards {Haptic} {Surface} {Devices} with {Force} {Feedback}\n    for {Visually} {Impaired} {People}},\n  booktitle = {Lecture Notes in Computer Science},\n  volume = {10897},\n  pages = {258-266},\n  date = {2018-07-12},\n  url = {http://link.springer.com/10.1007/978-3-319-94274-2_36},\n  doi = {10.1007/978-3-319-94274-2_36},\n  isbn = {978-3-319-94273-5 978-3-319-94274-2},\n  langid = {en},\n  abstract = {This paper presents a new haptic surface tablet that can\n    provide force feedback to the user. Force feedback means that the\n    device can react to the user’s movements and apply a force against\n    or in-line with these movements, according to the tactile properties\n    of a displayed image. The device consists of a frame attached to a\n    tactile tablet that generates a force feedback to user’s finger when\n    exploring the surface, providing haptic informations about the\n    displayed image. The experimental results suggest the relevance of\n    this tablet as an assistive device for visually impaired people in\n    perceiving and understanding the content of a displayed image.\n    Several potential applications are briefly presented.}\n}\nFor attribution, please cite this work as:\nSimon Gay, Marc-Aurèle Rivière, & Edwige Pissaloux. (2018). Towards\nHaptic Surface Devices with Force Feedback for Visually Impaired People.\nIn Miesenberger Klaus & Kouroupetroglou Georgios (Eds.), Lecture\nNotes in Computer Science (Vol. 10897, pp. 258–266). Springer\nInternational Publishing. https://doi.org/10.1007/978-3-319-94274-2_36"
  },
  {
    "objectID": "content/pubs/ICCHP18-TactiBelt/index.html",
    "href": "content/pubs/ICCHP18-TactiBelt/index.html",
    "title": "TactiBelt: integrating spatial cognition and mobility theories into the design of a novel orientation and mobility assistive device for the blind",
    "section": "",
    "text": "BibTeX citation:@inproceedings{rivière2018,\n  author = {Marc-Aurèle Rivière and Simon Gay and Edwige Pissaloux},\n  editor = {Miesenberger Klaus and Kouroupetroglou Georgios},\n  publisher = {Springer International Publishing},\n  title = {TactiBelt: Integrating Spatial Cognition and Mobility\n    Theories into the Design of a Novel Orientation and Mobility\n    Assistive Device for the Blind},\n  booktitle = {Lecture Notes in Computer Science},\n  volume = {10897},\n  pages = {110-113},\n  date = {2018-07-12},\n  url = {http://link.springer.com/10.1007/978-3-319-94274-2_16},\n  doi = {10.1007/978-3-319-94274-2_16},\n  isbn = {978-3-319-94273-5 978-3-319-94274-2},\n  langid = {en},\n  abstract = {The aim of this paper is to introduce a novel functional\n    design for an indoor and outdoor mobility assistive device for the\n    visually impaired, based on the theoretical frameworks of mobility\n    and spatial cognition. The originality of the proposed approach\n    comes from the integration of two main aspects of navigation,\n    locomotion and wayfinding. The cognitive theories which underpin the\n    design of the proposed sensory substitution device, called\n    TactiBelt, are identified and discussed in the framework of spatial\n    knowledge acquisition. The paper is organized as follows: section 1\n    gives a brief overview of the sensory substitution framework, while\n    sections 2 \\& 3 introduce the importance of navigation and spatial\n    cognition models for the design of mobility aids. Section 4 details\n    the functional design of the TactiBelt.}\n}\nFor attribution, please cite this work as:\nMarc-Aurèle Rivière, Simon Gay, & Edwige Pissaloux. (2018).\nTactiBelt: integrating spatial cognition and mobility theories into the\ndesign of a novel orientation and mobility assistive device for the\nblind. In Miesenberger Klaus & Kouroupetroglou Georgios (Eds.),\nLecture Notes in Computer Science (Vol. 10897, pp. 110–113).\nSpringer International Publishing. https://doi.org/10.1007/978-3-319-94274-2_16"
  },
  {
    "objectID": "content/pubs/ICCHP20/index.html",
    "href": "content/pubs/ICCHP20/index.html",
    "title": "An Audio-Based 3D Spatial Guidance AR System for Blind Users",
    "section": "",
    "text": "BibTeX citation:@inproceedings{coughlan2020,\n  author = {James Coughlan and Brandon Biggs and Marc-Aurèle Rivière and\n    Huiying Shen},\n  editor = {Miesenberger Klaus and Manduchi Roberto and Covarrubias\n    Rodriguez Mario and Peňáz Petr},\n  publisher = {Springer International Publishing},\n  title = {An {Audio-Based} {3D} {Spatial} {Guidance} {AR} {System} for\n    {Blind} {Users}},\n  booktitle = {Lecture Notes in Computer Science},\n  volume = {12376},\n  pages = {475-484},\n  date = {2020-09-12},\n  url = {https://link.springer.com/chapter/10.1007/978-3-030-58796-3_55},\n  doi = {10.1007/978-3-030-58796-3_55},\n  isbn = {978-3-030-58795-6 978-3-030-58796-3},\n  langid = {en},\n  abstract = {Augmented reality (AR) has great potential for blind users\n    because it enables a range of applications that provide audio\n    information about specific locations or directions in the user’s\n    environment. For instance, the {[}CamIO{]}(/content/projects/CamIO)\n    (“Camera Input-Output”) AR app makes physical objects (such as\n    documents, maps, devices and 3D models) accessible to blind and\n    visually impaired persons by providing real-time audio feedback in\n    response to the location on an object that the user is touching\n    (using an inexpensive stylus). An important feature needed by blind\n    users of AR apps such as CamIO is a 3D spatial guidance feature that\n    provides real-time audio feedback to help the user find a desired\n    location on an object. We have devised a simple audio interface to\n    provide verbal guidance towards a target of interest in 3D. The\n    experiment we report with blind participants using this guidance\n    interface demonstrates the feasibility of the approach and its\n    benefit for helping users find locations of interest.}\n}\nFor attribution, please cite this work as:\nJames Coughlan, Brandon Biggs, Marc-Aurèle Rivière, & Huiying Shen.\n(2020). An Audio-Based 3D Spatial Guidance AR System for Blind Users. In\nMiesenberger Klaus, Manduchi Roberto, Covarrubias Rodriguez Mario, &\nPeňáz Petr (Eds.), Lecture Notes in Computer Science (Vol.\n12376, pp. 475–484). Springer International Publishing. https://doi.org/10.1007/978-3-030-58796-3_55"
  },
  {
    "objectID": "content/pubs/ICISP20/index.html",
    "href": "content/pubs/ICISP20/index.html",
    "title": "Towards the Tactile Discovery of Cultural Heritage with Multi-approach Segmentation",
    "section": "",
    "text": "BibTeX citation:@inproceedings{souradi2020,\n  author = {Ali Souradi and Christele Lecomte and Katerine Romeo and\n    Simon Gay and Marc-Aurèle Rivière and Abderrahim El Moataz and\n    Edwige Pissaloux},\n  editor = {Abderrahim El Moataz and Driss Mammass and Alamin Mansouri\n    and Fathallah Nouboud},\n  publisher = {Springer International Publishing},\n  title = {Towards the {Tactile} {Discovery} of {Cultural} {Heritage}\n    with {Multi-approach} {Segmentation}},\n  booktitle = {Lecture Notes in Computer Science},\n  volume = {12119},\n  pages = {14-23},\n  date = {2020-07-08},\n  url = {http://link.springer.com/10.1007/978-3-030-51935-3_2},\n  doi = {10.1007/978-3-030-51935-3_2},\n  isbn = {978-3-030-51934-6 978-3-030-51935-3},\n  langid = {en},\n  abstract = {This paper presents a new way to access visual information\n    in museums through tactile exploration, and related techniques to\n    efficiently transform visual data into tactile objects.\n    Accessibility to cultural heritage and artworks for people with\n    visual impairments requires the segmentation of images and paintings\n    to extract and classify their contents into meaningful elements\n    which can then be presented through a tactile medium. In this paper,\n    we investigate the feasibility and how to optimize the tactile\n    discovery of an image. First, we study the emergence of image\n    comprehension through tactile discovery, using 3D-printed objects\n    extracted from paintings. Later, we present a dynamic Force Feedback\n    Tablet (F2T) used to convey the 2D shape and texture information of\n    objects through haptic feedback. We then explore several image\n    segmentation methods to automate the extraction of meaningful\n    objects from selected artworks, to be presented to visually impaired\n    people through the F2T. Finally, we evaluate how to best combine the\n    F2T’s haptic effects in order to convey the extracted objects and\n    features to the users, with the aim of facilitating the\n    comprehension of the represented objects and their affordances.}\n}\nFor attribution, please cite this work as:\nAli Souradi, Christele Lecomte, Katerine Romeo, Simon Gay, Marc-Aurèle\nRivière, Abderrahim El Moataz, & Edwige Pissaloux. (2020). Towards\nthe Tactile Discovery of Cultural Heritage with Multi-approach\nSegmentation. In Abderrahim El Moataz, Driss Mammass, Alamin Mansouri,\n& Fathallah Nouboud (Eds.), Lecture Notes in Computer\nScience (Vol. 12119, pp. 14–23). Springer International Publishing.\nhttps://doi.org/10.1007/978-3-030-51935-3_2"
  },
  {
    "objectID": "content/pubs/JEP22/index.html",
    "href": "content/pubs/JEP22/index.html",
    "title": "Spatiotemporal influences on the recognition of two-dimensional vibrotactile patterns on the abdomen",
    "section": "",
    "text": "BibTeX citation:@article{faugloire2022,\n  author = {Elise Faugloire and Laure Lejeune and Marc-Aurèle Rivière\n    and Bruno Mantel},\n  editor = {},\n  title = {Spatiotemporal Influences on the Recognition of\n    Two-Dimensional Vibrotactile Patterns on the Abdomen},\n  journal = {Journal of Experimental Psychology: Applied},\n  volume = {28},\n  number = {3},\n  pages = {606-628},\n  date = {2022-09-02},\n  url = {https://psycnet.apa.org/record/2022-01207-001},\n  doi = {10.1037/xap0000404},\n  issn = {1939-2192, 1076-898X},\n  langid = {en},\n  abstract = {Spatial and temporal factors are known to highly influence\n    tactile perception, but their role has been largely unexplored in\n    the case of two-dimensional (2D) pattern recognition. We\n    investigated whether recognition is facilitated by the spatial\n    and/or temporal separation of pattern elements, or by conditions\n    known to favor perceptual integration, such as the ones eliciting\n    apparent movement. 2D vibrotactile patterns were presented to the\n    abdomen of novice participants. In Experiment 1, we manipulated the\n    spatial (inter-tactor distance) and temporal (burst duration and\n    inter-burst interval) parameters applied to the tracing mode\n    (sequential activation of pattern elements). In Experiment 2, we\n    compared display modes differing in their level of temporal overlap\n    in the presentation of pattern elements: the static mode\n    (simultaneous activation of pattern elements), the slit-scan mode\n    (pattern revealed line by line), and the tracing mode. The results\n    of both experiments reveal that (a) recognition performance\n    increases with the isolation of pattern elements in space and/or in\n    time, (b) spatial and temporal factors interact in pattern\n    recognition, and (c) conditions leading to apparent movement tend to\n    be associated with lower recognition accuracy. These results further\n    our understanding of tactile perception and provide guidance for the\n    design of future vibrotactile communication systems.}\n}\nFor attribution, please cite this work as:\nElise Faugloire, Laure Lejeune, Marc-Aurèle Rivière, & Bruno Mantel.\n(2022). Spatiotemporal influences on the recognition of two-dimensional\nvibrotactile patterns on the abdomen. Journal of Experimental\nPsychology: Applied, 28(3), 606–628. https://doi.org/10.1037/xap0000404"
  },
  {
    "objectID": "content/pubs/NER19/index.html",
    "href": "content/pubs/NER19/index.html",
    "title": "NAV-VIR: an audio-tactile virtual environment to assist visually impaired people",
    "section": "",
    "text": "BibTeX citation:@inproceedings{rivière2019,\n  author = {Marc-Aurèle Rivière and Simon Gay and Katerine Romeo and\n    Edwige Pissaloux and Michal Bujacz and Piotr Skulimowski and Pawel\n    Strumillo},\n  editor = {},\n  publisher = {IEEE},\n  title = {NAV-VIR: An Audio-Tactile Virtual Environment to Assist\n    Visually Impaired People},\n  booktitle = {Proceedings of the International IEEE/EMBS Conference on\n    Neural Engineering},\n  pages = {1038-1041},\n  date = {2019-05-20},\n  url = {https://ieeexplore.ieee.org/document/8717086},\n  doi = {10.1109/NER.2019.8717086},\n  isbn = {978-1-5386-7921-0},\n  langid = {en},\n  abstract = {This paper introduces the\n    {[}NAV-VIR{]}(/content/projects/NAV-VIR) system, a multimodal\n    virtual environment to assist visually impaired people in virtually\n    discovering and exploring unknown areas from the safety of their\n    home. The originality of NAV-VIR resides in (1) an optimized\n    representation of the surrounding topography, the spatial gist,\n    based on human spatial cognition models and the sensorimotor\n    supplementation framework, and (2) a multimodal orientation-aware\n    immersive virtual environment relying on two synergetic interfaces:\n    an interactive force feedback tablet, the F2T, and an immersive\n    HRTF-based 3D audio simulation relying on binaural recordings of\n    real environments. This paper presents NAV-VIR functionalities and\n    its preliminary evaluation through a simple shape and movement\n    perception task.}\n}\nFor attribution, please cite this work as:\nMarc-Aurèle Rivière, Simon Gay, Katerine Romeo, Edwige Pissaloux, Michal\nBujacz, Piotr Skulimowski, & Pawel Strumillo. (2019). NAV-VIR: an\naudio-tactile virtual environment to assist visually impaired people.\nProceedings of the International IEEE/EMBS Conference on Neural\nEngineering, 1038–1041. https://doi.org/10.1109/NER.2019.8717086"
  },
  {
    "objectID": "content/pubs/index.html",
    "href": "content/pubs/index.html",
    "title": "Scientific Publications",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\nJournal of Experimental Psychology: Applied\n\n\n\n\nAssistive Devices\n\n\nAccessibility\n\n\nSensory Substitution\n\n\nHaptic Interface\n\n\nPsychophysics\n\n\n\n\nThis study reveals that patterns made up of several vibration points are better recognized when pattern elements are clearly isolated in time and space. The feeling of a single point moving continuously along the skin, as if the pattern was manually drawn on the skin, does not appear to favor the recognition of patterns’ shape\n\n\n\n\n\n\nSep 2, 2022\n\n\nElise Faugloire, Laure Lejeune, Marc-Aurèle Rivière, Bruno Mantel\n\n\n\n\n\n\n\n\n\nLecture Notes in Computer Science\n\n\n\n\nAssistive Devices\n\n\nAccessibility\n\n\nAugmented Reality\n\n\nSensory Substitution\n\n\nAuditory Interface\n\n\nComputer Vision\n\n\n\n\nWe introduce CamIO, an AR app for Visually Impaired People (VIP) to reach objects in their immediate environment through real-time 3D audio guidance\n\n\n\n\n\n\nSep 12, 2020\n\n\nJames Coughlan, Brandon Biggs, Marc-Aurèle Rivière, Huiying Shen\n\n\n\n\n\n\n\n\n\nLecture Notes in Computer Science\n\n\n\n\nAssistive Devices\n\n\nAccessibility\n\n\nComputer Vision\n\n\nSensory Substitution\n\n\nHaptic Interface\n\n\n\n\nWe introduce preliminary work on using multi-approach image segmentation, combined with a force-feedback interface, to provide access to Artworks to Visually Impaired People\n\n\n\n\n\n\nJul 8, 2020\n\n\nAli Souradi, Christele Lecomte, Katerine Romeo, Simon Gay, Marc-Aurèle Rivière, Abderrahim El Moataz, Edwige Pissaloux\n\n\n\n\n\n\n\n\n\nInternational IEEE/EMBS Conference on Neural Engineering\n\n\n\n\nAssistive Devices\n\n\nAccessibility\n\n\nAugmented Reality\n\n\nSensory Substitution\n\n\nAuditory Interface\n\n\nHaptic Interface\n\n\n\n\nWe introduce NAV-VIR, a multimodal interface for the interactive exploration of maps by Visually Impaired People\n\n\n\n\n\n\nMay 20, 2019\n\n\nMarc-Aurèle Rivière, Simon Gay, Katerine Romeo, Edwige Pissaloux, Michal Bujacz, Piotr Skulimowski, Pawel Strumillo\n\n\n\n\n\n\n\n\n\nLecture Notes in Computer Science\n\n\n\n\nAssistive Devices\n\n\nAccessibility\n\n\nAugmented Reality\n\n\nSensory Substitution\n\n\nHaptic Interface\n\n\n\n\nWe introduce the principles of a haptic interface for finger-movement based exploration of image content through force-feedback\n\n\n\n\n\n\nJul 12, 2018\n\n\nSimon Gay, Marc-Aurèle Rivière, Edwige Pissaloux\n\n\n\n\n\n\n\n\n\nLecture Notes in Computer Science\n\n\n\n\nAssistive Devices\n\n\nAccessibility\n\n\nAugmented Reality\n\n\nSensory Substitution\n\n\nHaptic Interface\n\n\nSpatial Cognition\n\n\n\n\nWe introduce spatial cognition models as a framework to design novel mobility assistive devices for Visually Impaired People\n\n\n\n\n\n\nJul 12, 2018\n\n\nMarc-Aurèle Rivière, Simon Gay, Edwige Pissaloux\n\n\n\n\n\n\nNo matching items"
  }
]