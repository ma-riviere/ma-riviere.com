[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Marc-Aurèle Rivière",
    "section": "",
    "text": "Cognitive Neuroscientist with a keen interest in Perception, Spatial Cognition, and Human-Machine Interfaces.\nI’m a recovering academic who worked on several projects at the intersection between Cognitive Neurosciences and Biomedical Engineering. Those projects aimed to develop and evaluate wearable assistive devices for Visually Impaired People (VIP), providing them with a non-visual experience of their surroundings through a clever use of :Computer Vision and Augmented Reality, within the :Sensory Substitution framework.\nI have since retrained as a Data Scientist with a fondness for Bayesian methods and an unhealthy obsession with the R ecosystem and its community. I also dabble in more generic programming languages such as Java, C# (Unity), and Javascript.\n\n\n\n\n\n\n\n\n\n\nI use this website to gather information on the various projects I have worked on, my publications and scientific communications, as well as some blog posts (which mainly pertain to R and statistics). I also maintain an up-to-date resumé."
  },
  {
    "objectID": "content/posts/spatial/index.html#wide-format-original",
    "href": "content/posts/spatial/index.html#wide-format-original",
    "title": "Fast spatial data matching in R",
    "section": "\n1.1 Wide format (original)",
    "text": "1.1 Wide format (original)\n\n\ndata.table\nSQL (DuckDB)\n\n\n\n\nrides <- (purrr::map_dfr(\n    fs::dir_ls(data_path, glob = \"*.csv\"),\n    \\(file) fread(file, na.strings = \"\")\n  )\n  |> setkey(ride_id)\n)\n\n\n\nTime difference of 16.48 secs\n\n\n\n\n\nrides_con <- DBI::dbConnect(duckdb::duckdb())\n\n\n\n\n\nduckdb::duckdb_read_csv(\n  rides_con, \n  \"rides\", \n  fs::dir_ls(data_path, glob = \"*.csv\")\n)\n\n\nCREATE INDEX ride_idx ON rides (ride_id)\n\n\n\nTime difference of 8.254 secs\n\n\n\n\n\n\n\ndata.frame [5,860,776 x 13]\n\n\n\nride_id\n\n\nrideable_type\n\n\nstarted_at\n\n\nended_at\n\n\nstart_station_name\n\n\nstart_station_id\n\n\nend_station_name\n\n\nend_station_id\n\n\nstart_lat\n\n\nstart_lng\n\n\nend_lat\n\n\nend_lng\n\n\nmember_casual\n\n\n\n\n\n00000123F60251E6\n\n\nclassic_bike\n\n\n2022-02-07 15:47:40\n\n\n2022-02-07 15:49:28\n\n\nWells St & Hubbard St\n\n\nTA1307000151\n\n\nKingsbury St & Kinzie St\n\n\nKA1503000043\n\n\n41.89\n\n\n−87.634\n\n\n41.889\n\n\n−87.639\n\n\nmember\n\n\n\n\n000002EBE159AE82\n\n\nelectric_bike\n\n\n2021-06-22 17:25:15\n\n\n2021-06-22 17:31:34\n\n\nClinton St & Jackson Blvd\n\n\n638\n\n\nMilwaukee Ave & Grand Ave\n\n\n13033\n\n\n41.878\n\n\n−87.641\n\n\n41.891\n\n\n−87.648\n\n\nmember\n\n\n\n\n0000080D43BAA9E4\n\n\nclassic_bike\n\n\n2021-08-29 15:38:05\n\n\n2021-08-29 16:24:03\n\n\nDearborn St & Van Buren St\n\n\n624\n\n\nFederal St & Polk St\n\n\nSL-008\n\n\n41.876\n\n\n−87.629\n\n\n41.872\n\n\n−87.63\n\n\ncasual\n\n\n\n\n00000B4F1F71F9C2\n\n\nelectric_bike\n\n\n2021-09-08 16:31:38\n\n\n2021-09-08 16:37:54\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n41.91\n\n\n−87.69\n\n\n41.91\n\n\n−87.7\n\n\nmember\n\n\n\n\n00000CAE95438C9D\n\n\nclassic_bike\n\n\n2021-07-20 15:40:46\n\n\n2021-07-20 17:38:17\n\n\nStreeter Dr & Grand Ave\n\n\n13022\n\n\nFairbanks Ct & Grand Ave\n\n\nTA1305000003\n\n\n41.892\n\n\n−87.612\n\n\n41.892\n\n\n−87.621\n\n\ncasual\n\n\n\n\n00000E22FBA89D81\n\n\nelectric_bike\n\n\n2022-05-19 14:42:55\n\n\n2022-05-19 14:54:03\n\n\nNA\n\n\nNA\n\n\nClark St & Armitage Ave\n\n\n13146\n\n\n41.9\n\n\n−87.62\n\n\n41.918\n\n\n−87.636\n\n\nmember\n\n\n\n\n00000EBBC119168C\n\n\nclassic_bike\n\n\n2021-10-31 11:30:37\n\n\n2021-10-31 11:39:27\n\n\nDorchester Ave & 49th St\n\n\nKA1503000069\n\n\nKimbark Ave & 53rd St\n\n\nTA1309000037\n\n\n41.806\n\n\n−87.592\n\n\n41.8\n\n\n−87.595\n\n\nmember\n\n\n\n\n000018B1D040DB44\n\n\nelectric_bike\n\n\n2022-04-25 10:37:22\n\n\n2022-04-25 10:44:19\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n41.79\n\n\n−87.6\n\n\n41.79\n\n\n−87.59\n\n\nmember\n\n\n\n\n000019B7F053D461\n\n\nclassic_bike\n\n\n2021-08-13 19:57:28\n\n\n2021-08-13 20:02:56\n\n\nLarrabee St & Webster Ave\n\n\n13193\n\n\nSheffield Ave & Webster Ave\n\n\nTA1309000033\n\n\n41.922\n\n\n−87.644\n\n\n41.922\n\n\n−87.654\n\n\nmember\n\n\n\n\n00001B4F79D102B5\n\n\nclassic_bike\n\n\n2021-07-28 07:58:27\n\n\n2021-07-28 08:05:00\n\n\nDuSable Lake Shore Dr & Belmont Ave\n\n\nTA1309000049\n\n\nBroadway & Waveland Ave\n\n\n13325\n\n\n41.941\n\n\n−87.639\n\n\n41.949\n\n\n−87.649\n\n\ncasual\n\n\n\n\n\n[ omitted 5,860,761 entries ]"
  },
  {
    "objectID": "content/posts/spatial/index.html#long-format",
    "href": "content/posts/spatial/index.html#long-format",
    "title": "Fast spatial data matching in R",
    "section": "\n1.2 Long format",
    "text": "1.2 Long format\n\n\ndata.table\ndtplyr\nSQL (DuckDB)\ndbplyr\n\n\n\n\nrides_l <- (melt(\n    rides,\n    measure = measure(way, value.name, pattern = \"(end|start).*(name|id|lat|lng)\")\n  )\n  |> setkey(ride_id, id)\n)\n\n\n\nTime difference of 5.821 secs\n\n\n\n\n\n(pivot_longer(\n    rides,\n    matches(\"^end_|^start_\"),\n    names_pattern = \"(end|start).*(name|id|lat|lng)\",\n    names_to = c(\"way\", \".value\")\n  ) \n  |> as.data.table()\n  |> setkey(ride_id, id)\n)\n\n\n\nTime difference of 13.2 secs\n\n\n\n\n\nCREATE TABLE rides_l AS \n(\n  SELECT\n    ride_id, rideable_type, started_at, ended_at,member_casual\n    , 'start' AS way\n    , start_station_name AS name\n    , start_station_id AS id\n    , start_lat AS lat\n    , start_lng AS lng\n  FROM rides\n)\nUNION ALL\n(\n  SELECT\n    ride_id, rideable_type, started_at, ended_at, member_casual\n    , 'end' AS way\n    , end_station_name AS name\n    , end_station_id AS id\n    , end_lat AS lat\n    , end_lng AS lng\n  FROM rides\n);\n\nCREATE INDEX station_idx ON rides_l (id);\n\n\n\nTime difference of 6.097 secs\n\n\n\n\n\n\n\n\nAlternatively\n\n\n\n\n\nWe can reuse an existinf df and directly add it (or bind it as a view) to the database:\n\nDBI::dbWriteTable(rides_con, \"rides_l\", rides_l) # As a TABLE\n\nduckdb::duckdb_register(rides_con, \"rides_l\", rides_l) # As a VIEW\n\n\n\n\n\n\n\n(tbl(rides_con, \"rides\") \n  |> pivot_longer(\n    matches(\"^end_|^start_\"),\n    names_pattern = \"(end|start).*(name|id|lat|lng)\", \n    names_to = c(\"way\", \".value\")\n  )\n  |> compute(\"rides_l.dbp\")\n)\n\n\n\nTime difference of 4.713 secs\n\n\n\n\n\n\n\ndata.frame [11,721,552 x 10]\n\n\n\nride_id\n\n\nrideable_type\n\n\nstarted_at\n\n\nended_at\n\n\nmember_casual\n\n\nway\n\n\nname\n\n\nid\n\n\nlat\n\n\nlng\n\n\n\n\n\n99FEC93BA843FB20\n\n\nelectric_bike\n\n\n2021-06-13 14:31:28\n\n\n2021-06-13 14:34:11\n\n\nmember\n\n\nstart\n\n\nNA\n\n\nNA\n\n\n41.8\n\n\n−87.59\n\n\n\n\n06048DCFC8520CAF\n\n\nelectric_bike\n\n\n2021-06-04 11:18:02\n\n\n2021-06-04 11:24:19\n\n\nmember\n\n\nstart\n\n\nNA\n\n\nNA\n\n\n41.79\n\n\n−87.59\n\n\n\n\n9598066F68045DF2\n\n\nelectric_bike\n\n\n2021-06-04 09:49:35\n\n\n2021-06-04 09:55:34\n\n\nmember\n\n\nstart\n\n\nNA\n\n\nNA\n\n\n41.8\n\n\n−87.6\n\n\n\n\nB03C0FE48C412214\n\n\nelectric_bike\n\n\n2021-06-03 19:56:05\n\n\n2021-06-03 20:21:55\n\n\nmember\n\n\nstart\n\n\nNA\n\n\nNA\n\n\n41.78\n\n\n−87.58\n\n\n\n\nB9EEA89F8FEE73B7\n\n\nelectric_bike\n\n\n2021-06-04 14:05:51\n\n\n2021-06-04 14:09:59\n\n\nmember\n\n\nstart\n\n\nNA\n\n\nNA\n\n\n41.8\n\n\n−87.59\n\n\n\n\n62B943CEAAA420BA\n\n\nelectric_bike\n\n\n2021-06-03 19:32:01\n\n\n2021-06-03 19:38:46\n\n\nmember\n\n\nstart\n\n\nNA\n\n\nNA\n\n\n41.78\n\n\n−87.58\n\n\n\n\n7E2546FBA79C46EE\n\n\nelectric_bike\n\n\n2021-06-10 16:30:10\n\n\n2021-06-10 16:36:21\n\n\nmember\n\n\nstart\n\n\nNA\n\n\nNA\n\n\n41.79\n\n\n−87.6\n\n\n\n\n3DDF3BBF6C4C3C89\n\n\nelectric_bike\n\n\n2021-06-10 17:00:30\n\n\n2021-06-10 17:06:48\n\n\nmember\n\n\nstart\n\n\nNA\n\n\nNA\n\n\n41.79\n\n\n−87.59\n\n\n\n\n2608805637155AB6\n\n\nelectric_bike\n\n\n2021-06-10 12:46:16\n\n\n2021-06-10 12:55:02\n\n\nmember\n\n\nstart\n\n\nNA\n\n\nNA\n\n\n41.93\n\n\n−87.67\n\n\n\n\nAF529C946F28ED42\n\n\nelectric_bike\n\n\n2021-06-23 17:57:29\n\n\n2021-06-23 18:06:40\n\n\nmember\n\n\nstart\n\n\nNA\n\n\nNA\n\n\n41.88\n\n\n−87.61\n\n\n\n\n\n[ omitted 11,721,537 entries ]"
  },
  {
    "objectID": "content/posts/spatial/index.html#cleaning-useless-coordinates",
    "href": "content/posts/spatial/index.html#cleaning-useless-coordinates",
    "title": "Fast spatial data matching in R",
    "section": "\n2.1 Cleaning useless coordinates",
    "text": "2.1 Cleaning useless coordinates\nRemoving entries were lat/lng do not have sufficient precision to be reliably matched to a station (i.e. entries having less than 4 decimals, which corresponds to a 11 meters “radius” at the equator).\n\n\n\n\n\n\nDegrees to distance equivalence\n\n\n\n\n\n\n\nDecimal\nDistance at the equator (m)\n\n\n\n0\n111,120\n\n\n1\n11,112\n\n\n2\n1,111.2\n\n\n3\n111.12\n\n\n4\n11.112\n\n\n5\n1.1112\n\n\n\n\n\n\n\ndecp <- \\(x) str_length(str_remove(as.character(abs(x)), \".*\\\\.\")) >= 4\n\n\nCREATE FUNCTION decp(x) AS length(str_split(CAST(abs(x) AS VARCHAR(10)), '.')[2]) >= 4\n\n\n\n\n\n\ndata.table\ndtplyr\nSQL (DuckDB)\ndbplyr\n\n\n\n\nrides_l_clean <- rides_l[decp(lat) & decp(lng), ] |> setkey(ride_id)\n\n\n\nTime difference of 24.62 secs\n\n\n\n\n\n(rides_l\n  |> filter(decp(lat) & decp(lng))\n  |> as.data.table()\n  |> setkey(ride_id)\n)\n\n\n\nTime difference of 29.03 secs\n\n\n\n\n\nCREATE TABLE rides_l_clean AS \nSELECT * FROM rides_l \nWHERE decp(lat) AND decp(lng)\n\n\n\nTime difference of 5.024 secs\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nHere, dbplyr will leave the decp call as-is in the SQL translation, but since we have previously defined a decp SQL function, this function will get called when the SQL query is executed.\n\n\n\n(tbl(rides_con, \"rides_l.dbp\") \n  |> filter(if_all(c(lat, lng), \\(x) decp(x)))\n  |> compute(\"rides_l_clean.dbp\")\n)\n\n\n\nTime difference of 5.426 secs\n\n\n\n\n\n\n\ndata.table [9,937,077 x 10]\n\n\n\nride_id\n\n\nrideable_type\n\n\nstarted_at\n\n\nended_at\n\n\nmember_casual\n\n\nway\n\n\nname\n\n\nid\n\n\nlat\n\n\nlng\n\n\n\n\n\n00000123F60251E6\n\n\nclassic_bike\n\n\n2022-02-07 15:47:40\n\n\n2022-02-07 15:49:28\n\n\nmember\n\n\nend\n\n\nKingsbury St & Kinzie St\n\n\nKA1503000043\n\n\n41.889\n\n\n−87.639\n\n\n\n\n00000123F60251E6\n\n\nclassic_bike\n\n\n2022-02-07 15:47:40\n\n\n2022-02-07 15:49:28\n\n\nmember\n\n\nstart\n\n\nWells St & Hubbard St\n\n\nTA1307000151\n\n\n41.89\n\n\n−87.634\n\n\n\n\n000002EBE159AE82\n\n\nelectric_bike\n\n\n2021-06-22 17:25:15\n\n\n2021-06-22 17:31:34\n\n\nmember\n\n\nend\n\n\nMilwaukee Ave & Grand Ave\n\n\n13033\n\n\n41.891\n\n\n−87.648\n\n\n\n\n000002EBE159AE82\n\n\nelectric_bike\n\n\n2021-06-22 17:25:15\n\n\n2021-06-22 17:31:34\n\n\nmember\n\n\nstart\n\n\nClinton St & Jackson Blvd\n\n\n638\n\n\n41.878\n\n\n−87.641\n\n\n\n\n0000080D43BAA9E4\n\n\nclassic_bike\n\n\n2021-08-29 15:38:05\n\n\n2021-08-29 16:24:03\n\n\ncasual\n\n\nstart\n\n\nDearborn St & Van Buren St\n\n\n624\n\n\n41.876\n\n\n−87.629\n\n\n\n\n0000080D43BAA9E4\n\n\nclassic_bike\n\n\n2021-08-29 15:38:05\n\n\n2021-08-29 16:24:03\n\n\ncasual\n\n\nend\n\n\nFederal St & Polk St\n\n\nSL-008\n\n\n41.872\n\n\n−87.63\n\n\n\n\n00000CAE95438C9D\n\n\nclassic_bike\n\n\n2021-07-20 15:40:46\n\n\n2021-07-20 17:38:17\n\n\ncasual\n\n\nstart\n\n\nStreeter Dr & Grand Ave\n\n\n13022\n\n\n41.892\n\n\n−87.612\n\n\n\n\n00000CAE95438C9D\n\n\nclassic_bike\n\n\n2021-07-20 15:40:46\n\n\n2021-07-20 17:38:17\n\n\ncasual\n\n\nend\n\n\nFairbanks Ct & Grand Ave\n\n\nTA1305000003\n\n\n41.892\n\n\n−87.621\n\n\n\n\n00000E22FBA89D81\n\n\nelectric_bike\n\n\n2022-05-19 14:42:55\n\n\n2022-05-19 14:54:03\n\n\nmember\n\n\nend\n\n\nClark St & Armitage Ave\n\n\n13146\n\n\n41.918\n\n\n−87.636\n\n\n\n\n00000EBBC119168C\n\n\nclassic_bike\n\n\n2021-10-31 11:30:37\n\n\n2021-10-31 11:39:27\n\n\nmember\n\n\nstart\n\n\nDorchester Ave & 49th St\n\n\nKA1503000069\n\n\n41.806\n\n\n−87.592\n\n\n\n\n00000EBBC119168C\n\n\nclassic_bike\n\n\n2021-10-31 11:30:37\n\n\n2021-10-31 11:39:27\n\n\nmember\n\n\nend\n\n\nKimbark Ave & 53rd St\n\n\nTA1309000037\n\n\n41.8\n\n\n−87.595\n\n\n\n\n000019B7F053D461\n\n\nclassic_bike\n\n\n2021-08-13 19:57:28\n\n\n2021-08-13 20:02:56\n\n\nmember\n\n\nstart\n\n\nLarrabee St & Webster Ave\n\n\n13193\n\n\n41.922\n\n\n−87.644\n\n\n\n\n000019B7F053D461\n\n\nclassic_bike\n\n\n2021-08-13 19:57:28\n\n\n2021-08-13 20:02:56\n\n\nmember\n\n\nend\n\n\nSheffield Ave & Webster Ave\n\n\nTA1309000033\n\n\n41.922\n\n\n−87.654\n\n\n\n\n00001B4F79D102B5\n\n\nclassic_bike\n\n\n2021-07-28 07:58:27\n\n\n2021-07-28 08:05:00\n\n\ncasual\n\n\nend\n\n\nBroadway & Waveland Ave\n\n\n13325\n\n\n41.949\n\n\n−87.649\n\n\n\n\n00001B4F79D102B5\n\n\nclassic_bike\n\n\n2021-07-28 07:58:27\n\n\n2021-07-28 08:05:00\n\n\ncasual\n\n\nstart\n\n\nDuSable Lake Shore Dr & Belmont Ave\n\n\nTA1309000049\n\n\n41.941\n\n\n−87.639\n\n\n\n\n\n[ omitted 9,937,062 entries ]"
  },
  {
    "objectID": "content/posts/spatial/index.html#whats-missing",
    "href": "content/posts/spatial/index.html#whats-missing",
    "title": "Fast spatial data matching in R",
    "section": "\n2.2 What’s missing ?",
    "text": "2.2 What’s missing ?\nEntries missing one or both coordinates but having an id or name:\n\n\ndata.table\nSQL (DuckDB)\ndbplyr\n\n\n\n\nrides_l_clean[(is.na(lat) | is.na(lng)) & (!is.na(id) | !is.na(name)), ]\n\n\n\n\nSELECT * FROM rides_l_clean \nWHERE ((lat IS NULL) OR (lng IS NULL) \n  AND (NOT((id IS NULL)) OR NOT((name IS NULL))))\n\n\n\n\n(tbl(rides_con, \"rides_l_clean.dbp\")\n  |> filter(if_any(c(lat, lng), \\(v) is.na(v)) & (!is.na(id) | !is.na(name)))\n  |> collect()\n)\n\n\n\n\n\n\ndata.frame [0 x 10]\n\n\n\nride_id\n\n\nrideable_type\n\n\nstarted_at\n\n\nended_at\n\n\nmember_casual\n\n\nway\n\n\nname\n\n\nid\n\n\nlat\n\n\nlng\n\n\n\n\n\nEntries missing either name or id, but having coordinates:\n\n\ndata.table\ndtplyr\nSQL (DuckDB)\ndbplyr\n\n\n\n\nrides_l_clean[(!is.na(lat) & !is.na(lng)) & (is.na(id) | is.na(name))] -> rides_l_clean_unk\n\n\n\n\n(rides_l_clean \n  |> filter(if_all(c(lat, lng), \\(v) !is.na(v)) & (is.na(id) | is.na(name)))\n  |> as.data.table()\n)\n\n\n\n\nCREATE TABLE rides_l_clean_unk AS\nSELECT * FROM rides_l_clean\nWHERE ((id IS NULL) OR (name IS NULL)) \n  AND (NOT((lat IS NULL)) AND NOT((lng IS NULL)))\n\n\n\n\n\n\n\n(tbl(rides_con, \"rides_l_clean.dbp\") \n  |> filter(if_all(c(lat, lng), \\(v) !is.na(v)) & (is.na(id) | is.na(name)))\n  |> compute(\"rides_l_clean.dbp\")\n)\n\n\n\n\n\n\ndata.frame [3 x 10]\n\n\n\nride_id\n\n\nrideable_type\n\n\nstarted_at\n\n\nended_at\n\n\nmember_casual\n\n\nway\n\n\nname\n\n\nid\n\n\nlat\n\n\nlng\n\n\n\n\n\n176105D1F8A1216B\n\n\nelectric_bike\n\n\n2021-07-18 03:44:22\n\n\n2021-07-18 04:12:23\n\n\ncasual\n\n\nstart\n\n\nNA\n\n\n13221\n\n\n41.908\n\n\n−87.673\n\n\n\n\nDE82A15026BA3056\n\n\nelectric_bike\n\n\n2021-09-21 18:18:59\n\n\n2021-09-21 18:21:48\n\n\ncasual\n\n\nstart\n\n\nNA\n\n\n20215\n\n\n41.648\n\n\n−87.546\n\n\n\n\nEE197EDA4CF8CFE5\n\n\nelectric_bike\n\n\n2021-09-22 07:14:42\n\n\n2021-09-22 07:22:38\n\n\ncasual\n\n\nstart\n\n\nNA\n\n\nWL-008\n\n\n41.867\n\n\n−87.641\n\n\n\n\n\nIt seems there are only 3 entries missing identification that could be matched based on their coordinates at the level of precision we use (11m / 4 decimals).\n\n\n\n\n\n\nWarning\n\n\n\nAlthough, if we look at the original dataset (before filtering the inaccurate coordinates):\n\n\n\n\ndata.table\ndtplyr\nSQL (DuckDB)\ndbplyr\n\n\n\n\nrides_l[(!is.na(lat) & !is.na(lng)) & (is.na(id) | is.na(name))] -> rides_l_unk\n\n\n\n\n(rides_l\n  |> filter(if_all(c(lat, lng), \\(v) !is.na(v)) & (is.na(id) | is.na(name)))\n  |> as.data.table()\n)\n\n\n\n\nCREATE TABLE rides_l_unk AS\nSELECT * FROM rides_l\nWHERE ((id IS NULL) OR (name IS NULL)) \n  AND (NOT((lat IS NULL)) AND NOT((lng IS NULL)))\n\n\n\n\n\n\n\n(tbl(rides_con, \"rides_l.dbp\") \n  |> filter(if_all(c(lat, lng), \\(v) !is.na(v)) & (is.na(id) | is.na(name)))\n  |> compute(\"rides_l_unk.dbp\")\n)\n\n\n\n\n\n\ndata.frame [1,696,469 x 10]\n\n\n\nride_id\n\n\nrideable_type\n\n\nstarted_at\n\n\nended_at\n\n\nmember_casual\n\n\nway\n\n\nname\n\n\nid\n\n\nlat\n\n\nlng\n\n\n\n\n\n00000B4F1F71F9C2\n\n\nelectric_bike\n\n\n2021-09-08 16:31:38\n\n\n2021-09-08 16:37:54\n\n\nmember\n\n\nstart\n\n\nNA\n\n\nNA\n\n\n41.91\n\n\n−87.69\n\n\n\n\n00000B4F1F71F9C2\n\n\nelectric_bike\n\n\n2021-09-08 16:31:38\n\n\n2021-09-08 16:37:54\n\n\nmember\n\n\nend\n\n\nNA\n\n\nNA\n\n\n41.91\n\n\n−87.7\n\n\n\n\n00000E22FBA89D81\n\n\nelectric_bike\n\n\n2022-05-19 14:42:55\n\n\n2022-05-19 14:54:03\n\n\nmember\n\n\nstart\n\n\nNA\n\n\nNA\n\n\n41.9\n\n\n−87.62\n\n\n\n\n000018B1D040DB44\n\n\nelectric_bike\n\n\n2022-04-25 10:37:22\n\n\n2022-04-25 10:44:19\n\n\nmember\n\n\nend\n\n\nNA\n\n\nNA\n\n\n41.79\n\n\n−87.59\n\n\n\n\n000018B1D040DB44\n\n\nelectric_bike\n\n\n2022-04-25 10:37:22\n\n\n2022-04-25 10:44:19\n\n\nmember\n\n\nstart\n\n\nNA\n\n\nNA\n\n\n41.79\n\n\n−87.6\n\n\n\n\n000025C113FEB7B6\n\n\nelectric_bike\n\n\n2021-10-25 11:15:21\n\n\n2021-10-25 11:20:21\n\n\nmember\n\n\nend\n\n\nNA\n\n\nNA\n\n\n41.81\n\n\n−87.62\n\n\n\n\n000025C113FEB7B6\n\n\nelectric_bike\n\n\n2021-10-25 11:15:21\n\n\n2021-10-25 11:20:21\n\n\nmember\n\n\nstart\n\n\nNA\n\n\nNA\n\n\n41.81\n\n\n−87.62\n\n\n\n\n00002E385DB2888C\n\n\nelectric_bike\n\n\n2022-05-07 16:28:53\n\n\n2022-05-07 16:40:28\n\n\ncasual\n\n\nstart\n\n\nNA\n\n\nNA\n\n\n41.89\n\n\n−87.75\n\n\n\n\n00002E385DB2888C\n\n\nelectric_bike\n\n\n2022-05-07 16:28:53\n\n\n2022-05-07 16:40:28\n\n\ncasual\n\n\nend\n\n\nNA\n\n\nNA\n\n\n41.87\n\n\n−87.75\n\n\n\n\n000043B681BFB305\n\n\nelectric_bike\n\n\n2021-10-14 16:24:41\n\n\n2021-10-14 16:29:02\n\n\ncasual\n\n\nend\n\n\nNA\n\n\nNA\n\n\n41.9\n\n\n−87.7\n\n\n\n\n\n[ omitted 1,696,454 entries ]\n\n\n\n\nThere were 1,696,469 missing stations’ id or name that could have been filled in the original data, but it seems that all of them disappeared when we filtered the coordinates with less than 4 decimals of precision. It would seem that those entries were missing their id/name in the source data because their coordinates were too imprecise to be matched to any station in the first place.\n\n\n\n\n\n\nIf one were to do the macthing anyway, here’s how:"
  },
  {
    "objectID": "content/posts/spatial/index.html#creating-stations-data",
    "href": "content/posts/spatial/index.html#creating-stations-data",
    "title": "Fast spatial data matching in R",
    "section": "\n3.1 Creating stations data",
    "text": "3.1 Creating stations data\nFirst, we need to assemble a dataset linking each unique station id (and name) with a set of coordinates (here, we use the average lat & lng)\n\n\ndata.table\nSQL (DuckDB)\ndbplyr\n\n\n\n\nstations_clean <- (rides_l_clean\n  |> na.omit(cols = c(\"id\", \"name\"))\n  |> dcast(id+name ~ ., fun.agg = list(min, max, mean), value.var = c(\"lat\", \"lng\"))\n  |> bind(x, setcolorder(x, c(\"id\", \"name\", str_subset(colnames(x), \"lat_|_lng\"))))\n  |> unique(by = \"id\")\n  |> setkey(id)\n)\n\n\n\n\nCREATE TABLE stations_clean AS \nSELECT DISTINCT on(id)\n  id, name\n  , MIN(lat) AS lat_min\n  , MAX(lat) AS lat_max\n  , AVG(lat) AS lat_mean\n  , MIN(lng) AS lng_min\n  , MAX(lng) AS lng_max\n  , AVG(lng) AS lng_mean\nFROM rides_l_clean\nWHERE (NOT((id IS NULL))) AND (NOT((name IS NULL)))\nGROUP BY id, name;\n\n\n\n\n(tbl(rides_con, \"rides_l_clean.dbp\")\n  |> filter(!is.na(id), !is.na(name))\n  |> group_by(id)\n  |> summarize(\n    name = first(name),\n    across(c(lat, lng), list(min, max, mean), .names = \"{.col}_{.fn}\")\n  )\n  |> arrange(id)\n  |> compute(\"stations_clean.dbp\")\n)\n\n\n\n\n\n\ndata.frame [693 x 8]\n\n\n\nid\n\n\nname\n\n\nlat_min\n\n\nlat_max\n\n\nlat_mean\n\n\nlng_min\n\n\nlng_max\n\n\nlng_mean\n\n\n\n\n\n13001\n\n\nMichigan Ave & Washington St\n\n\n41.813\n\n\n41.958\n\n\n41.884\n\n\n−87.657\n\n\n−87.59\n\n\n−87.625\n\n\n\n\n13006\n\n\nLaSalle St & Washington St\n\n\n41.872\n\n\n41.952\n\n\n41.883\n\n\n−87.833\n\n\n−87.619\n\n\n−87.633\n\n\n\n\n13008\n\n\nMillennium Park\n\n\n41.809\n\n\n41.96\n\n\n41.881\n\n\n−87.785\n\n\n−87.587\n\n\n−87.624\n\n\n\n\n13011\n\n\nCanal St & Adams St\n\n\n41.871\n\n\n41.902\n\n\n41.879\n\n\n−87.657\n\n\n−87.626\n\n\n−87.64\n\n\n\n\n13016\n\n\nSt. Clair St & Erie St\n\n\n41.841\n\n\n41.931\n\n\n41.894\n\n\n−87.744\n\n\n−87.616\n\n\n−87.623\n\n\n\n\n13017\n\n\nFranklin St & Chicago Ave\n\n\n41.873\n\n\n41.917\n\n\n41.897\n\n\n−87.663\n\n\n−87.625\n\n\n−87.636\n\n\n\n\n13021\n\n\nClinton St & Lake St\n\n\n41.876\n\n\n41.909\n\n\n41.886\n\n\n−87.661\n\n\n−87.617\n\n\n−87.642\n\n\n\n\n13022\n\n\nStreeter Dr & Grand Ave\n\n\n41.772\n\n\n41.969\n\n\n41.892\n\n\n−87.785\n\n\n−87.586\n\n\n−87.612\n\n\n\n\n13028\n\n\n900 W Harrison St\n\n\n41.836\n\n\n41.881\n\n\n41.875\n\n\n−87.679\n\n\n−87.607\n\n\n−87.65\n\n\n\n\n13029\n\n\nField Museum\n\n\n41.81\n\n\n41.896\n\n\n41.865\n\n\n−87.625\n\n\n−87.588\n\n\n−87.618\n\n\n\n\n\n[ omitted 678 entries ]"
  },
  {
    "objectID": "content/posts/spatial/index.html#matching-on-the-cleaned-data",
    "href": "content/posts/spatial/index.html#matching-on-the-cleaned-data",
    "title": "Fast spatial data matching in R",
    "section": "\n4.1 Matching on the cleaned data",
    "text": "4.1 Matching on the cleaned data\nTo save time, let’s only apply the procedure to the entries that actually need to be matched (i.e. the ones having coordinates but missing either name or id).\n\n\nfuzzyjoin\nSQL (DuckDB)\n\n\n\nThere are 3 entries from rides_l_clean that could be position-matched to a known station.\n\nmatched_clean <- (fuzzyjoin::geo_inner_join(\n    as.data.frame(rides_l_clean_unk),\n    as.data.frame(stations_clean),\n    by = c(\"lng\" = \"lng_mean\", \"lat\" = \"lat_mean\"),\n    method = \"haversine\",\n    unit = \"km\",\n    max_dist = 0.011, # 11 meters\n    distance_col = \"dist\"\n  ) \n  |> mutate(name = coalesce(name.x, name.y), id = coalesce(id.x, id.y)) \n  |> select(colnames(rides_l_clean), dist)\n  |> arrange(ride_id)\n  |> drop_na(ride_id, id, name)\n  |> as.data.table()\n  |> setkey(ride_id, id)\n)\n\n\n\nTime difference of 0.1416 secs\n\n\n\n\nThere are 3 entries from rides_l_clean that could be position-matched to a known station.\nCreating the haversine distance function:\n\n\nCREATE FUNCTION haversine(lat1, lng1, lat2, lng2) \n    AS ( 6371 * acos( cos( radians(lat1) ) *\n       cos( radians(lat2) ) * cos( radians(lng2) - radians(lng1) ) +\n       sin( radians(lat1) ) * sin( radians(lat2) ) ) \n    );\n\nDoing the matching:\n\nCREATE TABLE matched_clean AS\nSELECT\n  ride_id, rideable_type, started_at, ended_at, member_casual, way  \n  , COALESCE(r.name, s.name) AS name\n  , COALESCE(r.id, s.id) AS id\n  , r.lat, r.lng\n  , haversine(s.lat_mean, s.lng_mean, r.lat, r.lng) AS dist\nFROM rides_l_clean_unk r, stations_clean s\nWHERE dist <= 0.011\n\n\n\nTime difference of 0.004322 secs\n\n\n\n\n\n\ndata.table [3 x 11]\n\n\n\nride_id\n\n\nrideable_type\n\n\nstarted_at\n\n\nended_at\n\n\nmember_casual\n\n\nway\n\n\nname\n\n\nid\n\n\nlat\n\n\nlng\n\n\ndist\n\n\n\n\n\n176105D1F8A1216B\n\n\nelectric_bike\n\n\n2021-07-18 03:44:22\n\n\n2021-07-18 04:12:23\n\n\ncasual\n\n\nstart\n\n\nWood St & Milwaukee Ave\n\n\n13221\n\n\n41.908\n\n\n−87.673\n\n\n0.002\n\n\n\n\nDE82A15026BA3056\n\n\nelectric_bike\n\n\n2021-09-21 18:18:59\n\n\n2021-09-21 18:21:48\n\n\ncasual\n\n\nstart\n\n\nHegewisch Metra Station\n\n\n20215\n\n\n41.648\n\n\n−87.546\n\n\n0.009\n\n\n\n\nEE197EDA4CF8CFE5\n\n\nelectric_bike\n\n\n2021-09-22 07:14:42\n\n\n2021-09-22 07:22:38\n\n\ncasual\n\n\nstart\n\n\nClinton St & Roosevelt Rd\n\n\nWL-008\n\n\n41.867\n\n\n−87.641\n\n\n0.001\n\n\n\n\n\nAnd we indeed get three matches !\n\n\n\n\n\n\nNote\n\n\n\nBut those three already had an id, so we could probably have filled their missing name using stations_clean directly, instead of a convoluted proximity-based matching (which is more ressource intensive and less precise).\n\n\n\nstations_clean[matched_clean, on = .(id)\n             ][, .(id, name.stations = name, name.proximity = i.name, lat, lng)]\ndata.table [3 x 5]\n\n\n\nid\n\n\nname.stations\n\n\nname.proximity\n\n\nlat\n\n\nlng\n\n\n\n\n\n13221\n\n\nWood St & Milwaukee Ave\n\n\nWood St & Milwaukee Ave\n\n\n41.908\n\n\n−87.673\n\n\n\n\n20215\n\n\nHegewisch Metra Station\n\n\nHegewisch Metra Station\n\n\n41.648\n\n\n−87.546\n\n\n\n\nWL-008\n\n\nClinton St & Roosevelt Rd\n\n\nClinton St & Roosevelt Rd\n\n\n41.867\n\n\n−87.641\n\n\n\n\n\nAt least, we can see that the proximity-based matched name and the one associated to that station in stations_clean are the same, so the proximity-matching method works reasonably well."
  },
  {
    "objectID": "content/posts/spatial/index.html#matching-on-the-original-data",
    "href": "content/posts/spatial/index.html#matching-on-the-original-data",
    "title": "Fast spatial data matching in R",
    "section": "\n4.2 Matching on the original data",
    "text": "4.2 Matching on the original data\nWhat if we did the same procedure on the non-cleaned data (the one with coordinates less precise than our criteria for matching) ?\n\n4.2.1 Unfiltered stations data\nFirst, we need to recompute the stations data from rides_l (i.e. rides data before cleaning):\n\n\ndata.table\nSQL (DuckDB)\ndbplyr\n\n\n\n\nstations <- (rides_l\n  |> na.omit(cols = c(\"id\", \"name\"))\n  |> dcast(id+name ~ ., fun.agg = list(min, max, mean), value.var = c(\"lat\", \"lng\"))\n  |> bind(x, setcolorder(x, c(\"id\", \"name\", str_subset(colnames(x), \"lat_|_lng\"))))\n  |> unique(by = \"id\")\n  |> setkey(id, name)\n)\n\n\n\n\nCREATE TABLE stations AS \nSELECT DISTINCT on(id)\n  id, name\n  , MIN(lat) AS lat_min\n  , MAX(lat) AS lat_max\n  , AVG(lat) AS lat_mean\n  , MIN(lng) AS lng_min\n  , MAX(lng) AS lng_max\n  , AVG(lng) AS lng_mean\nFROM rides_l\nWHERE (NOT((id IS NULL))) AND (NOT((name IS NULL)))\nGROUP BY id, name;\n\n\n\n\n(tbl(rides_con, \"rides_l.dbp\")\n  |> filter(!is.na(id), !is.na(name))\n  |> group_by(id)\n  |> summarize(\n    name = first(name),\n    across(c(lat, lng), list(min, max, mean), .names = \"{.col}_{.fn}\")\n  )\n  |> arrange(id)\n  |> compute(\"stations.dbp\")\n)\n\n\n\n\n\n\ndata.frame [1,078 x 8]\n\n\n\nid\n\n\nname\n\n\nlat_min\n\n\nlat_max\n\n\nlat_mean\n\n\nlng_min\n\n\nlng_max\n\n\nlng_mean\n\n\n\n\n\n021320\n\n\nMTV Hubbard St\n\n\n41.89\n\n\n41.89\n\n\n41.89\n\n\n−87.68\n\n\n−87.68\n\n\n−87.68\n\n\n\n\n13001\n\n\nMichigan Ave & Washington St\n\n\n41.813\n\n\n41.958\n\n\n41.884\n\n\n−87.657\n\n\n−87.59\n\n\n−87.625\n\n\n\n\n13006\n\n\nLaSalle St & Washington St\n\n\n41.872\n\n\n41.952\n\n\n41.883\n\n\n−87.833\n\n\n−87.619\n\n\n−87.633\n\n\n\n\n13008\n\n\nMillennium Park\n\n\n41.809\n\n\n41.96\n\n\n41.881\n\n\n−87.785\n\n\n−87.587\n\n\n−87.624\n\n\n\n\n13011\n\n\nCanal St & Adams St\n\n\n41.871\n\n\n41.902\n\n\n41.879\n\n\n−87.657\n\n\n−87.626\n\n\n−87.64\n\n\n\n\n13016\n\n\nSt. Clair St & Erie St\n\n\n41.841\n\n\n41.931\n\n\n41.894\n\n\n−87.744\n\n\n−87.616\n\n\n−87.623\n\n\n\n\n13017\n\n\nFranklin St & Chicago Ave\n\n\n41.873\n\n\n41.917\n\n\n41.897\n\n\n−87.663\n\n\n−87.625\n\n\n−87.636\n\n\n\n\n13021\n\n\nClinton St & Lake St\n\n\n41.876\n\n\n41.909\n\n\n41.886\n\n\n−87.661\n\n\n−87.617\n\n\n−87.642\n\n\n\n\n13022\n\n\nStreeter Dr & Grand Ave\n\n\n41.772\n\n\n41.969\n\n\n41.892\n\n\n−87.785\n\n\n−87.586\n\n\n−87.612\n\n\n\n\n13028\n\n\n900 W Harrison St\n\n\n41.836\n\n\n41.881\n\n\n41.875\n\n\n−87.679\n\n\n−87.607\n\n\n−87.65\n\n\n\n\n\n[ omitted 1,063 entries ]\n\n\n\n\nCleaning the results:\nNotice we get a lot more entries in our stations: 1078 entries vs 693 entries in the filtered version.\nWhich entries are in stations but not in stations_clean ?\n\n(stations_diff <- stations[!stations_clean, on = .(id, name)])\ndata.table [417 x 8]\n\n\n\nid\n\n\nname\n\n\nlat_min\n\n\nlat_max\n\n\nlat_mean\n\n\nlng_min\n\n\nlng_max\n\n\nlng_mean\n\n\n\n\n\n021320\n\n\nMTV Hubbard St\n\n\n41.89\n\n\n41.89\n\n\n41.89\n\n\n−87.68\n\n\n−87.68\n\n\n−87.68\n\n\n\n\n20.0\n\n\nDamen Ave & Wabansia Ave\n\n\n41.91\n\n\n41.91\n\n\n41.91\n\n\n−87.68\n\n\n−87.68\n\n\n−87.68\n\n\n\n\n20126\n\n\nS Aberdeen St & W 106th St\n\n\n41.7\n\n\n41.7\n\n\n41.7\n\n\n−87.65\n\n\n−87.65\n\n\n−87.65\n\n\n\n\n20128\n\n\nS Wentworth Ave & W 111th St\n\n\n41.69\n\n\n41.69\n\n\n41.69\n\n\n−87.63\n\n\n−87.63\n\n\n−87.63\n\n\n\n\n20133\n\n\nWoodlawn & 103rd - Olive Harvey Vaccination Site\n\n\n41.71\n\n\n41.71\n\n\n41.71\n\n\n−87.59\n\n\n−87.59\n\n\n−87.59\n\n\n\n\n20134\n\n\nMaryland Ave & 104th St\n\n\n41.71\n\n\n41.71\n\n\n41.71\n\n\n−87.6\n\n\n−87.6\n\n\n−87.6\n\n\n\n\n20201\n\n\nKedzie Ave & 104th St\n\n\n41.7\n\n\n41.7\n\n\n41.7\n\n\n−87.7\n\n\n−87.7\n\n\n−87.7\n\n\n\n\n20202\n\n\nW 103rd St & S Avers Ave\n\n\n41.71\n\n\n41.71\n\n\n41.71\n\n\n−87.72\n\n\n−87.72\n\n\n−87.72\n\n\n\n\n20209\n\n\nS Michigan Ave & E 118th St\n\n\n41.68\n\n\n41.68\n\n\n41.68\n\n\n−87.62\n\n\n−87.62\n\n\n−87.62\n\n\n\n\n20220\n\n\nAvenue L & 114th St\n\n\n41.69\n\n\n41.69\n\n\n41.69\n\n\n−87.54\n\n\n−87.54\n\n\n−87.54\n\n\n\n\n20240\n\n\nIndiana Ave & 133rd St\n\n\n41.65\n\n\n41.65\n\n\n41.65\n\n\n−87.62\n\n\n−87.62\n\n\n−87.62\n\n\n\n\n20241\n\n\nSteelworkers Park\n\n\n41.74\n\n\n41.74\n\n\n41.74\n\n\n−87.53\n\n\n−87.53\n\n\n−87.53\n\n\n\n\n20246.0\n\n\nN Green St & W Lake St\n\n\n41.89\n\n\n41.89\n\n\n41.89\n\n\n−87.65\n\n\n−87.65\n\n\n−87.65\n\n\n\n\n20247.0\n\n\nW Washington Blvd & N Peoria St\n\n\n41.88\n\n\n41.88\n\n\n41.88\n\n\n−87.65\n\n\n−87.65\n\n\n−87.65\n\n\n\n\n202480.0\n\n\nHampden Ct & Diversey Ave\n\n\n41.93\n\n\n41.93\n\n\n41.93\n\n\n−87.64\n\n\n−87.64\n\n\n−87.64\n\n\n\n\n\n[ omitted 402 entries ]\n\n\n\n\nAnd which of those 417 entries have the necessary coordinate precision to be used later on to match against the unknown stations ?\n\nstations_diff[stations_diff[, Reduce(`&`, lapply(.SD, decp)), .SDcols = patterns(\"^lat|^lng\")]]\ndata.table [0 x 8]\n\n\n\nid\n\n\nname\n\n\nlat_min\n\n\nlat_max\n\n\nlat_mean\n\n\nlng_min\n\n\nlng_max\n\n\nlng_mean\n\n\n\n\n\nAs expected, none. But we’re still going to do the matching, for posterity !\n\n4.2.2 Position-matching on stations\n\nTo save time, let’s only apply the procedure to the entries that actually need to be matched (i.e. the ones having coordinates but missing either name or id):\n\n\nfuzzyjoin\nSQL (DuckDB)\n\n\n\nThere are 1,696,469 entries from rides_l that could be position-matched to a known station.\n\nmatched <- (fuzzyjoin::geo_inner_join(\n    as.data.frame(rides_l_unk),\n    as.data.frame(stations),\n    by = c(\"lng\" = \"lng_mean\", \"lat\" = \"lat_mean\"),\n    method = \"haversine\",\n    unit = \"km\",\n    max_dist = 0.011, # 11 meters\n    distance_col = \"dist\"\n  ) \n  |> mutate(name = coalesce(name.x, name.y), id = coalesce(id.x, id.y)) \n  |> select(colnames(rides_l), dist)\n  |> arrange(ride_id)\n  |> drop_na(ride_id, id, name)\n  |> as.data.table()\n  |> setkey(ride_id, id)\n)\n\n\n\nTime difference of 2.174 secs\n\n\n\n\nThere are 1,696,469 entries from rides_l that could be position-matched to a known station.\n\nSELECT\n  ride_id, rideable_type, started_at, ended_at, member_casual, way  \n  , COALESCE(r.name, s.name) AS name\n  , COALESCE(r.id, s.id) AS id\n  , r.lat, r.lng\n  , haversine(s.lat_mean, s.lng_mean, r.lat, r.lng) AS dist\nFROM rides_l_unk r, stations s\nWHERE dist <= 0.011\n\n\n\nTime difference of 9.689 secs\n\n\n\n\n\n\n\ndata.table [939,829 x 11]\n\n\n\nride_id\n\n\nrideable_type\n\n\nstarted_at\n\n\nended_at\n\n\nmember_casual\n\n\nway\n\n\nname\n\n\nid\n\n\nlat\n\n\nlng\n\n\ndist\n\n\n\n\n\n00000B4F1F71F9C2\n\n\nelectric_bike\n\n\n2021-09-08 16:31:38\n\n\n2021-09-08 16:37:54\n\n\nmember\n\n\nend\n\n\nFrancisco Ave & Bloomingdale Ave\n\n\n429\n\n\n41.91\n\n\n−87.7\n\n\n0\n\n\n\n\n000025C113FEB7B6\n\n\nelectric_bike\n\n\n2021-10-25 11:15:21\n\n\n2021-10-25 11:20:21\n\n\nmember\n\n\nstart\n\n\nPrairie Ave & 47th St - midblock\n\n\n814\n\n\n41.81\n\n\n−87.62\n\n\n0\n\n\n\n\n000025C113FEB7B6\n\n\nelectric_bike\n\n\n2021-10-25 11:15:21\n\n\n2021-10-25 11:20:21\n\n\nmember\n\n\nend\n\n\nPrairie Ave & 47th St - midblock\n\n\n814\n\n\n41.81\n\n\n−87.62\n\n\n0\n\n\n\n\n000025C113FEB7B6\n\n\nelectric_bike\n\n\n2021-10-25 11:15:21\n\n\n2021-10-25 11:20:21\n\n\nmember\n\n\nstart\n\n\nMartin Luther King Dr & 44th St\n\n\n914\n\n\n41.81\n\n\n−87.62\n\n\n0\n\n\n\n\n000025C113FEB7B6\n\n\nelectric_bike\n\n\n2021-10-25 11:15:21\n\n\n2021-10-25 11:20:21\n\n\nmember\n\n\nend\n\n\nMartin Luther King Dr & 44th St\n\n\n914\n\n\n41.81\n\n\n−87.62\n\n\n0\n\n\n\n\n000043B681BFB305\n\n\nelectric_bike\n\n\n2021-10-14 16:24:41\n\n\n2021-10-14 16:29:02\n\n\ncasual\n\n\nend\n\n\nCalifornia Ave & Cortez St\n\n\n512\n\n\n41.9\n\n\n−87.7\n\n\n0\n\n\n\n\n00009A0299026096\n\n\nelectric_bike\n\n\n2021-07-04 17:10:35\n\n\n2021-07-04 17:21:29\n\n\ncasual\n\n\nstart\n\n\nLake Park Ave & 44th St\n\n\n787\n\n\n41.81\n\n\n−87.6\n\n\n0\n\n\n\n\n00009F76371B5B23\n\n\nelectric_bike\n\n\n2021-12-12 14:10:54\n\n\n2021-12-12 14:42:44\n\n\nmember\n\n\nend\n\n\nDamen Ave & Wabansia Ave\n\n\n20.0\n\n\n41.91\n\n\n−87.68\n\n\n0\n\n\n\n\n00009FC70913FC9F\n\n\nelectric_bike\n\n\n2021-11-09 15:02:41\n\n\n2021-11-09 15:07:55\n\n\ncasual\n\n\nend\n\n\nLincoln Ave & Balmoral Ave\n\n\n442\n\n\n41.98\n\n\n−87.69\n\n\n0\n\n\n\n\n0000D2CE5AF46802\n\n\nelectric_bike\n\n\n2021-10-21 17:41:43\n\n\n2021-10-21 17:58:18\n\n\nmember\n\n\nend\n\n\nElston Ave & George St\n\n\n472\n\n\n41.93\n\n\n−87.69\n\n\n0\n\n\n\n\n0000D8A70B8D59B7\n\n\nelectric_bike\n\n\n2021-06-23 18:28:49\n\n\n2021-06-23 19:08:40\n\n\ncasual\n\n\nstart\n\n\nParnell Ave & 103rd St\n\n\n605\n\n\n41.71\n\n\n−87.64\n\n\n0\n\n\n\n\n0000D8A70B8D59B7\n\n\nelectric_bike\n\n\n2021-06-23 18:28:49\n\n\n2021-06-23 19:08:40\n\n\ncasual\n\n\nend\n\n\nParnell Ave & 103rd St\n\n\n605\n\n\n41.71\n\n\n−87.64\n\n\n0\n\n\n\n\n0000D8A70B8D59B7\n\n\nelectric_bike\n\n\n2021-06-23 18:28:49\n\n\n2021-06-23 19:08:40\n\n\ncasual\n\n\nstart\n\n\nHalsted St & 102nd St\n\n\n623\n\n\n41.71\n\n\n−87.64\n\n\n0\n\n\n\n\n0000D8A70B8D59B7\n\n\nelectric_bike\n\n\n2021-06-23 18:28:49\n\n\n2021-06-23 19:08:40\n\n\ncasual\n\n\nend\n\n\nHalsted St & 102nd St\n\n\n623\n\n\n41.71\n\n\n−87.64\n\n\n0\n\n\n\n\n0000D8A70B8D59B7\n\n\nelectric_bike\n\n\n2021-06-23 18:28:49\n\n\n2021-06-23 19:08:40\n\n\ncasual\n\n\nstart\n\n\nGreen St & 103rd St\n\n\n878\n\n\n41.71\n\n\n−87.64\n\n\n0\n\n\n\n\n\n[ omitted 939,814 entries ]\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNotice how fast the procedure is, with close to 1 million matches (even if the results are mostly garbage).\n\n\nWhat’s inside those matches ?\n\nmatched[, .(`Number of matches for an entry` = .N), by = .(ride_id, way)\n      ][, .(`Number of times it happens` = .N), by = `Number of matches for an entry`]\ndata.table [5 x 2]\n\n\n\nNumber of matches for an entry\n\n\nNumber of times it happens\n\n\n\n\n\n1\n\n\n437 864\n\n\n\n\n2\n\n\n130 830\n\n\n\n\n3\n\n\n51 620\n\n\n\n\n4\n\n\n19 615\n\n\n\n\n5\n\n\n1 397\n\n\n\n\n\nWe can see that more than half of the matches are coordinates that matched 2 or more stations, which we should definitely not keep.\nBut, among the ones with only one match, how many have coordinates precise enough to make that match in the first place (i.e. have 4 or more decimals or precision) ?\n\nmatched[, if(.N == 1) .SD, by = .(ride_id, way)][decp(lat) & decp(lng)]\ndata.table [3 x 11]\n\n\n\nride_id\n\n\nway\n\n\nrideable_type\n\n\nstarted_at\n\n\nended_at\n\n\nmember_casual\n\n\nname\n\n\nid\n\n\nlat\n\n\nlng\n\n\ndist\n\n\n\n\n\n176105D1F8A1216B\n\n\nstart\n\n\nelectric_bike\n\n\n2021-07-18 03:44:22\n\n\n2021-07-18 04:12:23\n\n\ncasual\n\n\nWood St & Milwaukee Ave\n\n\n13221\n\n\n41.908\n\n\n−87.673\n\n\n0.002\n\n\n\n\nDE82A15026BA3056\n\n\nstart\n\n\nelectric_bike\n\n\n2021-09-21 18:18:59\n\n\n2021-09-21 18:21:48\n\n\ncasual\n\n\nHegewisch Metra Station\n\n\n20215\n\n\n41.648\n\n\n−87.546\n\n\n0.009\n\n\n\n\nEE197EDA4CF8CFE5\n\n\nstart\n\n\nelectric_bike\n\n\n2021-09-22 07:14:42\n\n\n2021-09-22 07:22:38\n\n\ncasual\n\n\nClinton St & Roosevelt Rd\n\n\nWL-008\n\n\n41.867\n\n\n−87.641\n\n\n0.001\n\n\n\n\n\nAs it turns out ? Only 3. And those are the same three matches we got from the filtered data.\nIn the end, those three are the only three position-based matches we should reasonably keep !"
  },
  {
    "objectID": "content/posts/spatial/index.html#merging-the-two-datasets",
    "href": "content/posts/spatial/index.html#merging-the-two-datasets",
    "title": "Fast spatial data matching in R",
    "section": "\n5.1 Merging the two datasets",
    "text": "5.1 Merging the two datasets\n\n\n\n\n\n\nNote\n\n\n\nWe can update the initial (cleaned) data with the position-matched in two ways:\n- A join + coalesce: join the two tables and merge the two name & id columns (new and old) together.\n- A rows_patch: only replace the missing values (name & id) by matching new and old rows together.\n\n\n\n5.1.1 join + coalesce\n\n\ndata.table\ndtplyr\nSQL (DuckDB)\n\n\n\n\nmatched_clean[rides_l_clean, on = setdiff(colnames(rides_l_clean), c(\"id\", \"name\"))\n            ][, let(name = fcoalesce(name, i.name), id = fcoalesce(id, i.id))\n            ][, nms, env = list(nms = I(colnames(rides_l_clean)))] -> rides_l_merged\n\n# setkey(rides_l_merged, ride_id, id)\n\n\n\nTime difference of 5.703 secs\n\n\n\n\n\n(right_join(\n    matched_clean,\n    rides_l_clean,\n    by = setdiff(colnames(rides_l_clean), c(\"id\", \"name\"))\n  ) \n  |> mutate(name = coalesce(name.x, name.y), id = coalesce(id.x, id.y))\n  |> select(-matches(\"\\\\.x|\\\\.y\"), -dist)\n  |> as.data.table()\n  # |> setkey(ride_id, id)\n)\n\n\n\nTime difference of 9.987 secs\n\n\n\n\n\nCREATE TABLE rides_l_merged AS\nSELECT \n  ride_id, rideable_type, started_at, ended_at, member_casual, way,\n  COALESCE(id_x, id_y) AS id,\n  COALESCE(name_x, name_y) AS name,\n  lat, lng\nFROM (\n  SELECT\n    r.ride_id AS ride_id,\n    r.rideable_type AS rideable_type,\n    r.started_at AS started_at,\n    r.ended_at AS ended_at,\n    r.member_casual AS member_casual,\n    r.way AS way,\n    m.name AS name_x,\n    m.id AS id_x,\n    r.lat AS lat,\n    r.lng AS lng,\n    r.name AS name_y,\n    r.id AS id_y\n  FROM matched_clean AS m\n  RIGHT JOIN rides_l_clean AS r\n  ON m.ride_id = r.ride_id \n     AND m.rideable_type = r.rideable_type \n     AND m.started_at = r.started_at\n     AND m.ended_at = r.ended_at\n     AND m.member_casual = r.member_casual\n     AND m.way = r.way\n);\n\n\n\nTime difference of 3.834 secs\n\n\n\n\n\n\n5.1.2 rows_patch\n\n\ndplyr\ndbplyr\n\n\n\n\nrows_patch(\n  as.data.frame(rides_l_clean),\n  as.data.frame(matched_clean) |> select(-dist),\n  by = setdiff(colnames(rides_l_clean), c(\"name\", \"id\")),\n  unmatched = \"ignore\"\n)\n\n\n\nTime difference of 4.783 secs\n\n\n\n\n\nrows_patch(\n  tbl(rides_con, \"rides_l_clean.dbp\"),\n  tbl(rides_con, \"matched_clean\") |> select(-dist),\n  by = tbl(rides_con, \"rides_l_clean.dbp\") |> select(-name, -id) |> colnames(),\n  unmatched = \"ignore\"\n) |> compute(\"rides_l_merged.rows_dbp\")\n\n\n\n\n\n\n\n\n\ndata.table [9,937,077 x 10]\n\n\n\nride_id\n\n\nrideable_type\n\n\nstarted_at\n\n\nended_at\n\n\nmember_casual\n\n\nway\n\n\nname\n\n\nid\n\n\nlat\n\n\nlng\n\n\n\n\n\n00000123F60251E6\n\n\nclassic_bike\n\n\n2022-02-07 15:47:40\n\n\n2022-02-07 15:49:28\n\n\nmember\n\n\nend\n\n\nKingsbury St & Kinzie St\n\n\nKA1503000043\n\n\n41.889\n\n\n−87.639\n\n\n\n\n00000123F60251E6\n\n\nclassic_bike\n\n\n2022-02-07 15:47:40\n\n\n2022-02-07 15:49:28\n\n\nmember\n\n\nstart\n\n\nWells St & Hubbard St\n\n\nTA1307000151\n\n\n41.89\n\n\n−87.634\n\n\n\n\n000002EBE159AE82\n\n\nelectric_bike\n\n\n2021-06-22 17:25:15\n\n\n2021-06-22 17:31:34\n\n\nmember\n\n\nend\n\n\nMilwaukee Ave & Grand Ave\n\n\n13033\n\n\n41.891\n\n\n−87.648\n\n\n\n\n000002EBE159AE82\n\n\nelectric_bike\n\n\n2021-06-22 17:25:15\n\n\n2021-06-22 17:31:34\n\n\nmember\n\n\nstart\n\n\nClinton St & Jackson Blvd\n\n\n638\n\n\n41.878\n\n\n−87.641\n\n\n\n\n0000080D43BAA9E4\n\n\nclassic_bike\n\n\n2021-08-29 15:38:05\n\n\n2021-08-29 16:24:03\n\n\ncasual\n\n\nstart\n\n\nDearborn St & Van Buren St\n\n\n624\n\n\n41.876\n\n\n−87.629\n\n\n\n\n0000080D43BAA9E4\n\n\nclassic_bike\n\n\n2021-08-29 15:38:05\n\n\n2021-08-29 16:24:03\n\n\ncasual\n\n\nend\n\n\nFederal St & Polk St\n\n\nSL-008\n\n\n41.872\n\n\n−87.63\n\n\n\n\n00000CAE95438C9D\n\n\nclassic_bike\n\n\n2021-07-20 15:40:46\n\n\n2021-07-20 17:38:17\n\n\ncasual\n\n\nstart\n\n\nStreeter Dr & Grand Ave\n\n\n13022\n\n\n41.892\n\n\n−87.612\n\n\n\n\n00000CAE95438C9D\n\n\nclassic_bike\n\n\n2021-07-20 15:40:46\n\n\n2021-07-20 17:38:17\n\n\ncasual\n\n\nend\n\n\nFairbanks Ct & Grand Ave\n\n\nTA1305000003\n\n\n41.892\n\n\n−87.621\n\n\n\n\n00000E22FBA89D81\n\n\nelectric_bike\n\n\n2022-05-19 14:42:55\n\n\n2022-05-19 14:54:03\n\n\nmember\n\n\nend\n\n\nClark St & Armitage Ave\n\n\n13146\n\n\n41.918\n\n\n−87.636\n\n\n\n\n00000EBBC119168C\n\n\nclassic_bike\n\n\n2021-10-31 11:30:37\n\n\n2021-10-31 11:39:27\n\n\nmember\n\n\nstart\n\n\nDorchester Ave & 49th St\n\n\nKA1503000069\n\n\n41.806\n\n\n−87.592\n\n\n\n\n00000EBBC119168C\n\n\nclassic_bike\n\n\n2021-10-31 11:30:37\n\n\n2021-10-31 11:39:27\n\n\nmember\n\n\nend\n\n\nKimbark Ave & 53rd St\n\n\nTA1309000037\n\n\n41.8\n\n\n−87.595\n\n\n\n\n000019B7F053D461\n\n\nclassic_bike\n\n\n2021-08-13 19:57:28\n\n\n2021-08-13 20:02:56\n\n\nmember\n\n\nstart\n\n\nLarrabee St & Webster Ave\n\n\n13193\n\n\n41.922\n\n\n−87.644\n\n\n\n\n000019B7F053D461\n\n\nclassic_bike\n\n\n2021-08-13 19:57:28\n\n\n2021-08-13 20:02:56\n\n\nmember\n\n\nend\n\n\nSheffield Ave & Webster Ave\n\n\nTA1309000033\n\n\n41.922\n\n\n−87.654\n\n\n\n\n00001B4F79D102B5\n\n\nclassic_bike\n\n\n2021-07-28 07:58:27\n\n\n2021-07-28 08:05:00\n\n\ncasual\n\n\nend\n\n\nBroadway & Waveland Ave\n\n\n13325\n\n\n41.949\n\n\n−87.649\n\n\n\n\n00001B4F79D102B5\n\n\nclassic_bike\n\n\n2021-07-28 07:58:27\n\n\n2021-07-28 08:05:00\n\n\ncasual\n\n\nstart\n\n\nDuSable Lake Shore Dr & Belmont Ave\n\n\nTA1309000049\n\n\n41.941\n\n\n−87.639\n\n\n\n\n\n[ omitted 9,937,062 entries ]"
  },
  {
    "objectID": "content/posts/spatial/index.html#validating-the-merge",
    "href": "content/posts/spatial/index.html#validating-the-merge",
    "title": "Fast spatial data matching in R",
    "section": "\n5.2 Validating the merge:",
    "text": "5.2 Validating the merge:\n\nrides_l_merged[(is.na(id) | is.na(name)) & (!is.na(lat) & !is.na(lng))]\ndata.table [0 x 10]\n\n\n\nride_id\n\n\nrideable_type\n\n\nstarted_at\n\n\nended_at\n\n\nmember_casual\n\n\nway\n\n\nname\n\n\nid\n\n\nlat\n\n\nlng\n\n\n\n\n\nWe can see that the resulting dataset no longer has any entries that have coordinates but miss a name or an id, whereas there were three before. We have successfully updated them !"
  },
  {
    "objectID": "content/posts/spatial/index.html#pivoting-back-to-the-original-wide-format",
    "href": "content/posts/spatial/index.html#pivoting-back-to-the-original-wide-format",
    "title": "Fast spatial data matching in R",
    "section": "\n5.3 Pivoting back to the original (wide) format",
    "text": "5.3 Pivoting back to the original (wide) format\nTo finish, let’s pivot the resulting data back into the wider format it was originally in:\n\n\ndata.table\ndtplyr\nSQL (DuckDB)\ndbplyr\n\n\n\n\nrides_merged <- dcast(\n  rides_l_merged, ... ~ way, sep = \"_station_\",\n  value.var = c(\"name\", \"id\", \"lat\", \"lng\")\n)\n\n\n\nTime difference of 9.059 secs\n\n\n\n\n\npivot_wider(\n  rides_l_merged, names_from = \"way\", names_glue = \"{way}_station_{.value}\",\n  values_from = c(\"name\", \"id\", \"lat\", \"lng\")\n) |> as.data.table()\n\n\n\nTime difference of 12.39 secs\n\n\n\n\n\nCREATE TABLE rides_merged AS\nSELECT\n  ride_id, rideable_type, started_at, ended_at, member_casual,\n  MAX(CASE WHEN (way = 'start') THEN name END) AS start_station_name,\n  MAX(CASE WHEN (way = 'end') THEN name END) AS end_station_name,\n  MAX(CASE WHEN (way = 'start') THEN id END) AS start_station_id,\n  MAX(CASE WHEN (way = 'end') THEN id END) AS end_station_id,\n  MAX(CASE WHEN (way = 'start') THEN lat END) AS start_lat,\n  MAX(CASE WHEN (way = 'end') THEN lat END) AS end_lat,\n  MAX(CASE WHEN (way = 'start') THEN lng END) AS start_lng,\n  MAX(CASE WHEN (way = 'end') THEN lng END) AS end_lng\nFROM rides_l_merged\nGROUP BY ride_id, rideable_type, started_at, ended_at, member_casual\n\n\n\nTime difference of 7.599 secs\n\n\n\n\n\npivot_wider(\n  tbl(rides_con, \"rides_l_merged\"), names_from = \"way\", \n  names_glue = \"{way}_station_{.value}\", values_from = c(\"name\", \"id\", \"lat\", \"lng\")\n) |> compute(\"rides_merged.dbp\")\n\n\n\nTime difference of 7.744 secs\n\n\n\n\n\n\n\ndata.table [5,316,218 x 13]\n\n\n\nride_id\n\n\nrideable_type\n\n\nstarted_at\n\n\nended_at\n\n\nmember_casual\n\n\nname_station_end\n\n\nname_station_start\n\n\nid_station_end\n\n\nid_station_start\n\n\nlat_station_end\n\n\nlat_station_start\n\n\nlng_station_end\n\n\nlng_station_start\n\n\n\n\n\n00000123F60251E6\n\n\nclassic_bike\n\n\n2022-02-07 15:47:40\n\n\n2022-02-07 15:49:28\n\n\nmember\n\n\nKingsbury St & Kinzie St\n\n\nWells St & Hubbard St\n\n\nKA1503000043\n\n\nTA1307000151\n\n\n41.889\n\n\n41.89\n\n\n−87.639\n\n\n−87.634\n\n\n\n\n000002EBE159AE82\n\n\nelectric_bike\n\n\n2021-06-22 17:25:15\n\n\n2021-06-22 17:31:34\n\n\nmember\n\n\nMilwaukee Ave & Grand Ave\n\n\nClinton St & Jackson Blvd\n\n\n13033\n\n\n638\n\n\n41.891\n\n\n41.878\n\n\n−87.648\n\n\n−87.641\n\n\n\n\n0000080D43BAA9E4\n\n\nclassic_bike\n\n\n2021-08-29 15:38:05\n\n\n2021-08-29 16:24:03\n\n\ncasual\n\n\nFederal St & Polk St\n\n\nDearborn St & Van Buren St\n\n\nSL-008\n\n\n624\n\n\n41.872\n\n\n41.876\n\n\n−87.63\n\n\n−87.629\n\n\n\n\n00000CAE95438C9D\n\n\nclassic_bike\n\n\n2021-07-20 15:40:46\n\n\n2021-07-20 17:38:17\n\n\ncasual\n\n\nFairbanks Ct & Grand Ave\n\n\nStreeter Dr & Grand Ave\n\n\nTA1305000003\n\n\n13022\n\n\n41.892\n\n\n41.892\n\n\n−87.621\n\n\n−87.612\n\n\n\n\n00000E22FBA89D81\n\n\nelectric_bike\n\n\n2022-05-19 14:42:55\n\n\n2022-05-19 14:54:03\n\n\nmember\n\n\nClark St & Armitage Ave\n\n\nNA\n\n\n13146\n\n\nNA\n\n\n41.918\n\n\nNA\n\n\n−87.636\n\n\nNA\n\n\n\n\n00000EBBC119168C\n\n\nclassic_bike\n\n\n2021-10-31 11:30:37\n\n\n2021-10-31 11:39:27\n\n\nmember\n\n\nKimbark Ave & 53rd St\n\n\nDorchester Ave & 49th St\n\n\nTA1309000037\n\n\nKA1503000069\n\n\n41.8\n\n\n41.806\n\n\n−87.595\n\n\n−87.592\n\n\n\n\n000019B7F053D461\n\n\nclassic_bike\n\n\n2021-08-13 19:57:28\n\n\n2021-08-13 20:02:56\n\n\nmember\n\n\nSheffield Ave & Webster Ave\n\n\nLarrabee St & Webster Ave\n\n\nTA1309000033\n\n\n13193\n\n\n41.922\n\n\n41.922\n\n\n−87.654\n\n\n−87.644\n\n\n\n\n00001B4F79D102B5\n\n\nclassic_bike\n\n\n2021-07-28 07:58:27\n\n\n2021-07-28 08:05:00\n\n\ncasual\n\n\nBroadway & Waveland Ave\n\n\nDuSable Lake Shore Dr & Belmont Ave\n\n\n13325\n\n\nTA1309000049\n\n\n41.949\n\n\n41.941\n\n\n−87.649\n\n\n−87.639\n\n\n\n\n00001BEE76AB24E0\n\n\nelectric_bike\n\n\n2021-11-30 16:55:38\n\n\n2021-11-30 17:08:53\n\n\nmember\n\n\nAshland Ave & Division St\n\n\nDaley Center Plaza\n\n\n13061\n\n\nTA1306000010\n\n\n41.903\n\n\n41.884\n\n\n−87.668\n\n\n−87.629\n\n\n\n\n00001DCF2BC423F4\n\n\ndocked_bike\n\n\n2021-06-13 12:00:49\n\n\n2021-06-13 12:29:51\n\n\ncasual\n\n\nFort Dearborn Dr & 31st St\n\n\nMillennium Park\n\n\nTA1307000048\n\n\n13008\n\n\n41.839\n\n\n41.881\n\n\n−87.608\n\n\n−87.624\n\n\n\n\n000020C92AA9D6F7\n\n\nclassic_bike\n\n\n2021-09-12 09:53:00\n\n\n2021-09-12 10:12:52\n\n\ncasual\n\n\nDusable Harbor\n\n\nClark St & North Ave\n\n\nKA1503000064\n\n\n13128\n\n\n41.887\n\n\n41.912\n\n\n−87.613\n\n\n−87.632\n\n\n\n\n0000228A4B430869\n\n\nelectric_bike\n\n\n2021-10-18 10:42:20\n\n\n2021-10-18 10:47:58\n\n\nmember\n\n\nCalumet Ave & 18th St\n\n\nMLK Jr Dr & 29th St\n\n\n13102\n\n\nTA1307000139\n\n\n41.857\n\n\n41.842\n\n\n−87.619\n\n\n−87.617\n\n\n\n\n000022C3D3CE7DD5\n\n\nclassic_bike\n\n\n2022-04-30 09:57:39\n\n\n2022-04-30 10:03:12\n\n\ncasual\n\n\nSheffield Ave & Willow St\n\n\nHalsted St & Clybourn Ave\n\n\nTA1306000032\n\n\n331\n\n\n41.914\n\n\n41.91\n\n\n−87.653\n\n\n−87.648\n\n\n\n\n0000278F02EFFEF9\n\n\nclassic_bike\n\n\n2021-09-18 16:09:39\n\n\n2021-09-18 16:32:06\n\n\nmember\n\n\nMichigan Ave & Washington St\n\n\nBurnham Harbor\n\n\n13001\n\n\n15545\n\n\n41.884\n\n\n41.856\n\n\n−87.625\n\n\n−87.613\n\n\n\n\n000027C557F9372D\n\n\ndocked_bike\n\n\n2022-05-13 11:01:17\n\n\n2022-05-13 11:09:05\n\n\ncasual\n\n\nLincoln Ave & Roscoe St*\n\n\nAshland Ave & Belle Plaine Ave\n\n\nchargingstx5\n\n\n13249\n\n\n41.943\n\n\n41.956\n\n\n−87.671\n\n\n−87.669\n\n\n\n\n\n[ omitted 5,316,203 entries ]\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe get less entries than in the original (wide format) dataset due to having removed (filtered) the entries with bad coordinates."
  },
  {
    "objectID": "content/projects/ACCESSPACE/index.html#our-interface-the-tactibelt",
    "href": "content/projects/ACCESSPACE/index.html#our-interface-the-tactibelt",
    "title": "ACCESSPACE",
    "section": "2.1 Our interface: the TactiBelt",
    "text": "2.1 Our interface: the TactiBelt\nTo provide the proposed egocentric encoding scheme to the user, we designed a vibro-tactile belt, the TactiBelt: it comprises of 46 ERM motors spread into three layers, controlled by an Arduino Mega, through a specialized software written in Java:\n\n\n\nFigure 2: First prototype of the TactiBelt"
  },
  {
    "objectID": "content/projects/ACCESSPACE/index.html#software-tools",
    "href": "content/projects/ACCESSPACE/index.html#software-tools",
    "title": "ACCESSPACE",
    "section": "2.2 Software tools",
    "text": "2.2 Software tools\nTo capture and extract the information we need from the VIP’s environment, we devised a series of software tools relying mostly on Computer Vision:\n1) Obstacle detection and indoor localisation using the ORB-SLAM algorithm:\n\n\n\n\n\n2) Depth estimation from a monocular RGB camera, using the MonoDepth algorithm:\n\n\n\n\n\n3) Generating a mobility graph of the environment during movement using Reinforcement Learning:\nApplied to an artificial agent exploring a virtual maze, looking for food:\n\n\n\n\n\nApplied to a real agent (human pushing a cart with a camera and the computer running the algorithm around a meeting table):\n\n\n\n\n\n4) A virtual environment to test the TactiBelt and our candidate spatial encoding schemes:"
  },
  {
    "objectID": "content/projects/ACCESSPACE/index.html#project-dissemination",
    "href": "content/projects/ACCESSPACE/index.html#project-dissemination",
    "title": "ACCESSPACE",
    "section": "2.3 Project dissemination",
    "text": "2.3 Project dissemination\nThe ACCESSPACE project was promoted in various mainstream and technical media, such as:\n- On RTL, a French national radio station ()\n- On PhDTalent, a platform and network for PhD Students who wish to transition to industry ()\n- On Guide Néret, a specialized website on Handicap in France ()\n- On Acuité, a specialized website dedicated to Opticians and news around visual impairment ()\n- On Oxytude, a weekly podcast reviewing news related to visual impairment ()\n- On FIRAH, the French Foundation on Applied Research for Handicap ()\nThis project has been warmly welcomed by the VIP community and was awarded the “Applied research on disability” award from the CCAH in 2017 🥇."
  },
  {
    "objectID": "content/projects/AdViS/index.html",
    "href": "content/projects/AdViS/index.html",
    "title": "AdViS",
    "section": "",
    "text": "1 Introduction\n\nAdViS aims to explore various ways to provide visuo-spatial information through auditory feedback, based on the Sensory Substitution framework. Since its inception, the project investigated visuo-auditive substitution possibilities for multiple tasks in which vision plays a crucial role:\n\nNavigating a small maze using a depth-map-to-auditory-cues transcoding\n\nFinger-guided image exploration (on a touch screen)\n\nEye-movement guided image exploration (on a turned off computer screen)\n\nPointing towards and reaching a virtual target in 3D space using a motion capture environment\n\n\n\n\n\n\nAdViS - Depth Map navigation\n\n\n\n\n\nAdViS - Motion Capture\n\n\n\n\nThe AdViS platform is coded in C++ (and Qt for the GUI). It currently uses PureData for complex sound generation, and the VICON system to track participant’s movements in an augmented reality environment.\n\n\n2 My role in this project\n\n1) Propose a new model for image exploration using a touch-to-audio-feedback loop, where a VIP explores an image by moving its finger across it and gets auditive feedback from the explored regions and its surroundings.\n2) Modify the existing AdViS code to include the ability to transcode grey-scale images into soundscapes, and to capture finger movements information on a touchscreen.\n3) Organize experimental evaluations with blindfolded students, tasked with recognizing geometrical shapes on a touchscreen, and analyse the results.\n\n\n\n\n\n4) Participate in implementing an eye-tracking-to-audio-feedback loop in order to evaluate the possibility of exploring images (on a turned off screen) with eye-movements (which are still controllable by most of the non-congenital VIP)."
  },
  {
    "objectID": "content/projects/CamIO/index.html",
    "href": "content/projects/CamIO/index.html",
    "title": "CamIO",
    "section": "",
    "text": "1 Introduction\n\n\n\n\n2 My role in this project\n\n1) Explore new solutions to improve the localisation & tracking capabilities of CamIO:\nTheir existing solution, iLocalize (Fusco & Coughlan, 2018) (Swift / iOS), used a combination of Visuo-Inertial Odometry (VIO) through Apple’s ARKit, particle filtering based on a simplified map of the environment, and drift-correction through visual identification of known landmarks (using a gradient boosting algorithm).\n\n\n\n\n\nI developed a web app to send the live camera stream from a mobile phone (JavaScript / socket.io) to a backend server (Python / Flask). The goal of the application was to facilitate the exploration of new Computer Vision algorithms to process the captured video and IMU data, which would send back location or navigational information.\nI also explored existing 3rd-party services for indoor localization, such as Indoor Atlas (which combines VIO, GPS data, WiFi & geomagnetic fingerprinting, dead-reckoning, and barometric readings for altitude changes), for which I made a small demo.\n\n\n\n\n\n\n(a) Indoor Atlas’ localization\n\n\n\n\n\n(b) Indoor Atlas’ navigation graph\n\n\n\nFigure 1: Indoor Atlas\n\n\n2) Assist in writing a scientific paper presenting the project.\n\n\n\n\nReferences\n\nFusco, G., & Coughlan, J. M. (2018). Indoor localization using computer vision and visual-inertial odometry (pp. 86–93). Springer International Publishing. https://doi.org/10.1007/978-3-319-94274-2_13"
  },
  {
    "objectID": "content/projects/DE-AoP/index.html",
    "href": "content/projects/DE-AoP/index.html",
    "title": "DE-AoP",
    "section": "",
    "text": "1 My role in this project\n\n1) Develop tools to assist the project’s researchers exploration of the collected data. To this end, I developed a modular Shiny dashboard to assist in the data exploration process.\n2) Handle the RT-qPCR data processing and analysis.\n3) Participate in writing the final scientific paper resulting from this project (ongoing)."
  },
  {
    "objectID": "content/projects/LT-AoP/index.html",
    "href": "content/projects/LT-AoP/index.html",
    "title": "LT-AoP",
    "section": "",
    "text": "1 My role in this project\n\n1) Handle the data processing and analysis, for both immunohistochemistry and RT-qPCR data. The code for those analyses was made open-source and registered on Zenodo, while the results of the analyses were published in Cell & Bioscience.\n2) Make a website documenting and showcasing the project’s data, analyses, and results. The website uses Quarto and relies on templates to automatically generates documentation for each of the ~70 variables analyzed during the project.\n\n\nClick to see a preview of a page of the documentation"
  },
  {
    "objectID": "content/projects/NAV-VIR/index.html#our-interface-f2t-v2",
    "href": "content/projects/NAV-VIR/index.html#our-interface-f2t-v2",
    "title": "NAV-VIR",
    "section": "1.1 Our interface: F2T (v2)",
    "text": "1.1 Our interface: F2T (v2)\nDuring this project, we improved upon the first iteration of the Force Feedback Tablet (F2T) from the TETMOST project to design the finalized prototype of this interface:"
  },
  {
    "objectID": "content/projects/SAM-Guide/index.html",
    "href": "content/projects/SAM-Guide/index.html",
    "title": "SAM-Guide",
    "section": "",
    "text": "1 Introduction\n\n\nInteracting with space is a constant challenge for Visually Impaired People (VIP) since spatial information in Humans is typically provided by vision. Sensory Substitution Devices (SSDs) have been promising Human-Machine Interfaces (HMI) to assist VIP. They re-code missing visual information as stimuli for other sensory channels. Our project redirects somehow from SSD’s initial ambition for a single universal integrated device that would replace the whole sense organ, towards common encoding schemes for multiple applications.\nSAM-Guide will search for the most natural way to give online access to geometric variables that are necessary to achieve a range of tasks without eyes. Defining such encoding schemes requires selecting a crucial set of geometrical variables, and building efficient and comfortable auditory and/or tactile signals to represent them. We propose to concentrate on action-perception loops representing target-reaching affordances, where spatial properties are defined as ego-centered deviations from selected beacons.\nThe same grammar of cues could better help VIP to get autonomy along with a range of vital or leisure activities. Among such activities, the consortium has advances in orienting and navigating, object locating and reaching, laser shooting. Based on current neurocognitive models of human action-perception and spatial cognition, the design of the encoding schemes will lay on common theoretical principles: parsimony (minimum yet sufficient information for a task), congruency (leverage existing sensorimotor control laws), and multimodality (redundant or complementary signals across modalities). To ensure an efficient collaboration all partners will develop and evaluate their transcoding schemes based on common principles, methodology, and tools. An inclusive user-centered “living-lab” approach will ensure constant adequacy of our solutions with VIP’s needs.\nFive labs (three campuses) comprising ergonomists, neuroscientists, engineers, and mathematicians, united by their interest and experience with designing assistive devices for VIP, will duplicate, combine and share their pre-existing SSDs prototypes: a vibrotactile navigation belt, an audio-spatialized virtual guide for jogging, and an object-reaching sonic pointer. Using those prototypes, they will iteratively evaluate and improve their transcoding schemes in a 3-phase approach: First, in controlled experimental settings through augmented-reality serious games in motion capture (virtual prototyping indeed facilitates the creation of ad-hoc environments, and gaming eases the participants’ engagement). Next, spatial interaction subtasks will be progressively combined and tested in wider and more ecological indoor and outdoor environments. Finally, SAM-Guide’s system will be fully transitioned to real-world conditions through a friendly sporting event of laser-run, a novel handi-sport, which will involve each subtask.\nSAM-Guide will develop action-perception and spatial cognition theories relevant to nonvisual interfaces. It will provide guidelines for the efficient representation of spatial interactions to facilitate the emergence of spatial awareness in a task-oriented perspective. Our portable modular transcoding libraries are independent of hardware consideration. The principled experimental platform offered by AR games will be a tool for evaluating VIP spatial cognition, and novel strategies for mobility training.\n\n\n\n\n2 My role in this project\n\n1) I was the driving force behind the genesis of this project. I connected the consortium members together and wrote most of the grant proposal (ANR AAPG 2021, funding of 609k€). This project will last 4 years and allow the recruitment of 2 PhD students, one post-doc, and one Research Engineer.\n2) Participated in the Data Management plan creation (compliance to the GPDR).\n3) Designed and participated in the development of the second prototype of the TactiBelt, which features wireless communication and amovible vibrators:\n\n\n\nFigure 1: Second prototype of the TactiBelt\n\n\n4) Lead the design and development of the project’s experimental platform (choice of tools, lead developer). The platform uses Unity, connects to various motion tracking devices used by the consortium (Polhemus, VICON, pozyx), uses PureData for sound-wave generation, uses Steam Audio for 3D audio modeling, and communicates to the TactiBelt wirelessly using the OSC protocol.\n\n\n\n\n\n\n(a) Testing environment with a PureData audio beacon\n\n\n\n \n\n\n\n\n(b) Auto-generated maze with 3D audio beacons on waypoints\n\n\n\nFigure 2: Screenshots from SAM-Guide’s experimental platform (in development)\n\n\nThis platform allows one to easily spin up experimental trials by specifying the desired characteristics in a JSON file (based on the OpenMaze project). Unity will automatically generate the trial’s environment according to those specifications and populate it with the relevant items (e.g. a tactile-signal emitting beacon signalling a target to reach in a maze), handle the transition between successive trials and blocks of trials, and log all the relevant user metrics into a data file.\n\n\n\n\n\n\n(a) Specifying the avatar and the experimental blocks’ characteristics\n\n\n\n \n\n\n\n\n(b) Specifying experimental trials, which can be repeated and randomized within blocks\n\n\n\nFigure 3: Examples of settings used to generate experimental trials on the fly.\n\n\n5) Handling the experimental design of the first wave of experiments (ongoing)."
  },
  {
    "objectID": "content/projects/TETMOST/index.html#exploring-existing-haptic-interfaces",
    "href": "content/projects/TETMOST/index.html#exploring-existing-haptic-interfaces",
    "title": "TETMOST",
    "section": "1.1 Exploring existing haptic interfaces",
    "text": "1.1 Exploring existing haptic interfaces\nWe researched and tried different categories of haptic interfaces in order to asses their strengths and weaknesses for our purposes:\n\n\n\n\n\n\n(a) Taxel mechanical interfaces\n\n\n\n\n\n(b) Electro-friction interfaces\n\n\n\n\n\n(c) Vibrational interfaces\n\n\n\nFigure 1: The three main categories of haptic interfaces\n\n\nOur experience with the existing categories of haptic interfaces allowed us to designed one best adapted to our need: the Force-Feedback Tablet (F2T)"
  },
  {
    "objectID": "content/projects/TETMOST/index.html#our-interface-f2t-v1",
    "href": "content/projects/TETMOST/index.html#our-interface-f2t-v1",
    "title": "TETMOST",
    "section": "2.1 Our interface: F2T (v1)",
    "text": "2.1 Our interface: F2T (v1)\nThe first prototype of the F2T was assembled with legos and a camera to better asses the position of the joystick within the frame of the device."
  },
  {
    "objectID": "content/projects/TETMOST/index.html#software-tools",
    "href": "content/projects/TETMOST/index.html#software-tools",
    "title": "TETMOST",
    "section": "2.2 Software tools",
    "text": "2.2 Software tools\n1) We developed a Java application to create or convert images into simplified tactile representations, which can then be explored using the F2T:\n\n\n\n\n\n2) In order to display an image haptically, we first needed a way to simplify the image’s content without losing its meaning. To do so, we explored various Computer Vision techniques such as image segmentation and edge detection:"
  },
  {
    "objectID": "content/projects/index.html",
    "href": "content/projects/index.html",
    "title": " Past & Current Projects",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nSAM-Guide\n\n\nSpatial Awareness for Multimodal Guidance\n\n\n\n\nAssistive Devices\n\n\nAccessibility\n\n\nVisual Impairment\n\n\nAugmented Reality\n\n\nSensory Substitution\n\n\nAuditory Interface\n\n\nHaptic Interface\n\n\nComputer Vision\n\n\n\n\nDesigning an efficient multi-modal interface to help VIP during spatial interactions and sports.\n\n\n\n\n\n\nANR PRC (AAPG 2021)\n\n\n\n\n\n\n  \n\n\n\n\nDE-AoP\n\n\nDevelopmental effects of Apnea of Prematurity\n\n\n\n\nBiostatistics\n\n\nTranscriptomics\n\n\nData Science\n\n\nCerebellum\n\n\nHypoxia\n\n\nRT-qPCR\n\n\n\n\nThis project studies the underlying molecular and cellular mechanisms of apnea of prematurity at play during cerebellar development, using intermittent hypoxia in a mouse model.\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nNAV-VIR\n\n\nVirtual Map exploration for Visually Impaired People\n\n\n\n\nAssistive Devices\n\n\nAccessibility\n\n\nVisual Impairment\n\n\nVirtual Reality\n\n\nSensory Substitution\n\n\nHaptic Interface\n\n\nAuditory Interface\n\n\n\n\nDeveloping a multi-modal interface for Visually Impaired People to virtually explore a map in order to prepare for a journey.\n\n\n\n\n\n\nPHC Polonium (French-Polish EU grant)\n\n\n\n\n\n\n  \n\n\n\n\nCamIO\n\n\nCamera Input-Output\n\n\n\n\nAssistive Devices\n\n\nAccessibility\n\n\nVisual Impairment\n\n\nAugmented Reality\n\n\nSensory Substitution\n\n\nAuditory Interface\n\n\nComputer Vision\n\n\n\n\nSmart pen providing real-time audio-feedback on objects using the smartphone’s sensors.\n\n\n\n\n\n\nNIH/NEI & NIDILRR RERC\n\n\n\n\n\n\n  \n\n\n\n\nTETMOST\n\n\nMaking Art more accessible to Visually Impaired People\n\n\n\n\nAssistive Devices\n\n\nAccessibility\n\n\nVisual Impairment\n\n\nVirtual Reality\n\n\nSensory Substitution\n\n\nHaptic Interface\n\n\n\n\nDevelopping a haptic interface and studying ways to intuitively represent images and Art pieces haptically for Visually Impaired People.\n\n\n\n\n\n\nAUTON (CNRS)\n\n\n\n\n\n\n  \n\n\n\n\nACCESSPACE\n\n\nHelping Visually Impaired People travel autonomously\n\n\n\n\nAssistive Devices\n\n\nAccessibility\n\n\nVisual Impairment\n\n\nAugmented Reality\n\n\nSensory Substitution\n\n\nHaptic Interface\n\n\nComputer Vision\n\n\n\n\nDeveloping a wearable vibro-tactile electronic Orientation & Travel Aid for the autonomous navigation of VIP, based on Spatial Cognition models.\n\n\n\n\n\n\nCCAH & FIRAH\n\n\n\n\n\n\n  \n\n\n\n\nLT-AoP\n\n\nLong Term effects of Apnea of Prematurity\n\n\n\n\nBiostatistics\n\n\nTranscriptomics\n\n\nData Science\n\n\nCerebellum\n\n\nHypoxia\n\n\nRT-qPCR\n\n\n\n\nThis project studied the impact of apnea of prematurity on cerebellar development and the long-term functional deficits resulting from it, using intermittent hypoxia in a mouse model.\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nAdViS\n\n\nAdaptative Visual Substitution\n\n\n\n\nAssistive Devices\n\n\nAccessibility\n\n\nVisual Impairment\n\n\nAugmented Reality\n\n\nSensory Substitution\n\n\nAuditory Interface\n\n\nComputer Vision\n\n\n\n\nDeveloping a wearable visuo-auditive substitution system to assist Visually Impaired People in navigation and object-reaching tasks.\n\n\n\n\n\n\nAUTON (CNRS) & LabEx PERSYVAL (PIA)\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "content/pubs/ICCHP18-F2T/index.html",
    "href": "content/pubs/ICCHP18-F2T/index.html",
    "title": "Towards Haptic Surface Devices with Force Feedback for Visually Impaired People",
    "section": "",
    "text": "Link to the PDF\n\n\n\n\nCitationBibTeX citation:@inproceedings{gay2018,\n  author = {Simon Gay and Marc-Aurèle Rivière and Edwige Pissaloux},\n  editor = {Miesenberger Klaus and Kouroupetroglou Georgios},\n  publisher = {Springer International Publishing},\n  title = {Towards {Haptic} {Surface} {Devices} with {Force} {Feedback}\n    for {Visually} {Impaired} {People}},\n  booktitle = {Lecture Notes in Computer Science},\n  volume = {10897},\n  pages = {258-266},\n  date = {2018-07-12},\n  url = {http://link.springer.com/10.1007/978-3-319-94274-2_36},\n  doi = {10.1007/978-3-319-94274-2_36},\n  isbn = {978-3-319-94273-5 978-3-319-94274-2},\n  langid = {en},\n  abstract = {This paper presents a new haptic surface tablet that can\n    provide force feedback to the user. Force feedback means that the\n    device can react to the user’s movements and apply a force against\n    or in-line with these movements, according to the tactile properties\n    of a displayed image. The device consists of a frame attached to a\n    tactile tablet that generates a force feedback to user’s finger when\n    exploring the surface, providing haptic informations about the\n    displayed image. The experimental results suggest the relevance of\n    this tablet as an assistive device for visually impaired people in\n    perceiving and understanding the content of a displayed image.\n    Several potential applications are briefly presented.}\n}\nFor attribution, please cite this work as:\nSimon Gay, Marc-Aurèle Rivière, & Edwige Pissaloux. (2018). Towards\nHaptic Surface Devices with Force Feedback for Visually Impaired People.\nIn Miesenberger Klaus & Kouroupetroglou Georgios (Eds.), Lecture\nNotes in Computer Science (Vol. 10897, pp. 258–266). Springer\nInternational Publishing. https://doi.org/10.1007/978-3-319-94274-2_36"
  },
  {
    "objectID": "content/pubs/ICCHP18-TactiBelt/index.html",
    "href": "content/pubs/ICCHP18-TactiBelt/index.html",
    "title": "TactiBelt: integrating spatial cognition and mobility theories into the design of a novel orientation and mobility assistive device for the blind",
    "section": "",
    "text": "Link to the PDF\n\n\n\n\nCitationBibTeX citation:@inproceedings{rivière2018,\n  author = {Marc-Aurèle Rivière and Simon Gay and Edwige Pissaloux},\n  editor = {Miesenberger Klaus and Kouroupetroglou Georgios},\n  publisher = {Springer International Publishing},\n  title = {TactiBelt: Integrating Spatial Cognition and Mobility\n    Theories into the Design of a Novel Orientation and Mobility\n    Assistive Device for the Blind},\n  booktitle = {Lecture Notes in Computer Science},\n  volume = {10897},\n  pages = {110-113},\n  date = {2018-07-12},\n  url = {http://link.springer.com/10.1007/978-3-319-94274-2_16},\n  doi = {10.1007/978-3-319-94274-2_16},\n  isbn = {978-3-319-94273-5 978-3-319-94274-2},\n  langid = {en},\n  abstract = {The aim of this paper is to introduce a novel functional\n    design for an indoor and outdoor mobility assistive device for the\n    visually impaired, based on the theoretical frameworks of mobility\n    and spatial cognition. The originality of the proposed approach\n    comes from the integration of two main aspects of navigation,\n    locomotion and wayfinding. The cognitive theories which underpin the\n    design of the proposed sensory substitution device, called\n    TactiBelt, are identified and discussed in the framework of spatial\n    knowledge acquisition. The paper is organized as follows: section 1\n    gives a brief overview of the sensory substitution framework, while\n    sections 2 \\& 3 introduce the importance of navigation and spatial\n    cognition models for the design of mobility aids. Section 4 details\n    the functional design of the TactiBelt.}\n}\nFor attribution, please cite this work as:\nMarc-Aurèle Rivière, Simon Gay, & Edwige Pissaloux. (2018).\nTactiBelt: integrating spatial cognition and mobility theories into the\ndesign of a novel orientation and mobility assistive device for the\nblind. In Miesenberger Klaus & Kouroupetroglou Georgios (Eds.),\nLecture Notes in Computer Science (Vol. 10897, pp. 110–113).\nSpringer International Publishing. https://doi.org/10.1007/978-3-319-94274-2_16"
  },
  {
    "objectID": "content/pubs/ICCHP20/index.html",
    "href": "content/pubs/ICCHP20/index.html",
    "title": "An Audio-Based 3D Spatial Guidance AR System for Blind Users",
    "section": "",
    "text": "Link to the PDF (preprint)\n\n\n\n\nCitationBibTeX citation:@inproceedings{coughlan2020,\n  author = {James Coughlan and Brandon Biggs and Marc-Aurèle Rivière and\n    Huiying Shen},\n  editor = {Miesenberger Klaus and Manduchi Roberto and Covarrubias\n    Rodriguez Mario and Peňáz Petr},\n  publisher = {Springer International Publishing},\n  title = {An {Audio-Based} {3D} {Spatial} {Guidance} {AR} {System} for\n    {Blind} {Users}},\n  booktitle = {Lecture Notes in Computer Science},\n  volume = {12376},\n  pages = {475-484},\n  date = {2020-09-12},\n  url = {https://link.springer.com/chapter/10.1007/978-3-030-58796-3_55},\n  doi = {10.1007/978-3-030-58796-3_55},\n  isbn = {978-3-030-58795-6 978-3-030-58796-3},\n  langid = {en},\n  abstract = {Augmented reality (AR) has great potential for blind users\n    because it enables a range of applications that provide audio\n    information about specific locations or directions in the user’s\n    environment. For instance, the {[}CamIO{]}(/content/projects/CamIO)\n    (“Camera Input-Output”) AR app makes physical objects (such as\n    documents, maps, devices and 3D models) accessible to blind and\n    visually impaired persons by providing real-time audio feedback in\n    response to the location on an object that the user is touching\n    (using an inexpensive stylus). An important feature needed by blind\n    users of AR apps such as CamIO is a 3D spatial guidance feature that\n    provides real-time audio feedback to help the user find a desired\n    location on an object. We have devised a simple audio interface to\n    provide verbal guidance towards a target of interest in 3D. The\n    experiment we report with blind participants using this guidance\n    interface demonstrates the feasibility of the approach and its\n    benefit for helping users find locations of interest.}\n}\nFor attribution, please cite this work as:\nJames Coughlan, Brandon Biggs, Marc-Aurèle Rivière, & Huiying Shen.\n(2020). An Audio-Based 3D Spatial Guidance AR System for Blind Users. In\nMiesenberger Klaus, Manduchi Roberto, Covarrubias Rodriguez Mario, &\nPeňáz Petr (Eds.), Lecture Notes in Computer Science (Vol.\n12376, pp. 475–484). Springer International Publishing. https://doi.org/10.1007/978-3-030-58796-3_55"
  },
  {
    "objectID": "content/pubs/ICISP20/index.html",
    "href": "content/pubs/ICISP20/index.html",
    "title": "Towards the Tactile Discovery of Cultural Heritage with Multi-approach Segmentation",
    "section": "",
    "text": "Link to the PDF\n\n\n\n\nCitationBibTeX citation:@inproceedings{souradi2020,\n  author = {Ali Souradi and Christele Lecomte and Katerine Romeo and\n    Simon Gay and Marc-Aurèle Rivière and Abderrahim El Moataz and\n    Edwige Pissaloux},\n  editor = {Abderrahim El Moataz and Driss Mammass and Alamin Mansouri\n    and Fathallah Nouboud},\n  publisher = {Springer International Publishing},\n  title = {Towards the {Tactile} {Discovery} of {Cultural} {Heritage}\n    with {Multi-approach} {Segmentation}},\n  booktitle = {Lecture Notes in Computer Science},\n  volume = {12119},\n  pages = {14-23},\n  date = {2020-07-08},\n  url = {http://link.springer.com/10.1007/978-3-030-51935-3_2},\n  doi = {10.1007/978-3-030-51935-3_2},\n  isbn = {978-3-030-51934-6 978-3-030-51935-3},\n  langid = {en},\n  abstract = {This paper presents a new way to access visual information\n    in museums through tactile exploration, and related techniques to\n    efficiently transform visual data into tactile objects.\n    Accessibility to cultural heritage and artworks for people with\n    visual impairments requires the segmentation of images and paintings\n    to extract and classify their contents into meaningful elements\n    which can then be presented through a tactile medium. In this paper,\n    we investigate the feasibility and how to optimize the tactile\n    discovery of an image. First, we study the emergence of image\n    comprehension through tactile discovery, using 3D-printed objects\n    extracted from paintings. Later, we present a dynamic Force Feedback\n    Tablet (F2T) used to convey the 2D shape and texture information of\n    objects through haptic feedback. We then explore several image\n    segmentation methods to automate the extraction of meaningful\n    objects from selected artworks, to be presented to visually impaired\n    people through the F2T. Finally, we evaluate how to best combine the\n    F2T’s haptic effects in order to convey the extracted objects and\n    features to the users, with the aim of facilitating the\n    comprehension of the represented objects and their affordances.}\n}\nFor attribution, please cite this work as:\nAli Souradi, Christele Lecomte, Katerine Romeo, Simon Gay, Marc-Aurèle\nRivière, Abderrahim El Moataz, & Edwige Pissaloux. (2020). Towards\nthe Tactile Discovery of Cultural Heritage with Multi-approach\nSegmentation. In Abderrahim El Moataz, Driss Mammass, Alamin Mansouri,\n& Fathallah Nouboud (Eds.), Lecture Notes in Computer\nScience (Vol. 12119, pp. 14–23). Springer International Publishing.\nhttps://doi.org/10.1007/978-3-030-51935-3_2"
  },
  {
    "objectID": "content/pubs/JEP22/index.html",
    "href": "content/pubs/JEP22/index.html",
    "title": "Spatiotemporal influences on the recognition of two-dimensional vibrotactile patterns on the abdomen",
    "section": "",
    "text": "Link to the PDF (preprint)\n\n\n\n\nCitationBibTeX citation:@article{faugloire2022,\n  author = {Elise Faugloire and Laure Lejeune and Marc-Aurèle Rivière\n    and Bruno Mantel},\n  title = {Spatiotemporal Influences on the Recognition of\n    Two-Dimensional Vibrotactile Patterns on the Abdomen},\n  journal = {Journal of Experimental Psychology: Applied},\n  volume = {28},\n  number = {3},\n  pages = {606-628},\n  date = {2022-09-02},\n  url = {https://psycnet.apa.org/record/2022-01207-001},\n  doi = {10.1037/xap0000404},\n  issn = {1939-2192, 1076-898X},\n  langid = {en},\n  abstract = {Spatial and temporal factors are known to highly influence\n    tactile perception, but their role has been largely unexplored in\n    the case of two-dimensional (2D) pattern recognition. We\n    investigated whether recognition is facilitated by the spatial\n    and/or temporal separation of pattern elements, or by conditions\n    known to favor perceptual integration, such as the ones eliciting\n    apparent movement. 2D vibrotactile patterns were presented to the\n    abdomen of novice participants. In Experiment 1, we manipulated the\n    spatial (inter-tactor distance) and temporal (burst duration and\n    inter-burst interval) parameters applied to the tracing mode\n    (sequential activation of pattern elements). In Experiment 2, we\n    compared display modes differing in their level of temporal overlap\n    in the presentation of pattern elements: the static mode\n    (simultaneous activation of pattern elements), the slit-scan mode\n    (pattern revealed line by line), and the tracing mode. The results\n    of both experiments reveal that (a) recognition performance\n    increases with the isolation of pattern elements in space and/or in\n    time, (b) spatial and temporal factors interact in pattern\n    recognition, and (c) conditions leading to apparent movement tend to\n    be associated with lower recognition accuracy. These results further\n    our understanding of tactile perception and provide guidance for the\n    design of future vibrotactile communication systems.}\n}\nFor attribution, please cite this work as:\nElise Faugloire, Laure Lejeune, Marc-Aurèle Rivière, & Bruno Mantel.\n(2022). Spatiotemporal influences on the recognition of two-dimensional\nvibrotactile patterns on the abdomen. Journal of Experimental\nPsychology: Applied, 28(3), 606–628. https://doi.org/10.1037/xap0000404"
  },
  {
    "objectID": "content/pubs/NER19/index.html",
    "href": "content/pubs/NER19/index.html",
    "title": "NAV-VIR: an audio-tactile virtual environment to assist visually impaired people",
    "section": "",
    "text": "Link to the PDF\n\n\n\n\nCitationBibTeX citation:@inproceedings{rivière2019,\n  author = {Marc-Aurèle Rivière and Simon Gay and Katerine Romeo and\n    Edwige Pissaloux and Michal Bujacz and Piotr Skulimowski and Pawel\n    Strumillo},\n  publisher = {IEEE},\n  title = {NAV-VIR: An Audio-Tactile Virtual Environment to Assist\n    Visually Impaired People},\n  booktitle = {Proceedings of the International IEEE/EMBS Conference on\n    Neural Engineering},\n  pages = {1038-1041},\n  date = {2019-05-20},\n  url = {https://ieeexplore.ieee.org/document/8717086},\n  doi = {10.1109/NER.2019.8717086},\n  isbn = {978-1-5386-7921-0},\n  langid = {en},\n  abstract = {This paper introduces the\n    {[}NAV-VIR{]}(/content/projects/NAV-VIR) system, a multimodal\n    virtual environment to assist visually impaired people in virtually\n    discovering and exploring unknown areas from the safety of their\n    home. The originality of NAV-VIR resides in (1) an optimized\n    representation of the surrounding topography, the spatial gist,\n    based on human spatial cognition models and the sensorimotor\n    supplementation framework, and (2) a multimodal orientation-aware\n    immersive virtual environment relying on two synergetic interfaces:\n    an interactive force feedback tablet, the F2T, and an immersive\n    HRTF-based 3D audio simulation relying on binaural recordings of\n    real environments. This paper presents NAV-VIR functionalities and\n    its preliminary evaluation through a simple shape and movement\n    perception task.}\n}\nFor attribution, please cite this work as:\nMarc-Aurèle Rivière, Simon Gay, Katerine Romeo, Edwige Pissaloux, Michal\nBujacz, Piotr Skulimowski, & Pawel Strumillo. (2019). NAV-VIR: an\naudio-tactile virtual environment to assist visually impaired people.\nProceedings of the International IEEE/EMBS Conference on Neural\nEngineering, 1038–1041. https://doi.org/10.1109/NER.2019.8717086"
  },
  {
    "objectID": "content/pubs/index.html",
    "href": "content/pubs/index.html",
    "title": " Scientific Publications",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nSpatiotemporal influences on the recognition of two-dimensional vibrotactile patterns on the abdomen\n\n\nJournal of Experimental Psychology: Applied\n\n\n\n\nAssistive Devices\n\n\nAccessibility\n\n\nSensory Substitution\n\n\nHaptic Interface\n\n\nPsychophysics\n\n\n\n\nThis study reveals that patterns made up of several vibration points are better recognized when pattern elements are clearly isolated in time and space. The feeling of a single point moving continuously along the skin, as if the pattern was manually drawn on the skin, does not appear to favor the recognition of patterns’ shape\n\n\n\n\n\n\nSep 2, 2022\n\n\nElise Faugloire, Laure Lejeune, Marc-Aurèle Rivière, Bruno Mantel\n\n\n\n\n\n\n\n\nAn Audio-Based 3D Spatial Guidance AR System for Blind Users\n\n\nLecture Notes in Computer Science\n\n\n\n\nAssistive Devices\n\n\nAccessibility\n\n\nAugmented Reality\n\n\nSensory Substitution\n\n\nAuditory Interface\n\n\nComputer Vision\n\n\n\n\nWe introduce CamIO, an AR app for Visually Impaired People (VIP) to reach objects in their immediate environment through real-time 3D audio guidance\n\n\n\n\n\n\nSep 12, 2020\n\n\nJames Coughlan, Brandon Biggs, Marc-Aurèle Rivière, Huiying Shen\n\n\n\n\n\n\n\n\nTowards the Tactile Discovery of Cultural Heritage with Multi-approach Segmentation\n\n\nLecture Notes in Computer Science\n\n\n\n\nAssistive Devices\n\n\nAccessibility\n\n\nComputer Vision\n\n\nSensory Substitution\n\n\nHaptic Interface\n\n\n\n\nWe introduce preliminary work on using multi-approach image segmentation, combined with a force-feedback interface, to provide access to Artworks to Visually Impaired People\n\n\n\n\n\n\nJul 8, 2020\n\n\nAli Souradi, Christele Lecomte, Katerine Romeo, Simon Gay, Marc-Aurèle Rivière, Abderrahim El Moataz, Edwige Pissaloux\n\n\n\n\n\n\n\n\nNAV-VIR: an audio-tactile virtual environment to assist visually impaired people\n\n\nInternational IEEE/EMBS Conference on Neural Engineering\n\n\n\n\nAssistive Devices\n\n\nAccessibility\n\n\nAugmented Reality\n\n\nSensory Substitution\n\n\nAuditory Interface\n\n\nHaptic Interface\n\n\n\n\nWe introduce NAV-VIR, a multimodal interface for the interactive exploration of maps by Visually Impaired People\n\n\n\n\n\n\nMay 20, 2019\n\n\nMarc-Aurèle Rivière, Simon Gay, Katerine Romeo, Edwige Pissaloux, Michal Bujacz, Piotr Skulimowski, Pawel Strumillo\n\n\n\n\n\n\n\n\nTowards Haptic Surface Devices with Force Feedback for Visually Impaired People\n\n\nLecture Notes in Computer Science\n\n\n\n\nAssistive Devices\n\n\nAccessibility\n\n\nAugmented Reality\n\n\nSensory Substitution\n\n\nHaptic Interface\n\n\n\n\nWe introduce the principles of a haptic interface for finger-movement based exploration of image content through force-feedback\n\n\n\n\n\n\nJul 12, 2018\n\n\nSimon Gay, Marc-Aurèle Rivière, Edwige Pissaloux\n\n\n\n\n\n\n\n\nTactiBelt: integrating spatial cognition and mobility theories into the design of a novel orientation and mobility assistive device for the blind\n\n\nLecture Notes in Computer Science\n\n\n\n\nAssistive Devices\n\n\nAccessibility\n\n\nAugmented Reality\n\n\nSensory Substitution\n\n\nHaptic Interface\n\n\nSpatial Cognition\n\n\n\n\nWe introduce spatial cognition models as a framework to design novel mobility assistive devices for Visually Impaired People\n\n\n\n\n\n\nJul 12, 2018\n\n\nMarc-Aurèle Rivière, Simon Gay, Edwige Pissaloux\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "content/posts/index.html",
    "href": "content/posts/index.html",
    "title": " Blog Posts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nFast spatial data matching in R\n\n\nHow to match locations based on their coordinates\n\n\n\n\nBig Data\n\n\nData Manipulation\n\n\nSpatial Data\n\n\nR\n\n\nSQL\n\n\n\n\nThis document was prompted by this reddit question on how to fill missing location names by matching them to other known locations by their geographical proximity (using lat/long coordinates). The question is linked to a case study of Google’s Data Analytics certificate. To answer the question in a nutshell: the proposed matching by position won’t yield anything with this dataset since the locations missing a name or id are missing one because their coordinates lack the precision necessary to be reliably matched to another station by proximity alone.\n\n\n\n\n\n\nJun 18, 2022\n\n\n18 min\n\n\n\n\n\n\n\n\nMCMC for ‘Big Data’ with Stan\n\n\nFaster sampling with CmdStan using within-chain parallelization\n\n\n\n\nStatistics\n\n\nML\n\n\nBayesian Modeling\n\n\nBig Data\n\n\nStan\n\n\nR\n\n\n\n\nThis is an extension (and a translation in R) of PyMC-Labs’ benchmarking of MCMC for Big Data. The Stan code was updated to use within-chain parallelization and compiler optimization for faster CPU sampling.\n\n\n\n\n\n\nJun 5, 2022\n\n\n7 min\n\n\n\n\n\n\n\n\nTidyverse <-> data.table\n\n\nEquivalence between Tidyverse and data.table expressions\n\n\n\n\nData Manipulation\n\n\nTidyverse\n\n\ndata.table\n\n\nR\n\n\n\n\nThis document is a collection of notes I took while learning to use data.table, summarizing the equivalences between most dplyr/tidyr verbs and data.table.\n\n\n\n\n\n\nMay 19, 2022\n\n\n40 min\n\n\n\n\n\n\n\n\nBayesian Rock Climbing Rankings\n\n\nWith R and Stan\n\n\n\n\nStatistics\n\n\nML\n\n\nBayesian Modeling\n\n\nStan\n\n\nR\n\n\n\n\nThis is simply a transposition of Ethan Rosenthal’s article on Bayesian Rock Climbing to R. The Stan code was updated to use within-chain parallelization and compiler optimization for faster CPU sampling.\n\n\n\n\n\n\nApr 19, 2022\n\n\n13 min\n\n\n\n\n\n\nNo matching items\n\nReusehttps://creativecommons.org/licenses/by/4.0/"
  },
  {
    "objectID": "content/outreach/index.html",
    "href": "content/outreach/index.html",
    "title": " Outreach Activities",
    "section": "",
    "text": "College Fair of the University of Rouen\n\n\nPresenting my doctoral research project to highschool students during the College Fair of 2017 ()\n\n\n\n\n\n\n\n\n\n\n\nExpérimentarium Science Fair\n\n\nPresenting my doctoral research projects to a wide-ranging public of all backgrounds (from middle-school students to adults), during a yearly 3-days long science fair…\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "content/outreach/index.html#iconify-carbon-group-presentation-conferences-seminars",
    "href": "content/outreach/index.html#iconify-carbon-group-presentation-conferences-seminars",
    "title": " Outreach Activities",
    "section": " Conferences & Seminars",
    "text": "Conferences & Seminars\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nACCESSPACE: overview and future prospects\n\n\nRencontres Universitaires Numériques Normandes (RUNN’19)\n\n\n\nAssistive Devices\n\n\nAccessibility\n\n\nSensory Substitution\n\n\nSpatial Cognition\n\n\n\n\nAn overview of the ACCESSPACE project’s progress and future endeavors ()\n\n\n\n\n\n\nNov 21, 2019\n\n\nCaen, France\n\n\n\n\n\n\n\n\nSpatial Cognition and Computer Vision for better assistive devices\n\n\nFrench-Norwegian Workshop Day (2019)\n\n\n\nAssistive Devices\n\n\nAccessibility\n\n\nSensory Substitution\n\n\nSpatial Cognition\n\n\nComputer Vision\n\n\n\n\nAcademic talk presenting my work on using Cognitive Neurosciences and Computer Vision to develop better assistive devices for VIP\n\n\n\n\n\n\nJun 2, 2019\n\n\nTrondheim, Norway\n\n\n\n\n\n\n\n\nSensory substitution as a framework to access visual and spatial information for VIP\n\n\nSKERI Brown Bag\n\n\n\nAssistive Devices\n\n\nAccessibility\n\n\nSpatial Cognition\n\n\nSensory Substitution\n\n\nComputer Vision\n\n\n\n\nSeminar hosted at Smith-Kettlewell Eye-Research Institute, presenting the Sensory Substitution framework and its use in designing non-visual interfaces for VIP\n\n\n\n\n\n\nJan 9, 2019\n\n\nSan Francisco, USA\n\n\n\n\n\n\n\n\nTactiBelt: an Electronic Travel Aid prototype for VIP\n\n\nInt. Conf. on Computers Helping People (ICCHP’18)\n\n\n\nAssistive Devices\n\n\nAccessibility\n\n\nSpatial Cognition\n\n\nSensory Substitution\n\n\nVirtual Reality\n\n\n\n\nShort academic talk given during the ICCHP 2018 international conference to present the TactiBelt\n\n\n\n\n\n\nJul 12, 2018\n\n\nLinz, Austria\n\n\n\n\n\n\nNo matching items"
  }
]